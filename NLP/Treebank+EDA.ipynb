{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging - Lexicon and Rule Based Taggers\n",
    "\n",
    "Let's look at the two most basic tagging techniques - lexicon based (or unigram) and rule-based. \n",
    "\n",
    "In this guided exercise, you will explore the WSJ (wall street journal) POS-tagged corpus that comes with NLTK and build a lexicon and rule-based tagger using this corpus as the tarining data. \n",
    "\n",
    "This exercise is divided into the following sections:\n",
    "1. Reading and understanding the tagged dataset\n",
    "2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading and understanding the tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:31.236197Z",
     "start_time": "2019-09-29T17:07:25.231099Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:31.852385Z",
     "start_time": "2019-09-29T17:07:31.240405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:31.879403Z",
     "start_time": "2019-09-29T17:07:31.854664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.104797Z",
     "start_time": "2019-09-29T17:07:31.883321Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.115627Z",
     "start_time": "2019-09-29T17:07:35.108600Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('61', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('will', 'MD'),\n",
       "  ('join', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('board', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('Nov.', 'NNP'),\n",
       "  ('29', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Elsevier', 'NNP'),\n",
       "  ('N.V.', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('Dutch', 'NNP'),\n",
       "  ('publishing', 'VBG'),\n",
       "  ('group', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NNP'),\n",
       "  ('Agnew', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('55', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('former', 'JJ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Consolidated', 'NNP'),\n",
       "  ('Gold', 'NNP'),\n",
       "  ('Fields', 'NNP'),\n",
       "  ('PLC', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('was', 'VBD'),\n",
       "  ('named', 'VBN'),\n",
       "  ('*-1', '-NONE-'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('British', 'JJ'),\n",
       "  ('industrial', 'JJ'),\n",
       "  ('conglomerate', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples: Each sentence is a list of (word, pos) tuples\n",
    "wsj[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the list mentioned above, each element of the list is a sentence. Also, note that each sentence ends with a full stop '.' whose POS tag is also a '.'. Thus, the POS tag '.' demarcates the end of a sentence.\n",
    "\n",
    "Also, we do not need the corpus to be segmented into sentences, but can rather use a list of (word, tag) tuples. Let's convert the list into a (word, tag) tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.130134Z",
     "start_time": "2019-09-29T17:07:35.118107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list of sents to a list of (word, pos tag) tuples\n",
    "tagged_words = [tup for sent in wsj for tup in sent]\n",
    "print(len(tagged_words))\n",
    "tagged_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of about 100676 (word, tag) tuples. Let's now do some exploratory analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Analysis\n",
    "\n",
    "Let's now conduct some basic exploratory analysis to understand the tagged corpus. To start with, let's ask some simple questions:\n",
    "1. How many unique tags are there in the corpus? \n",
    "2. Which is the most frequent tag in the corpus?\n",
    "3. Which tag is most commonly assigned to the following words:\n",
    "    - \"bank\"\n",
    "    - \"executive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.151541Z",
     "start_time": "2019-09-29T17:07:35.133411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([word[0] for word in tagged_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.187949Z",
     "start_time": "2019-09-29T17:07:35.155827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elsevier', 'NNP'),\n",
       " ('N.V.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Dutch', 'NNP'),\n",
       " ('publishing', 'VBG'),\n",
       " ('group', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Rudolph', 'NNP'),\n",
       " ('Agnew', 'NNP'),\n",
       " (',', ','),\n",
       " ('55', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('former', 'JJ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Consolidated', 'NNP'),\n",
       " ('Gold', 'NNP'),\n",
       " ('Fields', 'NNP'),\n",
       " ('PLC', 'NNP'),\n",
       " (',', ','),\n",
       " ('was', 'VBD'),\n",
       " ('named', 'VBN'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('British', 'JJ'),\n",
       " ('industrial', 'JJ'),\n",
       " ('conglomerate', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('form', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('once', 'RB'),\n",
       " ('used', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarette', 'NN'),\n",
       " ('filters', 'NNS'),\n",
       " ('has', 'VBZ'),\n",
       " ('caused', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('high', 'JJ'),\n",
       " ('percentage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('cancer', 'NN'),\n",
       " ('deaths', 'NNS'),\n",
       " ('among', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('group', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('workers', 'NNS'),\n",
       " ('exposed', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('it', 'PRP'),\n",
       " ('more', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('30', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " (',', ','),\n",
       " ('researchers', 'NNS'),\n",
       " ('reported', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('asbestos', 'NN'),\n",
       " ('fiber', 'NN'),\n",
       " (',', ','),\n",
       " ('crocidolite', 'NN'),\n",
       " (',', ','),\n",
       " ('is', 'VBZ'),\n",
       " ('unusually', 'RB'),\n",
       " ('resilient', 'JJ'),\n",
       " ('once', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('enters', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('lungs', 'NNS'),\n",
       " (',', ','),\n",
       " ('with', 'IN'),\n",
       " ('even', 'RB'),\n",
       " ('brief', 'JJ'),\n",
       " ('exposures', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('it', 'PRP'),\n",
       " ('causing', 'VBG'),\n",
       " ('symptoms', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('show', 'VBP'),\n",
       " ('up', 'RP'),\n",
       " ('decades', 'NNS'),\n",
       " ('later', 'JJ'),\n",
       " (',', ','),\n",
       " ('researchers', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-2', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('Lorillard', 'NNP'),\n",
       " ('Inc.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('unit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('New', 'JJ'),\n",
       " ('York-based', 'JJ'),\n",
       " ('Loews', 'NNP'),\n",
       " ('Corp.', 'NNP'),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-2', '-NONE-'),\n",
       " ('makes', 'VBZ'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarettes', 'NNS'),\n",
       " (',', ','),\n",
       " ('stopped', 'VBD'),\n",
       " ('using', 'VBG'),\n",
       " ('crocidolite', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('Micronite', 'NN'),\n",
       " ('cigarette', 'NN'),\n",
       " ('filters', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('1956', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Although', 'IN'),\n",
       " ('preliminary', 'JJ'),\n",
       " ('findings', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('reported', 'VBN'),\n",
       " ('*-2', '-NONE-'),\n",
       " ('more', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('year', 'NN'),\n",
       " ('ago', 'IN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('latest', 'JJS'),\n",
       " ('results', 'NNS'),\n",
       " ('appear', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('today', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('New', 'NNP'),\n",
       " ('England', 'NNP'),\n",
       " ('Journal', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Medicine', 'NNP'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('forum', 'NN'),\n",
       " ('likely', 'JJ'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('bring', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('attention', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('Lorillard', 'NNP'),\n",
       " ('spokewoman', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('``', '``'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('old', 'JJ'),\n",
       " ('story', 'NN'),\n",
       " ('.', '.'),\n",
       " ('We', 'PRP'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('talking', 'VBG'),\n",
       " ('about', 'IN'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " ('before', 'IN'),\n",
       " ('anyone', 'NN'),\n",
       " ('heard', 'VBD'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('having', 'VBG'),\n",
       " ('any', 'DT'),\n",
       " ('questionable', 'JJ'),\n",
       " ('properties', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('There', 'EX'),\n",
       " ('is', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('asbestos', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('products', 'NNS'),\n",
       " ('now', 'RB'),\n",
       " ('.', '.'),\n",
       " (\"''\", \"''\"),\n",
       " ('Neither', 'DT'),\n",
       " ('Lorillard', 'NNP'),\n",
       " ('nor', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('researchers', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('*T*-3', '-NONE-'),\n",
       " ('studied', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('workers', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('aware', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('research', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('smokers', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarettes', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('We', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('no', 'DT'),\n",
       " ('useful', 'JJ'),\n",
       " ('information', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('whether', 'IN'),\n",
       " ('users', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('at', 'IN'),\n",
       " ('risk', 'NN'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('said', 'VBD'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('James', 'NNP'),\n",
       " ('A.', 'NNP'),\n",
       " ('Talcott', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Boston', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Dana-Farber', 'NNP'),\n",
       " ('Cancer', 'NNP'),\n",
       " ('Institute', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Dr.', 'NNP'),\n",
       " ('Talcott', 'NNP'),\n",
       " ('led', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('team', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('researchers', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('National', 'NNP'),\n",
       " ('Cancer', 'NNP'),\n",
       " ('Institute', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('medical', 'JJ'),\n",
       " ('schools', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Harvard', 'NNP'),\n",
       " ('University', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Boston', 'NNP'),\n",
       " ('University', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('Lorillard', 'NNP'),\n",
       " ('spokeswoman', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('asbestos', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('used', 'VBN'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('in', 'IN'),\n",
       " ('``', '``'),\n",
       " ('very', 'RB'),\n",
       " ('modest', 'JJ'),\n",
       " ('amounts', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('in', 'IN'),\n",
       " ('*', '-NONE-'),\n",
       " ('making', 'VBG'),\n",
       " ('paper', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('filters', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('early', 'JJ'),\n",
       " ('1950s', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('replaced', 'VBN'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('different', 'JJ'),\n",
       " ('type', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('filter', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('1956', 'CD'),\n",
       " ('.', '.'),\n",
       " ('From', 'IN'),\n",
       " ('1953', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('1955', 'CD'),\n",
       " (',', ','),\n",
       " ('9.8', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarettes', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('filters', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('sold', 'VBN'),\n",
       " ('*-3', '-NONE-'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('Among', 'IN'),\n",
       " ('33', 'CD'),\n",
       " ('men', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('*T*-4', '-NONE-'),\n",
       " ('worked', 'VBD'),\n",
       " ('closely', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('substance', 'NN'),\n",
       " (',', ','),\n",
       " ('28', 'CD'),\n",
       " ('*ICH*-1', '-NONE-'),\n",
       " ('have', 'VBP'),\n",
       " ('died', 'VBN'),\n",
       " ('--', ':'),\n",
       " ('more', 'JJ'),\n",
       " ('than', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('times', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('expected', 'VBN'),\n",
       " ('number', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Four', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('five', 'CD'),\n",
       " ('surviving', 'VBG'),\n",
       " ('workers', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('asbestos-related', 'JJ'),\n",
       " ('diseases', 'NNS'),\n",
       " (',', ','),\n",
       " ('including', 'VBG'),\n",
       " ('three', 'CD'),\n",
       " ('with', 'IN'),\n",
       " ('recently', 'RB'),\n",
       " ('diagnosed', 'VBN'),\n",
       " ('cancer', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('total', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('18', 'CD'),\n",
       " ('deaths', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('malignant', 'JJ'),\n",
       " ('mesothelioma', 'NN'),\n",
       " (',', ','),\n",
       " ('lung', 'NN'),\n",
       " ('cancer', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('asbestosis', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('far', 'RB'),\n",
       " ('higher', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('*', '-NONE-'),\n",
       " ('expected', 'VBN'),\n",
       " ('*?*', '-NONE-'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('researchers', 'NNS'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('The', 'DT'),\n",
       " ('morbidity', 'NN'),\n",
       " ('rate', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('striking', 'JJ'),\n",
       " ('finding', 'NN'),\n",
       " ('among', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('who', 'WP'),\n",
       " ('*T*-5', '-NONE-'),\n",
       " ('study', 'VBP'),\n",
       " ('asbestos-related', 'JJ'),\n",
       " ('diseases', 'NNS'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('said', 'VBD'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('Dr.', 'NNP'),\n",
       " ('Talcott', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('percentage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('lung', 'NN'),\n",
       " ('cancer', 'NN'),\n",
       " ('deaths', 'NNS'),\n",
       " ('among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('workers', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('West', 'NNP'),\n",
       " ('Groton', 'NNP'),\n",
       " (',', ','),\n",
       " ('Mass.', 'NNP'),\n",
       " (',', ','),\n",
       " ('paper', 'NN'),\n",
       " ('factory', 'NN'),\n",
       " ('appears', 'VBZ'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('highest', 'JJS'),\n",
       " ('for', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('asbestos', 'NN'),\n",
       " ('workers', 'NNS'),\n",
       " ('studied', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('in', 'IN'),\n",
       " ('Western', 'JJ'),\n",
       " ('industrialized', 'VBN'),\n",
       " ('countries', 'NNS'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-2', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('plant', 'NN'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('is', 'VBZ'),\n",
       " ('owned', 'VBN'),\n",
       " ('*-4', '-NONE-'),\n",
       " ('by', 'IN'),\n",
       " ('Hollingsworth', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('Vose', 'NNP'),\n",
       " ('Co.', 'NNP'),\n",
       " (',', ','),\n",
       " ('was', 'VBD'),\n",
       " ('under', 'IN'),\n",
       " ('contract', 'NN'),\n",
       " ('*ICH*-2', '-NONE-'),\n",
       " ('with', 'IN'),\n",
       " ('Lorillard', 'NN'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('cigarette', 'NN'),\n",
       " ('filters', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('finding', 'NN'),\n",
       " ('probably', 'RB'),\n",
       " ('will', 'MD'),\n",
       " ('support', 'VB'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('*T*-6', '-NONE-'),\n",
       " ('argue', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('U.S.', 'NNP'),\n",
       " ('should', 'MD'),\n",
       " ('regulate', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('class', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('including', 'VBG'),\n",
       " ('crocidolite', 'NN'),\n",
       " ('more', 'RBR'),\n",
       " ('stringently', 'RB'),\n",
       " ('than', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('common', 'JJ'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " (',', ','),\n",
       " ('chrysotile', 'NN'),\n",
       " (',', ','),\n",
       " ('found', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('in', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('schools', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('other', 'JJ'),\n",
       " ('buildings', 'NNS'),\n",
       " (',', ','),\n",
       " ('Dr.', 'NNP'),\n",
       " ('Talcott', 'NNP'),\n",
       " ('said', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('U.S.', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('industrialized', 'VBN'),\n",
       " ('nations', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-7', '-NONE-'),\n",
       " ('does', 'VBZ'),\n",
       " (\"n't\", 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('higher', 'JJR'),\n",
       " ('standard', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('regulation', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('smooth', 'JJ'),\n",
       " (',', ','),\n",
       " ('needle-like', 'JJ'),\n",
       " ('fibers', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('crocidolite', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('are', 'VBP'),\n",
       " ('classified', 'VBN'),\n",
       " ('*-5', '-NONE-'),\n",
       " ('as', 'IN'),\n",
       " ('amphobiles', 'NNS'),\n",
       " (',', ','),\n",
       " ('according', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('Brooke', 'NNP'),\n",
       " ('T.', 'NNP'),\n",
       " ('Mossman', 'NNP'),\n",
       " (',', ','),\n",
       " ('a', 'DT'),\n",
       " ('professor', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('pathlogy', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('University', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Vermont', 'NNP'),\n",
       " ('College', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Medicine', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('More', 'RBR'),\n",
       " ('common', 'JJ'),\n",
       " ('chrysotile', 'NN'),\n",
       " ('fibers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('curly', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('are', 'VBP'),\n",
       " ('more', 'RBR'),\n",
       " ('easily', 'RB'),\n",
       " ('rejected', 'VBN'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('body', 'NN'),\n",
       " (',', ','),\n",
       " ('Dr.', 'NNP'),\n",
       " ('Mossman', 'NNP'),\n",
       " ('explained', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-2', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('In', 'IN'),\n",
       " ('July', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Environmental', 'NNP'),\n",
       " ('Protection', 'NNP'),\n",
       " ('Agency', 'NNP'),\n",
       " ('imposed', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('gradual', 'JJ'),\n",
       " ('ban', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('virtually', 'RB'),\n",
       " ('all', 'DT'),\n",
       " ('uses', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('.', '.'),\n",
       " ('By', 'IN'),\n",
       " ('1997', 'CD'),\n",
       " (',', ','),\n",
       " ('almost', 'RB'),\n",
       " ('all', 'DT'),\n",
       " ('remaining', 'VBG'),\n",
       " ('uses', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('cancer-causing', 'JJ'),\n",
       " ('asbestos', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('outlawed', 'VBN'),\n",
       " ('*-6', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('About', 'IN'),\n",
       " ('160', 'CD'),\n",
       " ('workers', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('factory', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-8', '-NONE-'),\n",
       " ('made', 'VBD'),\n",
       " ('paper', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('Kent', 'NNP'),\n",
       " ('filters', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('exposed', 'VBN'),\n",
       " ('*-7', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('asbestos', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('1950s', 'CD'),\n",
       " ('.', '.'),\n",
       " ('Areas', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('factory', 'NN'),\n",
       " ('*ICH*-2', '-NONE-'),\n",
       " ('were', 'VBD'),\n",
       " ('particularly', 'RB'),\n",
       " ('dusty', 'JJ'),\n",
       " ('where', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('crocidolite', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('used', 'VBN'),\n",
       " ('*-8', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.'),\n",
       " ('Workers', 'NNS'),\n",
       " ('dumped', 'VBD'),\n",
       " ('large', 'JJ'),\n",
       " ('burlap', 'NN'),\n",
       " ('sacks', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('imported', 'VBN'),\n",
       " ('material', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('huge', 'JJ'),\n",
       " ('bin', 'NN'),\n",
       " (',', ','),\n",
       " ('poured', 'VBD'),\n",
       " ('in', 'RP'),\n",
       " ('cotton', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('acetate', 'NN'),\n",
       " ('fibers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('mechanically', 'RB'),\n",
       " ('mixed', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('dry', 'JJ'),\n",
       " ('fibers', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('process', 'NN'),\n",
       " ('used', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('filters', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Workers', 'NNS'),\n",
       " ('described', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('clouds', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('blue', 'JJ'),\n",
       " ('dust', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('that', 'WDT'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('hung', 'VBD'),\n",
       " ('over', 'IN'),\n",
       " ('parts', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('factory', 'NN'),\n",
       " (',', ','),\n",
       " ('even', 'RB'),\n",
       " ('though', 'IN'),\n",
       " ('exhaust', 'NN'),\n",
       " ('fans', 'NNS'),\n",
       " ('ventilated', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('area', 'NN'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('There', 'EX'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('question', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('workers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('managers', 'NNS'),\n",
       " ('contracted', 'VBD'),\n",
       " ('asbestos-related', 'JJ'),\n",
       " ('diseases', 'NNS'),\n",
       " (',', ','),\n",
       " (\"''\", \"''\"),\n",
       " ('said', 'VBD'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('Darrell', 'NNP'),\n",
       " ('Phillips', 'NNP'),\n",
       " (',', ','),\n",
       " ('vice', 'NN'),\n",
       " ('president', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('human', 'JJ'),\n",
       " ('resources', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('Hollingsworth', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('Vose', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('But', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('recognize', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('events', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('place', 'NN'),\n",
       " ('35', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('bearing', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('work', 'NN'),\n",
       " ('force', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Yields', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('money-market', 'JJ'),\n",
       " ('mutual', 'JJ'),\n",
       " ('funds', 'NNS'),\n",
       " ('continued', 'VBD'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('slide', 'VB'),\n",
       " (',', ','),\n",
       " ('amid', 'IN'),\n",
       " ('signs', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('portfolio', 'NN'),\n",
       " ('managers', 'NNS'),\n",
       " ('expect', 'VBP'),\n",
       " ('further', 'JJ'),\n",
       " ('declines', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('interest', 'NN'),\n",
       " ('rates', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('average', 'JJ'),\n",
       " ('seven-day', 'JJ'),\n",
       " ('compound', 'NN'),\n",
       " ('yield', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('400', 'CD'),\n",
       " ('taxable', 'JJ'),\n",
       " ('funds', 'NNS'),\n",
       " ('tracked', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('by', 'IN'),\n",
       " ('IBC', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Money', 'NNP'),\n",
       " ('Fund', 'NNP'),\n",
       " ('Report', 'NNP'),\n",
       " ('eased', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('fraction', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('percentage', 'NN'),\n",
       " ('point', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('8.45', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('8.47', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('week', 'NN'),\n",
       " ('ended', 'VBD'),\n",
       " ('Tuesday', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Compound', 'NN'),\n",
       " ('yields', 'NNS'),\n",
       " ('assume', 'VBP'),\n",
       " ('reinvestment', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('dividends', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('yield', 'NN'),\n",
       " ('continues', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('year', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Average', 'JJ'),\n",
       " ('maturity', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('funds', 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " ('investments', 'NNS'),\n",
       " ('lengthened', 'VBD'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('41', 'CD'),\n",
       " ('days', 'NNS'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('longest', 'JJS'),\n",
       " ('since', 'IN'),\n",
       " ('early', 'JJ'),\n",
       " ('August', 'NNP'),\n",
       " (',', ','),\n",
       " ('according', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('Donoghue', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('.', '.'),\n",
       " ('Longer', 'JJR'),\n",
       " ('maturities', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('thought', 'VBN'),\n",
       " ('*-1', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('indicate', 'VB'),\n",
       " ('declining', 'VBG'),\n",
       " ('interest', 'NN'),\n",
       " ('rates', 'NNS'),\n",
       " ('because', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('permit', 'VBP'),\n",
       " ('portfolio', 'NN'),\n",
       " ('managers', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('retain', 'VB'),\n",
       " ('relatively', 'RB'),\n",
       " ('higher', 'JJR'),\n",
       " ('rates', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('longer', 'JJR'),\n",
       " ('period', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Shorter', 'JJR'),\n",
       " ('maturities', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('considered', 'VBN'),\n",
       " ('*-9', '-NONE-'),\n",
       " ('a', 'DT'),\n",
       " ('sign', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('rising', 'VBG'),\n",
       " ('rates', 'NNS'),\n",
       " ('because', 'IN'),\n",
       " ('portfolio', 'NN'),\n",
       " ('managers', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('capture', 'VB'),\n",
       " ('higher', 'JJR'),\n",
       " ('rates', 'NNS'),\n",
       " ('sooner', 'RB'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('average', 'JJ'),\n",
       " ('maturity', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('funds', 'NNS'),\n",
       " ('open', 'JJ'),\n",
       " ('only', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('institutions', 'NNS'),\n",
       " (',', ','),\n",
       " ('considered', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.205836Z",
     "start_time": "2019-09-29T17:07:35.190409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 1: Find the number of unique POS tags in the corpus\n",
    "# you can use the set() function on the list of tags to get a unique set of tags, \n",
    "# and compute its length\n",
    "unique_set = set([word[1] for word in tagged_words])\n",
    "len(unique_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.413557Z",
     "start_time": "2019-09-29T17:07:35.208158Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-86cdabad9912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "Counter([word[1] for word in tagged_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.428277Z",
     "start_time": "2019-09-29T17:07:25.285Z"
    }
   },
   "outputs": [],
   "source": [
    "# question 2: Which is the most frequent tag in the corpus\n",
    "# to count the frequency of elements in a list, the Counter() class from collections\n",
    "# module is very useful, as shown below\n",
    "\n",
    "from collections import Counter\n",
    "tag_counts = Counter([word[1] for word in tagged_words])\n",
    "tag_counts.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.429446Z",
     "start_time": "2019-09-29T17:07:25.289Z"
    }
   },
   "outputs": [],
   "source": [
    "# the most common tags can be seen using the most_common() method of Counter\n",
    "tag_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.430589Z",
     "start_time": "2019-09-29T17:07:25.293Z"
    }
   },
   "outputs": [],
   "source": [
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, NN is the most common tag followed by IN, NNP, DT, -NONE- etc. You can read the exhaustive list of tags using the NLTK documentation as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.431774Z",
     "start_time": "2019-09-29T17:07:25.297Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of POS tags in NLTK\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.432897Z",
     "start_time": "2019-09-29T17:07:25.299Z"
    }
   },
   "outputs": [],
   "source": [
    "# question 3: Which tag is most commonly assigned to the word w. Get the tags list that appear for word w and then use the Counter()\n",
    "# Try \n",
    "w ='bank' \n",
    "bank = Counter([word[1] for word in tagged_words if word[0] == w])\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.434554Z",
     "start_time": "2019-09-29T17:07:25.303Z"
    }
   },
   "outputs": [],
   "source": [
    "# question 3: Which tag is most commonly assigned to the word w. Try 'executive' \n",
    "executive = Counter([word[1] for word in tagged_words if word[0] == 'executive'])\n",
    "executive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Analysis Contd.\n",
    "\n",
    "Until now, we were looking at the frequency of tags assigned to particular words, which is the basic idea used by lexicon or unigram taggers. Let's now try observing some rules which can potentially be used for POS tagging. \n",
    "\n",
    "To start with, let's see if the following questions reveal something useful:\n",
    "\n",
    "4. What fraction of words with the tag 'VBD' (verb, past tense) end with the letters 'ed'\n",
    "5. What fraction of words with the tag 'VBG' (verb, present participle/gerund) end with the letters 'ing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.436171Z",
     "start_time": "2019-09-29T17:07:25.308Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. how many words with the tag 'VBD' (verb, past tense) end with 'ed'\n",
    "# first get the all the words tagged as VBD\n",
    "past_tense_verbs = [word for word in tagged_words if word[1] =='VBD']\n",
    "\n",
    "# subset the past tense verbs with words ending with 'ed'. (Try w.endswith('ed'))\n",
    "ed_verbs = [word for word in past_tense_verbs if word[0].endswith('ed') ]\n",
    "print(len(ed_verbs) / len(past_tense_verbs))\n",
    "ed_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.437484Z",
     "start_time": "2019-09-29T17:07:25.311Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5. how many words with the tag 'VBG' end with 'ing'\n",
    "participle_verbs = [ word for word in tagged_words if word[1] =='VBG']\n",
    "ing_verbs = [w for w in participle_verbs if w[0].endswith('ing')]\n",
    "print(len(ing_verbs) / len(participle_verbs))\n",
    "ing_verbs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Analysis Continued\n",
    "\n",
    "Let's now try observing some tag patterns using the fact the some tags are more likely to apper after certain other tags. For e.g. most nouns NN are usually followed by determiners DT (\"The/DT constitution/NN\"), adjectives JJ usually precede a noun NN (\" A large/JJ building/NN\"), etc. \n",
    "\n",
    "Try answering the following questions:\n",
    "1. What fraction of adjectives JJ are followed by a noun NN? \n",
    "2. What fraction of determiners DT are followed by a noun NN?\n",
    "3. What fraction of modals MD are followed by a verb VB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.439012Z",
     "start_time": "2019-09-29T17:07:25.316Z"
    }
   },
   "outputs": [],
   "source": [
    "# question: what fraction of adjectives JJ are followed by a noun NN\n",
    "\n",
    "# create a list of all tags (without the words)\n",
    "tags = [ word[1] for word in tagged_words]\n",
    "\n",
    "# create a list of JJ tags\n",
    "jj_tags = [ word[1] for word in tagged_words if word[1] == 'JJ']\n",
    "\n",
    "# create a list of (JJ, NN) tags\n",
    "jj_nn_tags = [(tags[index], tags[index+1]) for index, t in enumerate(tags) \n",
    "              if tags[index] == 'JJ' and tags[index+1] == 'NN']\n",
    "\n",
    "print(len(jj_tags))\n",
    "print(len(jj_nn_tags))\n",
    "print(len(jj_nn_tags) / len(jj_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.442135Z",
     "start_time": "2019-09-29T17:07:25.319Z"
    }
   },
   "outputs": [],
   "source": [
    "# question: what fraction of determiners DT are followed by a noun NN\n",
    "dt_tags = [word[1] for word in tagged_words if word[1] == 'DT']\n",
    "dt_nn_tags = [(tags[index], tags[index+1]) for index, t in enumerate(tags) \n",
    "              if tags[index] == 'DT' and tags[index+1] == 'NN']\n",
    "\n",
    "print(len(dt_tags))\n",
    "print(len(dt_nn_tags))\n",
    "print(len(dt_nn_tags) / len(dt_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.443245Z",
     "start_time": "2019-09-29T17:07:25.323Z"
    }
   },
   "outputs": [],
   "source": [
    "# question: what fraction of modals MD are followed by a verb VB?\n",
    "md_tags = [word[1] for word in tagged_words if word[1] == 'MD']\n",
    "md_vb_tags = [(tags[index], tags[index+1]) for index, t in enumerate(tags) \n",
    "              if tags[index] == 'MD' and tags[index+1] == 'VB']\n",
    "\n",
    "print(len(md_tags))\n",
    "print(len(md_vb_tags))\n",
    "print(len(md_vb_tags) / len(md_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexican and Ruley based models for POS tagging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.444412Z",
     "start_time": "2019-09-29T17:07:25.326Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(wsj, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.445863Z",
     "start_time": "2019-09-29T17:07:25.330Z"
    }
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "unigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.447109Z",
     "start_time": "2019-09-29T17:07:25.332Z"
    }
   },
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.BigramTagger(wsj)\n",
    "bigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule based tagging: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.448258Z",
     "start_time": "2019-09-29T17:07:25.335Z"
    }
   },
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    (r'.*ing$', 'VBG'),\n",
    "    (r'.*ed$', 'VBD'),\n",
    "    (r'.*es$', 'VBZ'),\n",
    "    (r'.*ould$', 'MD'),\n",
    "    (r'.*\\'s$', 'NN$'),\n",
    "    (r'.*s$', 'NNS'),\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),\n",
    "    (r'.*', 'NN')\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(pattern)\n",
    "regexp_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine lexical and rule based models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.449307Z",
     "start_time": "2019-09-29T17:07:25.339Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====> Combine regexp tagger and unigram tagger\n",
    "rule_based_taggers = nltk.RegexpTagger(pattern)\n",
    "lexicon_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_taggers)\n",
    "lexicon_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regexep, unigram and bigram taggers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.450710Z",
     "start_time": "2019-09-29T17:07:25.341Z"
    }
   },
   "outputs": [],
   "source": [
    "rule_based_taggers = nltk.RegexpTagger(pattern)\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_taggers)\n",
    "bigram_tagger = nltk.BigramTagger(train_set, backoff=unigram_tagger)\n",
    "bigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regexp, unigram, bigram and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.451904Z",
     "start_time": "2019-09-29T17:07:25.345Z"
    }
   },
   "outputs": [],
   "source": [
    "class PosTagger:\n",
    "    \n",
    "    def __init__(self, train_set, test_set, pattern):\n",
    "        self.train_set = train_set\n",
    "        self.test_set = test_set\n",
    "        self.pattern = pattern\n",
    "    \n",
    "    def get_pos_tagger(self):\n",
    "        rule_based_tagger = nltk.RegexpTagger(pattern)\n",
    "        unigram_tagger = nltk.UnigramTagger(train_set, backoff=rule_based_tagger)\n",
    "        bigram_tagger = nltk.BigramTagger(train_set, backoff=unigram_tagger)\n",
    "        trigram_tagger = nltk.TrigramTagger(train_set, backoff=bigram_tagger)\n",
    "        self.main_tagger = trigram_tagger\n",
    "        return unigram_tagger\n",
    "    \n",
    "    def evaluate(self):\n",
    "        return self.main_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.453967Z",
     "start_time": "2019-09-29T17:07:25.347Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_tagger = PosTagger(train_set, test_set, pattern)\n",
    "pos_tagger.get_pos_tagger()\n",
    "pos_tagger.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.455159Z",
     "start_time": "2019-09-29T17:07:25.350Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====> Unigram tagger default variation\n",
    "tagger = nltk.NgramTagger(1, train_set, backoff=regexp_tagger)\n",
    "tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.456516Z",
     "start_time": "2019-09-29T17:07:25.352Z"
    }
   },
   "outputs": [],
   "source": [
    "wsj = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.457899Z",
     "start_time": "2019-09-29T17:07:25.356Z"
    }
   },
   "outputs": [],
   "source": [
    "wsj[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging algorithm - HIDDEN MARKOV MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.459148Z",
     "start_time": "2019-09-29T17:07:25.358Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_set # ===> tag set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.460539Z",
     "start_time": "2019-09-29T17:07:25.361Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tagged_words = [tu for sentence in train_set for tu in sentence]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.461796Z",
     "start_time": "2019-09-29T17:07:25.364Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "vocabulary = set(tokens)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.462959Z",
     "start_time": "2019-09-29T17:07:25.368Z"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel():\n",
    "    def __init__(self, train_tagged_words, tags):\n",
    "        self.train_tagged_words = train_tagged_words\n",
    "        self.tags = tags\n",
    "    \n",
    "    def word_given_tag(self, word, tag):\n",
    "        tags_list = [pair for pair in self.train_tagged_words if pair[1] == tag]\n",
    "        matching_words = [pair for pair in tags_list if pair[0] == word]\n",
    "        return (len(matching_words), len(tags_list))\n",
    "\n",
    "    def transition(self, t2, t1):\n",
    "        t2_followed_by_t1_count, t1_count = 0, 0\n",
    "        tags = [word[1] for word in self.train_tagged_words]\n",
    "        for _idx in range(len(tags) - 1):\n",
    "            if (tags[_idx] == t1 and tags[_idx+1]  == t2):\n",
    "                t2_followed_by_t1_count += 1\n",
    "                t1_count += 1\n",
    "            elif (tags[_idx] == t1):\n",
    "                t1_count += 1\n",
    "        return (t2_followed_by_t1_count, t1_count)\n",
    "\n",
    "    def construct_transition_matrix(self):\n",
    "        no_of_tags = len(self.tags)\n",
    "        tags_matrix = np.zeros((no_of_tags, no_of_tags), dtype='float32')\n",
    "        for i, t1 in enumerate(list(self.tags)):\n",
    "            for j, t2 in enumerate(list(self.tags)):\n",
    "                result = self.transition(t2, t1)\n",
    "                tags_matrix[i][j] = (result[0]/result[1])\n",
    "        \n",
    "        return tags_matrix\n",
    "    \n",
    "    def vetarbi(self, words, tags_transistion_matrix):\n",
    "        result = []\n",
    "        tokens = list(set([word[1] for word in self.train_tagged_words]))\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            probabilities = []\n",
    "            for tag in tokens:\n",
    "                if i == 0:\n",
    "                    transition_p = tags_transistion.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_transistion.loc[result[-1], tag]\n",
    "\n",
    "                words_count = self.word_given_tag(word, tag)\n",
    "                emission_probability = words_count[0] / words_count[1]\n",
    "                probabilities.append( emission_probability *  transition_p)\n",
    "            pmax = max(probabilities)\n",
    "            state_max = tokens[probabilities.index(pmax)]\n",
    "            result.append(state_max)\n",
    "        return list(zip(words, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.464110Z",
     "start_time": "2019-09-29T17:07:25.370Z"
    }
   },
   "outputs": [],
   "source": [
    "obj = HiddenMarkovModel(train_tagged_words, unique_set)\n",
    "\n",
    "print(\"\\n large\")\n",
    "print(obj.word_given_tag(\"large\", \"JJ\"))\n",
    "print(obj.word_given_tag(\"large\", \"VB\"))\n",
    "print(obj.word_given_tag(\"large\", \"NN\"))\n",
    "\n",
    "print(\"\\n book\")\n",
    "print(obj.word_given_tag('book', 'NN'))\n",
    "print(obj.word_given_tag('book', 'JJ'))\n",
    "print(obj.word_given_tag('book', 'VB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.465217Z",
     "start_time": "2019-09-29T17:07:25.374Z"
    }
   },
   "outputs": [],
   "source": [
    "print(obj.transition('NNP', 'JJ'))\n",
    "print(obj.transition('NN', 'JJ'))\n",
    "print(obj.transition('VBG', 'NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.467345Z",
     "start_time": "2019-09-29T17:07:25.376Z"
    }
   },
   "outputs": [],
   "source": [
    "obj.construct_transition_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.468538Z",
     "start_time": "2019-09-29T17:07:25.379Z"
    }
   },
   "outputs": [],
   "source": [
    "obj.word_given_tag('Android', 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.469831Z",
     "start_time": "2019-09-29T17:07:25.381Z"
    }
   },
   "outputs": [],
   "source": [
    "result = obj.transition('VB', 'MD')\n",
    "result[0] /result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.470973Z",
     "start_time": "2019-09-29T17:07:25.387Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_transistion = pd.DataFrame(obj.construct_transition_matrix(), index=list(unique_set), columns=list(unique_set))\n",
    "tags_transistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.478112Z",
     "start_time": "2019-09-29T17:07:25.390Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===> start of the the sentence trancistion probabilities\n",
    "tags_transistion.loc['.', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.479746Z",
     "start_time": "2019-09-29T17:07:25.392Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(tags_transistion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test run of hidden markov model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.485081Z",
     "start_time": "2019-09-29T17:07:25.394Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.488373Z",
     "start_time": "2019-09-29T17:07:25.396Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "obj = HiddenMarkovModel(train_tagged_words, unique_set)\n",
    "tagged_seq = obj.vetarbi(test_tagged_words, tags_transistion)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.489738Z",
     "start_time": "2019-09-29T17:07:25.398Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.491259Z",
     "start_time": "2019-09-29T17:07:25.402Z"
    }
   },
   "outputs": [],
   "source": [
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.492948Z",
     "start_time": "2019-09-29T17:07:25.404Z"
    }
   },
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T17:07:35.495029Z",
     "start_time": "2019-09-29T17:07:25.406Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_test = 'Twitter is the best networking social site. Man is a social animal. Data science is an emerging field. Data science jobs are high in demand.'\n",
    "words = word_tokenize(sentence_test)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq = obj.vetarbi(words, tags_transistion)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(difference)\n",
    "print(tagged_seq)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
