{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:17.456949Z",
     "start_time": "2019-10-07T14:05:17.453112Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:17.612154Z",
     "start_time": "2019-10-07T14:05:17.609357Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### synsets: \n",
    "Synonyms of a word that we can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.202773Z",
     "start_time": "2019-10-07T14:05:19.984753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(astronomy) any of the nine large celestial bodies in the solar system that revolve around the sun and shine by reflected light; Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto in order of their proximity to the sun; viewed from the constellation Hercules, all the planets rotate around the sun in a counterclockwise direction\n",
      "\n",
      "\n",
      "a person who follows or serves another\n",
      "\n",
      "\n",
      "any celestial body (other than comets or satellites) that revolves around a star\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = wordnet.synsets('planet')\n",
    "for word in words:\n",
    "    print(word.definition())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: synonyms contained within wordnet is called lemmas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.221455Z",
     "start_time": "2019-10-07T14:05:20.212576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('kettle.n.01.kettle'), Lemma('kettle.n.01.boiler')]\n",
      "['kettle', 'boiler']\n",
      "a metal pot for stewing or boiling; usually has a lid \n",
      "\n",
      "[Lemma('kettle.n.02.kettle'), Lemma('kettle.n.02.kettleful')]\n",
      "['kettle', 'kettleful']\n",
      "the quantity a kettle will hold \n",
      "\n",
      "[Lemma('kettle_hole.n.01.kettle_hole'), Lemma('kettle_hole.n.01.kettle')]\n",
      "['kettle_hole', 'kettle']\n",
      "(geology) a hollow (typically filled by a lake) that results from the melting of a mass of ice trapped in glacial deposits \n",
      "\n",
      "[Lemma('kettle.n.04.kettle'), Lemma('kettle.n.04.kettledrum'), Lemma('kettle.n.04.tympanum'), Lemma('kettle.n.04.tympani'), Lemma('kettle.n.04.timpani')]\n",
      "['kettle', 'kettledrum', 'tympanum', 'tympani', 'timpani']\n",
      "a large hemispherical brass or copper percussion instrument with a drumhead that can be tuned by adjusting the tension on it \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = wordnet.synsets('kettle')\n",
    "\n",
    "for word in words:\n",
    "    print(word.lemmas())\n",
    "    print(word.lemma_names())\n",
    "    print(word.definition(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wordnet using Multilingual**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.281644Z",
     "start_time": "2019-10-07T14:05:20.253631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eng', 'als', 'arb', 'bul', 'cat', 'cmn', 'dan', 'ell', 'eus', 'fas', 'fin', 'fra', 'glg', 'heb', 'hrv', 'ind', 'ita', 'jpn', 'nld', 'nno', 'nob', 'pol', 'por', 'qcn', 'slv', 'spa', 'swe', 'tha', 'zsm']\n"
     ]
    }
   ],
   "source": [
    "print(wordnet.langs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.918876Z",
     "start_time": "2019-10-07T14:05:20.290480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['イヌ', 'ドッグ', '洋犬', '犬', '飼犬', '飼い犬']\n",
      "['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "['いぬ', 'スパイ', '回者', '回し者', '密偵', '工作員', '廻者', '廻し者', '探', '探り', '犬', '秘密捜査員', 'まわし者', '諜報員', '諜者', '間者', '間諜', '隠密']\n",
      "['spy', 'undercover_agent']\n"
     ]
    }
   ],
   "source": [
    "words = wordnet.synsets(b'\\xe7\\x8a\\xac'.decode('utf-8'), lang='jpn')\n",
    "\n",
    "for word in words:\n",
    "    print(word.lemma_names('jpn'))\n",
    "    print(word.lemma_names('eng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypernyms and hyponyms: \n",
    "\n",
    "**Hypernyms: More generic term compared to hyponyms** \n",
    "\n",
    "**Hyponyms: hyponym is word or a phrase which has a more specific meaning than hypernym**\n",
    "\n",
    "Hypernyms and hyponyms **is-a** a relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.931459Z",
     "start_time": "2019-10-07T14:05:20.926933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('pot.n.01')]\n",
      "[]\n",
      "[Synset('containerful.n.01')]\n",
      "[]\n",
      "[Synset('hole.n.05')]\n",
      "[]\n",
      "[Synset('percussion_instrument.n.01')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "words = wordnet.synsets('kettle')\n",
    "\n",
    "for word in words: \n",
    "    print(word.hypernyms())\n",
    "    print(word.member_holonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.971902Z",
     "start_time": "2019-10-07T14:05:20.941973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('instrumentality.n.03')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('group.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('matter.n.03')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('method.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('structure.n.03')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('body_part.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('plan_of_action.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('live_body.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n",
      "[Synset('orderliness.n.01')]\n",
      "[Synset('entity.n.01')]\n",
      "[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = wordnet.synsets('system')\n",
    "for word in words:\n",
    "    print(word.hypernyms())\n",
    "    print(word.root_hypernyms())\n",
    "    print(word.member_holonyms(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word sense disambiguation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:20.988689Z",
     "start_time": "2019-10-07T14:05:20.983857Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:21.095129Z",
     "start_time": "2019-10-07T14:05:21.019241Z"
    }
   },
   "outputs": [],
   "source": [
    "s = 'i went to the bank to deposit money'\n",
    "lesk_context_word = lesk(s.split(), 'bank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:21.115768Z",
     "start_time": "2019-10-07T14:05:21.107492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('savings_bank.n.02')\n",
      "a container (usually with a slot in the top) for keeping money at home\n"
     ]
    }
   ],
   "source": [
    "print(lesk_context_word)\n",
    "print(lesk_context_word.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesk algorithm from scratch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:45.807356Z",
     "start_time": "2019-10-07T14:05:45.793616Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:50.526931Z",
     "start_time": "2019-10-07T14:05:50.414661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'enclose with a bank'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = 'The frog is jumping around the bank of the river'\n",
    "required_word = 'bank'\n",
    "\n",
    "word_tokens = nltk.word_tokenize(bank)\n",
    "filtered_words = []\n",
    "\n",
    "for word in word_tokens:\n",
    "    if word not in stopwords.words('english'):\n",
    "        filtered_words.append(word)\n",
    "\n",
    "\n",
    "max_matches = 0\n",
    "best_sentence = None\n",
    "for word in wordnet.synsets(required_word):\n",
    "    tokenized_sent = nltk.word_tokenize(word.definition())\n",
    "    common_words = set(tokenized_sent).intersection(set(filtered_words))\n",
    "    if (len(common_words) > max_matches):\n",
    "        best_sentence = word\n",
    "        max_matches = len(common_words)\n",
    "\n",
    "best_sentence.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent semantic analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:52.087171Z",
     "start_time": "2019-10-07T14:05:52.077880Z"
    }
   },
   "outputs": [],
   "source": [
    "textCorpus = ['Seven continent planet', 'Five ocean planet', 'Asia largest continet', 'Pacific Ocean largest', 'Ocean saline water']\n",
    "text_tokens = [token.split() for token in textCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:53.844560Z",
     "start_time": "2019-10-07T14:05:53.819396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.6141889663426562\n",
      "  (0, 1)\t0.6141889663426562\n",
      "  (0, 7)\t0.49552379079705033\n",
      "  (1, 7)\t0.5568161504458247\n",
      "  (1, 3)\t0.6901592662889633\n",
      "  (1, 5)\t0.46220770413113277\n",
      "  (2, 0)\t0.6141889663426562\n",
      "  (2, 4)\t0.49552379079705033\n",
      "  (2, 2)\t0.6141889663426562\n",
      "  (3, 5)\t0.46220770413113277\n",
      "  (3, 4)\t0.5568161504458247\n",
      "  (3, 6)\t0.6901592662889633\n",
      "  (4, 5)\t0.42799292268317357\n",
      "  (4, 8)\t0.6390704413963749\n",
      "  (4, 10)\t0.6390704413963749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "transform = TfidfVectorizer()\n",
    "tfidf = transform.fit_transform(textCorpus)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:55.418848Z",
     "start_time": "2019-10-07T14:05:55.416071Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:55.791709Z",
     "start_time": "2019-10-07T14:05:55.622823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.71043068e-01  6.36069088e-01 -5.03448918e-01]\n",
      " [ 6.91226804e-01  4.35823958e-01  2.58982974e-16]\n",
      " [ 3.71043068e-01 -6.36069088e-01 -5.03448918e-01]\n",
      " [ 6.91226804e-01 -4.35823958e-01 -1.78982886e-15]\n",
      " [ 5.32049147e-01 -3.50501861e-15  7.02195396e-01]]\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=3)\n",
    "lsa = svd.fit_transform(tfidf)\n",
    "print(lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:56.120349Z",
     "start_time": "2019-10-07T14:05:56.107212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85208873e-01,  3.58266110e-01, -3.09212770e-01],\n",
       "       [ 1.85208873e-01, -3.58266110e-01, -3.09212770e-01],\n",
       "       [ 1.85208873e-01,  3.58266110e-01, -3.09212770e-01],\n",
       "       [ 3.87708525e-01, -2.75841656e-01, -1.66321233e-15],\n",
       "       [ 4.62226149e-01,  5.11594152e-01, -2.49470916e-01],\n",
       "       [ 7.04370623e-01, -1.10472485e-15,  3.00534660e-01],\n",
       "       [ 3.87708525e-01,  2.75841656e-01,  1.69695375e-15],\n",
       "       [ 4.62226149e-01, -5.11594152e-01, -2.49470916e-01],\n",
       "       [ 2.76335027e-01, -2.24821337e-15,  4.48752322e-01],\n",
       "       [ 1.85208873e-01, -3.58266110e-01, -3.09212770e-01],\n",
       "       [ 2.76335027e-01, -2.24821337e-15,  4.48752322e-01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====> Generate vectors using LSA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=3)\n",
    "svd.fit_transform(tfidf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:56.524112Z",
     "start_time": "2019-10-07T14:05:56.520212Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import os \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:56.704377Z",
     "start_time": "2019-10-07T14:05:56.696615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'like', 'upgrad'],\n",
       " ['Upgrad', 'has', 'good', 'ML', 'program'],\n",
       " ['Upgrad', 'has', 'good', 'faculty'],\n",
       " ['Rahim', 'is', 'that', 'good', 'faculty'],\n",
       " ['I', 'Like', 'ML']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textCorpus = ['I like upgrad', 'Upgrad has good ML program', 'Upgrad has good faculty', 'Rahim is that good faculty', 'I Like ML']\n",
    "text_tokens = [word.split() for word in textCorpus]\n",
    "text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:05:58.716658Z",
     "start_time": "2019-10-07T14:05:58.704684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Word2Vec in module gensim.models.word2vec:\n",
      "\n",
      "class Word2Vec(gensim.models.base_any2vec.BaseWordEmbeddingsModel)\n",
      " |  Word2Vec(sentences=None, corpus_file=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, hashfxn=<built-in function hash>, iter=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=(), max_final_vocab=None)\n",
      " |  \n",
      " |  Train, use and evaluate neural networks described in https://code.google.com/p/word2vec/.\n",
      " |  \n",
      " |  Once you're finished training a model (=no more updates, only querying)\n",
      " |  store and use only the :class:`~gensim.models.keyedvectors.KeyedVectors` instance in `self.wv` to reduce memory.\n",
      " |  \n",
      " |  The model can be stored/loaded via its :meth:`~gensim.models.word2vec.Word2Vec.save` and\n",
      " |  :meth:`~gensim.models.word2vec.Word2Vec.load` methods.\n",
      " |  \n",
      " |  The trained word vectors can also be stored/loaded from a format compatible with the\n",
      " |  original word2vec implementation via `self.wv.save_word2vec_format`\n",
      " |  and :meth:`gensim.models.keyedvectors.KeyedVectors.load_word2vec_format`.\n",
      " |  \n",
      " |  Some important attributes are the following:\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  wv : :class:`~gensim.models.keyedvectors.Word2VecKeyedVectors`\n",
      " |      This object essentially contains the mapping between words and embeddings. After training, it can be used\n",
      " |      directly to query those embeddings in various ways. See the module level docstring for examples.\n",
      " |  \n",
      " |  vocabulary : :class:`~gensim.models.word2vec.Word2VecVocab`\n",
      " |      This object represents the vocabulary (sometimes called Dictionary in gensim) of the model.\n",
      " |      Besides keeping track of all unique words, this object provides extra functionality, such as\n",
      " |      constructing a huffman tree (frequent words are closer to the root), or discarding extremely rare words.\n",
      " |  \n",
      " |  trainables : :class:`~gensim.models.word2vec.Word2VecTrainables`\n",
      " |      This object represents the inner shallow neural network used to train the embeddings. The semantics of the\n",
      " |      network differ slightly in the two available training modes (CBOW or SG) but you can think of it as a NN with\n",
      " |      a single projection and hidden layer which we train on the corpus. The weights are then used as our embeddings\n",
      " |      (which means that the size of the hidden layer is equal to the number of features `self.size`).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Word2Vec\n",
      " |      gensim.models.base_any2vec.BaseWordEmbeddingsModel\n",
      " |      gensim.models.base_any2vec.BaseAny2VecModel\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __contains__(self, word)\n",
      " |      Deprecated. Use `self.wv.__contains__` instead.\n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__contains__`.\n",
      " |  \n",
      " |  __getitem__(self, words)\n",
      " |      Deprecated. Use `self.wv.__getitem__` instead.\n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.__getitem__`.\n",
      " |  \n",
      " |  __init__(self, sentences=None, corpus_file=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, hashfxn=<built-in function hash>, iter=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=(), max_final_vocab=None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of iterables, optional\n",
      " |          The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,\n",
      " |          consider an iterable that streams the sentences directly from disk/network.\n",
      " |          See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`\n",
      " |          or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.\n",
      " |          See also the `tutorial on data streaming in Python\n",
      " |          <https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/>`_.\n",
      " |          If you don't supply `sentences`, the model is left uninitialized -- use if you plan to initialize it\n",
      " |          in some other way.\n",
      " |      corpus_file : str, optional\n",
      " |          Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.\n",
      " |          You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or\n",
      " |          `corpus_file` arguments need to be passed (or none of them, in that case, the model is left uninitialized).\n",
      " |      size : int, optional\n",
      " |          Dimensionality of the word vectors.\n",
      " |      window : int, optional\n",
      " |          Maximum distance between the current and predicted word within a sentence.\n",
      " |      min_count : int, optional\n",
      " |          Ignores all words with total frequency lower than this.\n",
      " |      workers : int, optional\n",
      " |          Use these many worker threads to train the model (=faster training with multicore machines).\n",
      " |      sg : {0, 1}, optional\n",
      " |          Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
      " |      hs : {0, 1}, optional\n",
      " |          If 1, hierarchical softmax will be used for model training.\n",
      " |          If 0, and `negative` is non-zero, negative sampling will be used.\n",
      " |      negative : int, optional\n",
      " |          If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\"\n",
      " |          should be drawn (usually between 5-20).\n",
      " |          If set to 0, no negative sampling is used.\n",
      " |      ns_exponent : float, optional\n",
      " |          The exponent used to shape the negative sampling distribution. A value of 1.0 samples exactly in proportion\n",
      " |          to the frequencies, 0.0 samples all words equally, while a negative value samples low-frequency words more\n",
      " |          than high-frequency words. The popular default value of 0.75 was chosen by the original Word2Vec paper.\n",
      " |          More recently, in https://arxiv.org/abs/1804.04212, Caselles-Dupré, Lesaint, & Royo-Letelier suggest that\n",
      " |          other values may perform better for recommendation applications.\n",
      " |      cbow_mean : {0, 1}, optional\n",
      " |          If 0, use the sum of the context word vectors. If 1, use the mean, only applies when cbow is used.\n",
      " |      alpha : float, optional\n",
      " |          The initial learning rate.\n",
      " |      min_alpha : float, optional\n",
      " |          Learning rate will linearly drop to `min_alpha` as training progresses.\n",
      " |      seed : int, optional\n",
      " |          Seed for the random number generator. Initial vectors for each word are seeded with a hash of\n",
      " |          the concatenation of word + `str(seed)`. Note that for a fully deterministically-reproducible run,\n",
      " |          you must also limit the model to a single worker thread (`workers=1`), to eliminate ordering jitter\n",
      " |          from OS thread scheduling. (In Python 3, reproducibility between interpreter launches also requires\n",
      " |          use of the `PYTHONHASHSEED` environment variable to control hash randomization).\n",
      " |      max_vocab_size : int, optional\n",
      " |          Limits the RAM during vocabulary building; if there are more unique\n",
      " |          words than this, then prune the infrequent ones. Every 10 million word types need about 1GB of RAM.\n",
      " |          Set to `None` for no limit.\n",
      " |      max_final_vocab : int, optional\n",
      " |          Limits the vocab to a target vocab size by automatically picking a matching min_count. If the specified\n",
      " |          min_count is more than the calculated min_count, the specified min_count will be used.\n",
      " |          Set to `None` if not required.\n",
      " |      sample : float, optional\n",
      " |          The threshold for configuring which higher-frequency words are randomly downsampled,\n",
      " |          useful range is (0, 1e-5).\n",
      " |      hashfxn : function, optional\n",
      " |          Hash function to use to randomly initialize weights, for increased training reproducibility.\n",
      " |      iter : int, optional\n",
      " |          Number of iterations (epochs) over the corpus.\n",
      " |      trim_rule : function, optional\n",
      " |          Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,\n",
      " |          be trimmed away, or handled using the default (discard if word count < min_count).\n",
      " |          Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),\n",
      " |          or a callable that accepts parameters (word, count, min_count) and returns either\n",
      " |          :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.\n",
      " |          The rule, if given, is only used to prune vocabulary during build_vocab() and is not stored as part of the\n",
      " |          model.\n",
      " |      \n",
      " |          The input parameters are of the following types:\n",
      " |              * `word` (str) - the word we are examining\n",
      " |              * `count` (int) - the word's frequency count in the corpus\n",
      " |              * `min_count` (int) - the minimum count threshold.\n",
      " |      sorted_vocab : {0, 1}, optional\n",
      " |          If 1, sort the vocabulary by descending frequency before assigning word indexes.\n",
      " |          See :meth:`~gensim.models.word2vec.Word2VecVocab.sort_vocab()`.\n",
      " |      batch_words : int, optional\n",
      " |          Target size (in words) for batches of examples passed to worker threads (and\n",
      " |          thus cython routines).(Larger batches will be passed if individual\n",
      " |          texts are longer than 10000 words, but the standard cython code truncates to that maximum.)\n",
      " |      compute_loss: bool, optional\n",
      " |          If True, computes and stores loss value which can be retrieved using\n",
      " |          :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.\n",
      " |      callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional\n",
      " |          Sequence of callbacks to be executed at specific stages during training.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Initialize and train a :class:`~gensim.models.word2vec.Word2Vec` model\n",
      " |      \n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.models import Word2Vec\n",
      " |          >>> sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
      " |          >>> model = Word2Vec(sentences, min_count=1)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Human readable representation of the model's state.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Human readable representation of the model's state, including the vocabulary size, vector size\n",
      " |          and learning rate.\n",
      " |  \n",
      " |  accuracy(self, questions, restrict_vocab=30000, most_similar=None, case_insensitive=True)\n",
      " |      Deprecated. Use `self.wv.accuracy` instead.\n",
      " |      See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.accuracy`.\n",
      " |  \n",
      " |  clear_sims(self)\n",
      " |      Remove all L2-normalized word vectors from the model, to free up memory.\n",
      " |      \n",
      " |      You can recompute them later again using the :meth:`~gensim.models.word2vec.Word2Vec.init_sims` method.\n",
      " |  \n",
      " |  delete_temporary_training_data(self, replace_word_vectors_with_normalized=False)\n",
      " |      Discard parameters that are used in training and scoring, to save memory.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      Use only if you're sure you're done training a model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      replace_word_vectors_with_normalized : bool, optional\n",
      " |          If True, forget the original (not normalized) word vectors and only keep\n",
      " |          the L2-normalized word vectors, to save even more memory.\n",
      " |  \n",
      " |  get_latest_training_loss(self)\n",
      " |      Get current value of the training loss.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Current training loss.\n",
      " |  \n",
      " |  init_sims(self, replace=False)\n",
      " |      Deprecated. Use `self.wv.init_sims` instead.\n",
      " |      See :meth:`~gensim.models.keyedvectors.Word2VecKeyedVectors.init_sims`.\n",
      " |  \n",
      " |  intersect_word2vec_format(self, fname, lockf=0.0, binary=False, encoding='utf8', unicode_errors='strict')\n",
      " |      Merge in an input-hidden weight matrix loaded from the original C word2vec-tool format,\n",
      " |      where it intersects with the current vocabulary.\n",
      " |      \n",
      " |      No words are added to the existing vocabulary, but intersecting words adopt the file's weights, and\n",
      " |      non-intersecting words are left alone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          The file path to load the vectors from.\n",
      " |      lockf : float, optional\n",
      " |          Lock-factor value to be set for any imported word-vectors; the\n",
      " |          default value of 0.0 prevents further updating of the vector during subsequent\n",
      " |          training. Use 1.0 to allow further training updates of merged vectors.\n",
      " |      binary : bool, optional\n",
      " |          If True, `fname` is in the binary word2vec C format.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of `text` for `unicode` function (python2 only).\n",
      " |      unicode_errors : str, optional\n",
      " |          Error handling behaviour, used as parameter for `unicode` function (python2 only).\n",
      " |  \n",
      " |  predict_output_word(self, context_words_list, topn=10)\n",
      " |      Get the probability distribution of the center word given context words.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      context_words_list : list of str\n",
      " |          List of context words.\n",
      " |      topn : int, optional\n",
      " |          Return `topn` words and their probabilities.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          `topn` length list of tuples of (word, probability).\n",
      " |  \n",
      " |  reset_from(self, other_model)\n",
      " |      Borrow shareable pre-built structures from `other_model` and reset hidden layer weights.\n",
      " |      \n",
      " |      Structures copied are:\n",
      " |          * Vocabulary\n",
      " |          * Index to word mapping\n",
      " |          * Cumulative frequency table (used for negative sampling)\n",
      " |          * Cached corpus length\n",
      " |      \n",
      " |      Useful when testing multiple models on the same corpus in parallel.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other_model : :class:`~gensim.models.word2vec.Word2Vec`\n",
      " |          Another model to copy the internal structures from.\n",
      " |  \n",
      " |  save(self, *args, **kwargs)\n",
      " |      Save the model.\n",
      " |      This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports\n",
      " |      online training and getting vectors for vocabulary words.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the file.\n",
      " |  \n",
      " |  save_word2vec_format(self, fname, fvocab=None, binary=False)\n",
      " |      Deprecated. Use `model.wv.save_word2vec_format` instead.\n",
      " |      See :meth:`gensim.models.KeyedVectors.save_word2vec_format`.\n",
      " |  \n",
      " |  score(self, sentences, total_sentences=1000000, chunksize=100, queue_factor=2, report_delay=1)\n",
      " |      Score the log probability for a sequence of sentences.\n",
      " |      This does not change the fitted model in any way (see :meth:`~gensim.models.word2vec.Word2Vec.train` for that).\n",
      " |      \n",
      " |      Gensim has currently only implemented score for the hierarchical softmax scheme,\n",
      " |      so you need to have run word2vec with `hs=1` and `negative=0` for this to work.\n",
      " |      \n",
      " |      Note that you should specify `total_sentences`; you'll run into problems if you ask to\n",
      " |      score more than this number of sentences but it is inefficient to set the value too high.\n",
      " |      \n",
      " |      See the `article by Matt Taddy: \"Document Classification by Inversion of Distributed Language Representations\"\n",
      " |      <https://arxiv.org/pdf/1504.07295.pdf>`_ and the\n",
      " |      `gensim demo <https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb>`_ for examples of\n",
      " |      how to use such scores in document classification.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,\n",
      " |          consider an iterable that streams the sentences directly from disk/network.\n",
      " |          See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`\n",
      " |          or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.\n",
      " |      total_sentences : int, optional\n",
      " |          Count of sentences.\n",
      " |      chunksize : int, optional\n",
      " |          Chunksize of jobs\n",
      " |      queue_factor : int, optional\n",
      " |          Multiplier for size of queue (number of workers * queue_factor).\n",
      " |      report_delay : float, optional\n",
      " |          Seconds to wait before reporting progress.\n",
      " |  \n",
      " |  train(self, sentences=None, corpus_file=None, total_examples=None, total_words=None, epochs=None, start_alpha=None, end_alpha=None, word_count=0, queue_factor=2, report_delay=1.0, compute_loss=False, callbacks=())\n",
      " |      Update the model's neural weights from a sequence of sentences.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To support linear learning-rate decay from (initial) `alpha` to `min_alpha`, and accurate\n",
      " |      progress-percentage logging, either `total_examples` (count of sentences) or `total_words` (count of\n",
      " |      raw words in sentences) **MUST** be provided. If `sentences` is the same corpus\n",
      " |      that was provided to :meth:`~gensim.models.word2vec.Word2Vec.build_vocab` earlier,\n",
      " |      you can simply use `total_examples=self.corpus_count`.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      To avoid common mistakes around the model's ability to do multiple training passes itself, an\n",
      " |      explicit `epochs` argument **MUST** be provided. In the common and recommended case\n",
      " |      where :meth:`~gensim.models.word2vec.Word2Vec.train` is only called once, you can set `epochs=self.iter`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          The `sentences` iterable can be simply a list of lists of tokens, but for larger corpora,\n",
      " |          consider an iterable that streams the sentences directly from disk/network.\n",
      " |          See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`\n",
      " |          or :class:`~gensim.models.word2vec.LineSentence` in :mod:`~gensim.models.word2vec` module for such examples.\n",
      " |          See also the `tutorial on data streaming in Python\n",
      " |          <https://rare-technologies.com/data-streaming-in-python-generators-iterators-iterables/>`_.\n",
      " |      corpus_file : str, optional\n",
      " |          Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.\n",
      " |          You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or\n",
      " |          `corpus_file` arguments need to be passed (not both of them).\n",
      " |      total_examples : int\n",
      " |          Count of sentences.\n",
      " |      total_words : int\n",
      " |          Count of raw words in sentences.\n",
      " |      epochs : int\n",
      " |          Number of iterations (epochs) over the corpus.\n",
      " |      start_alpha : float, optional\n",
      " |          Initial learning rate. If supplied, replaces the starting `alpha` from the constructor,\n",
      " |          for this one call to`train()`.\n",
      " |          Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself\n",
      " |          (not recommended).\n",
      " |      end_alpha : float, optional\n",
      " |          Final learning rate. Drops linearly from `start_alpha`.\n",
      " |          If supplied, this replaces the final `min_alpha` from the constructor, for this one call to `train()`.\n",
      " |          Use only if making multiple calls to `train()`, when you want to manage the alpha learning-rate yourself\n",
      " |          (not recommended).\n",
      " |      word_count : int, optional\n",
      " |          Count of words already trained. Set this to 0 for the usual\n",
      " |          case of training on all words in sentences.\n",
      " |      queue_factor : int, optional\n",
      " |          Multiplier for size of queue (number of workers * queue_factor).\n",
      " |      report_delay : float, optional\n",
      " |          Seconds to wait before reporting progress.\n",
      " |      compute_loss: bool, optional\n",
      " |          If True, computes and stores loss value which can be retrieved using\n",
      " |          :meth:`~gensim.models.word2vec.Word2Vec.get_latest_training_loss`.\n",
      " |      callbacks : iterable of :class:`~gensim.models.callbacks.CallbackAny2Vec`, optional\n",
      " |          Sequence of callbacks to be executed at specific stages during training.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.models import Word2Vec\n",
      " |          >>> sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
      " |          >>>\n",
      " |          >>> model = Word2Vec(min_count=1)\n",
      " |          >>> model.build_vocab(sentences)  # prepare the model vocabulary\n",
      " |          >>> model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n",
      " |          (1, 30)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(*args, **kwargs) from builtins.type\n",
      " |      Load a previously saved :class:`~gensim.models.word2vec.Word2Vec` model.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.word2vec.Word2Vec.save`\n",
      " |          Save model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the saved file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`~gensim.models.word2vec.Word2Vec`\n",
      " |          Loaded model.\n",
      " |  \n",
      " |  load_word2vec_format(fname, fvocab=None, binary=False, encoding='utf8', unicode_errors='strict', limit=None, datatype=<class 'numpy.float32'>) from builtins.type\n",
      " |      Deprecated. Use :meth:`gensim.models.KeyedVectors.load_word2vec_format` instead.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  log_accuracy(section)\n",
      " |      Deprecated. Use `self.wv.log_accuracy` instead.\n",
      " |      See :meth:`~gensim.models.word2vec.Word2VecKeyedVectors.log_accuracy`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.base_any2vec.BaseWordEmbeddingsModel:\n",
      " |  \n",
      " |  build_vocab(self, sentences=None, corpus_file=None, update=False, progress_per=10000, keep_raw_vocab=False, trim_rule=None, **kwargs)\n",
      " |      Build vocabulary from a sequence of sentences (can be a once-only generator stream).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sentences : iterable of list of str\n",
      " |          Can be simply a list of lists of tokens, but for larger corpora,\n",
      " |          consider an iterable that streams the sentences directly from disk/network.\n",
      " |          See :class:`~gensim.models.word2vec.BrownCorpus`, :class:`~gensim.models.word2vec.Text8Corpus`\n",
      " |          or :class:`~gensim.models.word2vec.LineSentence` module for such examples.\n",
      " |      corpus_file : str, optional\n",
      " |          Path to a corpus file in :class:`~gensim.models.word2vec.LineSentence` format.\n",
      " |          You may use this argument instead of `sentences` to get performance boost. Only one of `sentences` or\n",
      " |          `corpus_file` arguments need to be passed (not both of them).\n",
      " |      update : bool\n",
      " |          If true, the new words in `sentences` will be added to model's vocab.\n",
      " |      progress_per : int, optional\n",
      " |          Indicates how many words to process before showing/updating the progress.\n",
      " |      keep_raw_vocab : bool, optional\n",
      " |          If False, the raw vocabulary will be deleted after the scaling is done to free up RAM.\n",
      " |      trim_rule : function, optional\n",
      " |          Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,\n",
      " |          be trimmed away, or handled using the default (discard if word count < min_count).\n",
      " |          Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),\n",
      " |          or a callable that accepts parameters (word, count, min_count) and returns either\n",
      " |          :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.\n",
      " |          The rule, if given, is only used to prune vocabulary during current method call and is not stored as part\n",
      " |          of the model.\n",
      " |      \n",
      " |          The input parameters are of the following types:\n",
      " |              * `word` (str) - the word we are examining\n",
      " |              * `count` (int) - the word's frequency count in the corpus\n",
      " |              * `min_count` (int) - the minimum count threshold.\n",
      " |      \n",
      " |      **kwargs : object\n",
      " |          Key word arguments propagated to `self.vocabulary.prepare_vocab`\n",
      " |  \n",
      " |  build_vocab_from_freq(self, word_freq, keep_raw_vocab=False, corpus_count=None, trim_rule=None, update=False)\n",
      " |      Build vocabulary from a dictionary of word frequencies.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      word_freq : dict of (str, int)\n",
      " |          A mapping from a word in the vocabulary to its frequency count.\n",
      " |      keep_raw_vocab : bool, optional\n",
      " |          If False, delete the raw vocabulary after the scaling is done to free up RAM.\n",
      " |      corpus_count : int, optional\n",
      " |          Even if no corpus is provided, this argument can set corpus_count explicitly.\n",
      " |      trim_rule : function, optional\n",
      " |          Vocabulary trimming rule, specifies whether certain words should remain in the vocabulary,\n",
      " |          be trimmed away, or handled using the default (discard if word count < min_count).\n",
      " |          Can be None (min_count will be used, look to :func:`~gensim.utils.keep_vocab_item`),\n",
      " |          or a callable that accepts parameters (word, count, min_count) and returns either\n",
      " |          :attr:`gensim.utils.RULE_DISCARD`, :attr:`gensim.utils.RULE_KEEP` or :attr:`gensim.utils.RULE_DEFAULT`.\n",
      " |          The rule, if given, is only used to prune vocabulary during current method call and is not stored as part\n",
      " |          of the model.\n",
      " |      \n",
      " |          The input parameters are of the following types:\n",
      " |              * `word` (str) - the word we are examining\n",
      " |              * `count` (int) - the word's frequency count in the corpus\n",
      " |              * `min_count` (int) - the minimum count threshold.\n",
      " |      \n",
      " |      update : bool, optional\n",
      " |          If true, the new provided words in `word_freq` dict will be added to model's vocab.\n",
      " |  \n",
      " |  doesnt_match(self, words)\n",
      " |      Deprecated, use self.wv.doesnt_match() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.doesnt_match`.\n",
      " |  \n",
      " |  estimate_memory(self, vocab_size=None, report=None)\n",
      " |      Estimate required memory for a model using current settings and provided vocabulary size.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      vocab_size : int, optional\n",
      " |          Number of unique tokens in the vocabulary\n",
      " |      report : dict of (str, int), optional\n",
      " |          A dictionary from string representations of the model's memory consuming members to their size in bytes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict of (str, int)\n",
      " |          A dictionary from string representations of the model's memory consuming members to their size in bytes.\n",
      " |  \n",
      " |  evaluate_word_pairs(self, pairs, delimiter='\\t', restrict_vocab=300000, case_insensitive=True, dummy4unknown=False)\n",
      " |      Deprecated, use self.wv.evaluate_word_pairs() instead.\n",
      " |      \n",
      " |      Refer to the documentation for\n",
      " |      :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.evaluate_word_pairs`.\n",
      " |  \n",
      " |  most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None)\n",
      " |      Deprecated, use self.wv.most_similar() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n",
      " |  \n",
      " |  most_similar_cosmul(self, positive=None, negative=None, topn=10)\n",
      " |      Deprecated, use self.wv.most_similar_cosmul() instead.\n",
      " |      \n",
      " |      Refer to the documentation for\n",
      " |      :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar_cosmul`.\n",
      " |  \n",
      " |  n_similarity(self, ws1, ws2)\n",
      " |      Deprecated, use self.wv.n_similarity() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.n_similarity`.\n",
      " |  \n",
      " |  similar_by_vector(self, vector, topn=10, restrict_vocab=None)\n",
      " |      Deprecated, use self.wv.similar_by_vector() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similar_by_vector`.\n",
      " |  \n",
      " |  similar_by_word(self, word, topn=10, restrict_vocab=None)\n",
      " |      Deprecated, use self.wv.similar_by_word() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similar_by_word`.\n",
      " |  \n",
      " |  similarity(self, w1, w2)\n",
      " |      Deprecated, use self.wv.similarity() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similarity`.\n",
      " |  \n",
      " |  wmdistance(self, document1, document2)\n",
      " |      Deprecated, use self.wv.wmdistance() instead.\n",
      " |      \n",
      " |      Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.wmdistance`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.models.base_any2vec.BaseWordEmbeddingsModel:\n",
      " |  \n",
      " |  cum_table\n",
      " |  \n",
      " |  hashfxn\n",
      " |  \n",
      " |  iter\n",
      " |  \n",
      " |  layer1_size\n",
      " |  \n",
      " |  min_count\n",
      " |  \n",
      " |  sample\n",
      " |  \n",
      " |  syn0_lockf\n",
      " |  \n",
      " |  syn1\n",
      " |  \n",
      " |  syn1neg\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:06:01.176550Z",
     "start_time": "2019-10-07T14:06:01.156387Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_tokens, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:06:01.326849Z",
     "start_time": "2019-10-07T14:06:01.310282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.9016900e-04, -2.3255458e-03,  7.9922710e-04, -1.9906370e-03,\n",
       "       -3.8045424e-03, -1.0349287e-03, -2.0592397e-03, -1.0386542e-03,\n",
       "        4.5100539e-03,  2.3329158e-03,  1.3752882e-03, -1.0890745e-03,\n",
       "        7.4144331e-04,  4.5908676e-03,  1.5138037e-04, -8.0088421e-04,\n",
       "       -4.0086061e-03,  2.7947056e-03, -1.0998478e-03, -3.3366804e-03,\n",
       "        1.4677966e-03, -1.3990870e-03,  2.8503179e-03,  5.7581684e-04,\n",
       "        3.2518194e-03, -4.7584954e-03,  8.6941366e-04, -1.6225907e-03,\n",
       "       -5.2219268e-04,  4.1860770e-03, -2.9238532e-03,  1.9478005e-03,\n",
       "       -3.1681650e-03, -3.6915122e-03,  3.0447270e-03,  3.3798758e-03,\n",
       "       -4.5306035e-03, -1.5462940e-03,  2.2010433e-03,  1.8488319e-03,\n",
       "        8.6296775e-04,  4.7532353e-03,  1.9862321e-03, -2.7291540e-03,\n",
       "       -2.9069136e-03, -4.7538625e-03, -1.5203880e-04,  3.5707874e-03,\n",
       "        2.1648204e-03, -2.6271495e-03, -1.6718570e-03, -5.4842670e-04,\n",
       "       -1.3767561e-03,  4.8176730e-03,  2.1368430e-03,  1.9623698e-03,\n",
       "        4.2849523e-03, -1.5954577e-03,  3.4439147e-03,  2.9173463e-03,\n",
       "        3.3561420e-03,  3.7195841e-03, -3.6750210e-03, -2.6625355e-03,\n",
       "        4.5028506e-03, -1.7104564e-03, -1.4863684e-03, -2.8983911e-03,\n",
       "        3.7304831e-03, -1.6765512e-04, -4.5237193e-04, -1.3008933e-03,\n",
       "        2.9750206e-03,  1.4604753e-03, -3.2266011e-03, -9.3047402e-04,\n",
       "        1.7295311e-03,  2.4511418e-03, -3.9007636e-03,  2.6945660e-03,\n",
       "       -4.4709928e-03,  2.7636301e-03, -4.7827582e-03,  4.1033751e-03,\n",
       "        1.1198861e-03,  1.1490178e-03, -1.1706934e-03, -1.8249919e-03,\n",
       "       -6.1835052e-04,  3.1108649e-03,  2.3276664e-03, -2.4692616e-03,\n",
       "        4.7342852e-03, -2.4535682e-03, -4.7056540e-03, -8.2424231e-05,\n",
       "       -3.5869475e-03,  1.7798850e-03,  3.6912127e-03, -2.5275813e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['Upgrad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:06:01.497420Z",
     "start_time": "2019-10-07T14:06:01.482723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 0.19310399889945984),\n",
       " ('Like', 0.17624276876449585),\n",
       " ('I', 0.15665806829929352),\n",
       " ('upgrad', 0.11086973547935486),\n",
       " ('good', 0.08089747279882431),\n",
       " ('that', 0.07270504534244537),\n",
       " ('program', 0.06846922636032104),\n",
       " ('Upgrad', 0.06559135019779205),\n",
       " ('has', 0.007857931777834892),\n",
       " ('is', -0.024154655635356903)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['faculty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic regularities captured: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:10:06.577457Z",
     "start_time": "2019-10-07T14:10:06.571096Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====> import text8 file\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "URL = (\"http://mattmahoney.net/dc/text8.zip\")\n",
    "ARCHIVE_NAME = \"text8.zip\"\n",
    "\n",
    "def download_text8(target_dir=None):\n",
    "    if (target_dir == None):\n",
    "        target_dir = os.path.join('~', 'GENSIM_DATA')\n",
    "    target_dir = os.path.expanduser(target_dir)\n",
    "    archive_path = os.path.join(target_dir, ARCHIVE_NAME)\n",
    "    opener = urlopen(URL)\n",
    "    with open(archive_path, 'wb') as f:\n",
    "        f.write(opener.read())\n",
    "    return archive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:12:35.884201Z",
     "start_time": "2019-10-07T14:10:06.945337Z"
    }
   },
   "outputs": [],
   "source": [
    "text_path = download_text8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:14:08.869877Z",
     "start_time": "2019-10-07T14:14:08.864871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/GENSIM_DATA/text8'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('~', 'GENSIM_DATA/text8')\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:30.689921Z",
     "start_time": "2019-10-07T14:14:10.965097Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Text8Corpus\n",
    "sentences = Text8Corpus(file_path)\n",
    "model = Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:35.415360Z",
     "start_time": "2019-10-07T14:15:35.324717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conference', 0.7008732557296753),\n",
       " ('meetings', 0.6858977675437927),\n",
       " ('synod', 0.6343523263931274),\n",
       " ('ceremony', 0.6189403533935547),\n",
       " ('commencement', 0.6130998134613037),\n",
       " ('session', 0.5983527898788452),\n",
       " ('signing', 0.5911296606063843),\n",
       " ('council', 0.5836823582649231),\n",
       " ('convened', 0.5833077430725098),\n",
       " ('consultation', 0.5770002603530884)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('meeting', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:38.446082Z",
     "start_time": "2019-10-07T14:15:38.435313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('princess', 0.7493656873703003),\n",
       " ('elizabeth', 0.7343113422393799),\n",
       " ('king', 0.7300397753715515),\n",
       " ('prince', 0.7217133045196533),\n",
       " ('crown', 0.680674135684967),\n",
       " ('mary', 0.6589072942733765),\n",
       " ('duchess', 0.6387004852294922),\n",
       " ('consort', 0.6315656900405884),\n",
       " ('lord', 0.619235634803772),\n",
       " ('regent', 0.601592481136322)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:38.829913Z",
     "start_time": "2019-10-07T14:15:38.816208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7793024 , -0.08686993,  0.05973373,  0.8296694 ,  1.0673525 ,\n",
       "        0.6825147 , -2.6039577 , -0.9617494 ,  2.1265035 ,  2.021424  ,\n",
       "       -0.7878816 , -1.0467973 , -0.25066805, -1.2110091 , -1.0155547 ,\n",
       "        2.0126743 ,  1.0562001 ,  0.16806504, -0.48078135, -2.60769   ,\n",
       "       -2.1377425 , -2.2145221 , -0.9791996 ,  1.8623862 ,  0.9964132 ,\n",
       "        2.771474  ,  3.2287319 ,  2.1624627 , -0.17795558,  1.808069  ,\n",
       "        2.2993567 ,  1.4123621 , -2.9134448 ,  0.4351304 , -1.9103515 ,\n",
       "       -1.7319393 ,  1.9761266 , -0.7054211 , -1.593311  ,  0.5179413 ,\n",
       "        1.2081876 , -1.0439299 , -0.5596501 , -0.05837123,  3.954224  ,\n",
       "       -0.24699713,  0.44069588,  0.36978066, -0.445647  , -3.1470726 ,\n",
       "        0.53335774, -2.361012  ,  1.8392905 , -1.0730633 , -2.7907526 ,\n",
       "        0.65891016,  0.85158145, -2.1961365 , -0.92812115,  1.5950416 ,\n",
       "        3.2410078 , -0.9457627 ,  1.9473404 , -0.5016214 , -1.809664  ,\n",
       "        1.2236012 ,  0.8327048 , -1.4688836 ,  0.3337162 ,  1.4183792 ,\n",
       "        3.7013433 ,  1.0902094 , -1.7343992 ,  1.6461427 , -1.028607  ,\n",
       "        1.6156462 , -1.2018162 , -2.1624532 ,  0.66628695,  0.6398166 ,\n",
       "       -0.70573264, -2.9377553 , -2.431352  ,  1.3230377 , -0.7608292 ,\n",
       "        0.19383484,  0.79869837, -0.02122318, -1.1258469 ,  1.252109  ,\n",
       "       -1.5726867 ,  0.83681774,  0.6199563 ,  1.8838803 , -0.3813873 ,\n",
       "       -1.4247538 , -0.14595962, -0.9082962 ,  0.9983052 , -0.24008438],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:39.633739Z",
     "start_time": "2019-10-07T14:15:39.628099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8176899"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.n_similarity('meeting', 'conference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:41.697997Z",
     "start_time": "2019-10-07T14:15:41.686311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.693665623664856),\n",
       " ('princess', 0.6304328441619873),\n",
       " ('prince', 0.6225016713142395),\n",
       " ('emperor', 0.6130492091178894),\n",
       " ('elizabeth', 0.5962637066841125),\n",
       " ('empress', 0.589701771736145),\n",
       " ('daughter', 0.5871102213859558),\n",
       " ('throne', 0.5866202116012573),\n",
       " ('isabella', 0.5824654698371887),\n",
       " ('sigismund', 0.5815116763114929)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:44.992173Z",
     "start_time": "2019-10-07T14:15:44.731888Z"
    }
   },
   "outputs": [],
   "source": [
    "X = model.wv[model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:45.817527Z",
     "start_time": "2019-10-07T14:15:45.814396Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:47.401823Z",
     "start_time": "2019-10-07T14:15:47.173434Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===> Dimentionality reduction: \n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:48.548620Z",
     "start_time": "2019-10-07T14:15:48.475924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.17884546518325806, 3.364095687866211],\n",
       " [0.47161903977394104, 1.5211131572723389],\n",
       " [2.4206490516662598, 1.6706243753433228],\n",
       " [3.1224095821380615, 1.1520317792892456],\n",
       " [3.819544553756714, 2.7863662242889404],\n",
       " [1.3855223655700684, 2.7853405475616455],\n",
       " [3.006835699081421, 3.8315699100494385],\n",
       " [-0.27320271730422974, 1.6022394895553589],\n",
       " [5.92889928817749, -1.713295817375183],\n",
       " [0.13107581436634064, 6.263754844665527],\n",
       " [-0.5776327848434448, 2.1274051666259766],\n",
       " [1.7360249757766724, 1.35951566696167],\n",
       " [3.3366971015930176, 1.4974778890609741],\n",
       " [1.3452961444854736, 0.8214448690414429],\n",
       " [-0.3061221241950989, -0.04256567358970642],\n",
       " [2.1723644733428955, 2.8293800354003906],\n",
       " [-0.4424193501472473, 0.09584108740091324],\n",
       " [-2.0224688053131104, 1.051672339439392],\n",
       " [-1.5603885650634766, 5.156474590301514],\n",
       " [0.638089656829834, 1.1929854154586792],\n",
       " [-0.6004152894020081, -1.1005496978759766],\n",
       " [-0.09515862911939621, 0.01291870791465044],\n",
       " [-4.692727565765381, 2.5815532207489014],\n",
       " [1.0224828720092773, 0.63971346616745],\n",
       " [4.6739301681518555, 0.17813687026500702],\n",
       " [3.921980142593384, 2.812973976135254],\n",
       " [0.5810973048210144, 2.5326576232910156],\n",
       " [0.5064824223518372, 0.458499014377594],\n",
       " [5.274459362030029, 2.4591665267944336],\n",
       " [4.124165058135986, 3.9551000595092773],\n",
       " [3.934584856033325, 0.7922143936157227],\n",
       " [7.709751605987549, 4.064001083374023],\n",
       " [1.6068122386932373, 4.373524188995361],\n",
       " [6.020544052124023, 4.0796732902526855],\n",
       " [1.0800870656967163, 3.433884382247925],\n",
       " [5.369598388671875, 1.2477127313613892],\n",
       " [1.2833937406539917, 1.3639246225357056],\n",
       " [1.9096282720565796, 5.650880813598633],\n",
       " [0.8720089197158813, 5.247520446777344],\n",
       " [5.187049388885498, 2.532090425491333],\n",
       " [4.123606204986572, 2.5070559978485107],\n",
       " [2.2042219638824463, 1.0308696031570435],\n",
       " [2.6441729068756104, 3.7234857082366943],\n",
       " [1.975608229637146, 3.3015780448913574],\n",
       " [2.5306551456451416, 0.1850089728832245],\n",
       " [6.498416423797607, 1.2806097269058228],\n",
       " [2.1980504989624023, -0.37043580412864685],\n",
       " [-0.5362175703048706, 1.21816885471344],\n",
       " [4.215155601501465, 4.211231708526611],\n",
       " [5.733479976654053, 1.4204457998275757],\n",
       " [-0.6274285912513733, 3.2252583503723145],\n",
       " [3.187699317932129, -0.2484305053949356],\n",
       " [3.424345016479492, -0.742808997631073],\n",
       " [0.9283749461174011, 1.777371883392334],\n",
       " [-0.6908212900161743, 1.2905988693237305],\n",
       " [5.309444427490234, 3.223195791244507],\n",
       " [-0.07278679311275482, 0.14231599867343903],\n",
       " [-3.9044501781463623, 5.013477325439453],\n",
       " [-3.924591064453125, 3.4189748764038086],\n",
       " [-5.317776679992676, 4.847317695617676],\n",
       " [1.4080767631530762, 8.862780570983887],\n",
       " [0.5503956079483032, 4.327919960021973],\n",
       " [5.002445697784424, 6.750282287597656],\n",
       " [-2.404773235321045, 7.40157413482666],\n",
       " [7.716136455535889, 0.6253376007080078],\n",
       " [2.2850451469421387, 0.9261614084243774],\n",
       " [5.184555530548096, 3.1459290981292725],\n",
       " [7.00806188583374, 2.2195215225219727],\n",
       " [-1.6766525506973267, 4.784879207611084],\n",
       " [3.0018272399902344, 2.723527193069458],\n",
       " [3.8735499382019043, 2.4452097415924072],\n",
       " [3.785635471343994, 0.7577469348907471],\n",
       " [2.639310359954834, 2.663198709487915],\n",
       " [4.574460029602051, 3.7140467166900635],\n",
       " [5.804874897003174, 2.921243667602539],\n",
       " [3.069371223449707, -0.9680689573287964],\n",
       " [4.378714084625244, 0.4874420464038849],\n",
       " [3.7880842685699463, 5.861298084259033],\n",
       " [2.8143889904022217, 5.089799880981445],\n",
       " [-0.3708200752735138, 3.42518949508667],\n",
       " [3.0994927883148193, 0.7740480899810791],\n",
       " [0.8664694428443909, 3.758256673812866],\n",
       " [3.1783740520477295, 7.210398197174072],\n",
       " [3.170877695083618, 2.548287868499756],\n",
       " [2.173121452331543, 5.3865065574646],\n",
       " [0.13580501079559326, 1.4055430889129639],\n",
       " [4.5279669761657715, 3.0355541706085205],\n",
       " [7.5112528800964355, 0.5610520243644714],\n",
       " [5.059614181518555, 0.9467310905456543],\n",
       " [6.600956439971924, 4.37335729598999],\n",
       " [2.7732419967651367, 0.9905336499214172],\n",
       " [0.35196226835250854, 1.0521602630615234],\n",
       " [0.2133006602525711, 0.3806799650192261],\n",
       " [4.610416412353516, 0.2306564450263977],\n",
       " [-0.0916842445731163, 0.10825759172439575],\n",
       " [4.469245433807373, 3.8202226161956787],\n",
       " [4.897426605224609, 2.333585023880005],\n",
       " [0.012498029507696629, -0.13191302120685577],\n",
       " [1.5601108074188232, 5.308714389801025],\n",
       " [2.249953508377075, 3.2263286113739014],\n",
       " [0.9133130311965942, 3.4461493492126465],\n",
       " [6.644826412200928, -0.1661125123500824],\n",
       " [0.9388107061386108, 1.3318885564804077],\n",
       " [4.498828411102295, 8.43605899810791],\n",
       " [2.879377603530884, 7.067656517028809],\n",
       " [2.4558186531066895, -0.68433678150177],\n",
       " [1.425234079360962, 3.722165584564209],\n",
       " [2.0751686096191406, 3.9851949214935303],\n",
       " [0.8319674730300903, 2.33583927154541],\n",
       " [0.4162749946117401, 3.662151575088501],\n",
       " [6.22902774810791, 5.772894382476807],\n",
       " [2.4802603721618652, 3.679598808288574],\n",
       " [2.3386781215667725, 5.111608982086182],\n",
       " [1.103952169418335, 2.7514450550079346],\n",
       " [2.596316337585449, 2.269679546356201],\n",
       " [5.8608293533325195, -0.6768622994422913],\n",
       " [3.016954183578491, 2.0078296661376953],\n",
       " [0.1597292721271515, 0.5660002827644348],\n",
       " [5.0723042488098145, 3.8611462116241455],\n",
       " [2.344214677810669, 5.52864408493042],\n",
       " [1.6977282762527466, 1.4230926036834717],\n",
       " [3.5415143966674805, 2.0538437366485596],\n",
       " [3.8268468379974365, 3.915884017944336],\n",
       " [4.038300514221191, 4.429575443267822],\n",
       " [2.2579662799835205, 1.8923897743225098],\n",
       " [5.307230472564697, 1.0323729515075684],\n",
       " [2.6387341022491455, 1.5129776000976562],\n",
       " [-1.8590353727340698, 3.2009079456329346],\n",
       " [4.64756441116333, 1.9969185590744019],\n",
       " [2.4655802249908447, 1.861619472503662],\n",
       " [7.081356525421143, 1.3600659370422363],\n",
       " [3.9424893856048584, 1.2334264516830444],\n",
       " [3.089400291442871, 2.329669713973999],\n",
       " [2.0694234371185303, 1.0790241956710815],\n",
       " [4.6303887367248535, 5.145212650299072],\n",
       " [1.7366430759429932, 3.4573700428009033],\n",
       " [1.6737109422683716, 2.3867573738098145],\n",
       " [-0.7973843812942505, 4.485919952392578],\n",
       " [-0.014278477057814598, 2.0942115783691406],\n",
       " [0.0242791585624218, 1.6872137784957886],\n",
       " [-0.9391138553619385, 0.4817652106285095],\n",
       " [1.5655863285064697, 2.562122106552124],\n",
       " [4.4551239013671875, 5.896811008453369],\n",
       " [0.591277003288269, 3.147768259048462],\n",
       " [-0.618888795375824, -0.8204329013824463],\n",
       " [-0.5086702704429626, 2.47776460647583],\n",
       " [5.331453323364258, 2.4863674640655518],\n",
       " [-1.743513584136963, 3.73264217376709],\n",
       " [0.5637035965919495, 4.195363998413086],\n",
       " [1.5313549041748047, 1.5891023874282837],\n",
       " [3.55991268157959, 4.901522636413574],\n",
       " [1.0576152801513672, 2.007483720779419],\n",
       " [3.3963782787323, 2.4499120712280273],\n",
       " [-1.4285157918930054, 0.8845158219337463],\n",
       " [0.6768310070037842, 2.7627203464508057],\n",
       " [-3.143653154373169, -1.412588119506836],\n",
       " [-0.47182008624076843, -0.18056173622608185],\n",
       " [1.2752169370651245, -1.9334421157836914],\n",
       " [2.000438928604126, 5.040318965911865],\n",
       " [0.31706157326698303, 1.0170129537582397],\n",
       " [1.5974246263504028, 0.8657827973365784],\n",
       " [1.1382659673690796, 2.2360405921936035],\n",
       " [0.9600332379341125, 5.583130836486816],\n",
       " [1.6631786823272705, 0.5648056864738464],\n",
       " [2.8967502117156982, 5.460049629211426],\n",
       " [-0.9494109153747559, 1.3889667987823486],\n",
       " [1.8705934286117554, 6.517467021942139],\n",
       " [-0.08269692212343216, 5.2155046463012695],\n",
       " [4.983147144317627, 1.9659162759780884],\n",
       " [6.394029140472412, 2.3418171405792236],\n",
       " [5.09371280670166, 2.4355621337890625],\n",
       " [-8.023154258728027, -0.42466434836387634],\n",
       " [-1.3589129447937012, 0.45365142822265625],\n",
       " [1.311692237854004, 4.410594463348389],\n",
       " [-0.8218432068824768, 0.7667533159255981],\n",
       " [3.8349390029907227, 0.5775437951087952],\n",
       " [2.452486276626587, 3.8897271156311035],\n",
       " [-0.28744325041770935, 0.927434504032135],\n",
       " [0.29042118787765503, 2.2161519527435303],\n",
       " [-0.07261978089809418, 4.3183274269104],\n",
       " [2.0588715076446533, 0.16872040927410126],\n",
       " [4.5790696144104, -1.0939239263534546],\n",
       " [-0.7911146879196167, 0.15001855790615082],\n",
       " [-0.7766253352165222, 0.35221514105796814],\n",
       " [-0.24035610258579254, 0.10628097504377365],\n",
       " [-0.6477559208869934, 1.8531944751739502],\n",
       " [-1.2621430158615112, 1.0714519023895264],\n",
       " [-0.19990214705467224, 0.21231767535209656],\n",
       " [4.419559955596924, 3.5007078647613525],\n",
       " [1.4809609651565552, 5.903451919555664],\n",
       " [-0.10757335275411606, 0.24738332629203796],\n",
       " [-4.333855628967285, 4.592296123504639],\n",
       " [0.7964701056480408, 7.452887535095215],\n",
       " [4.002994537353516, 5.438833713531494],\n",
       " [7.179422378540039, 3.7710070610046387],\n",
       " [-0.17319323122501373, 1.4870356321334839],\n",
       " [-3.8668041229248047, 0.036156073212623596],\n",
       " [-4.41930627822876, -0.747067391872406],\n",
       " [-3.126270294189453, 1.6837998628616333],\n",
       " [-1.7835123538970947, 3.0033745765686035],\n",
       " [1.7777249813079834, 5.391156196594238],\n",
       " [4.642093658447266, 0.16286753118038177],\n",
       " [3.243166923522949, 2.957627058029175],\n",
       " [2.143758535385132, 8.62633991241455],\n",
       " [-0.23076003789901733, 0.34403714537620544],\n",
       " [2.100045680999756, 1.1419267654418945],\n",
       " [-3.1080241203308105, -0.6398426294326782],\n",
       " [-3.6937596797943115, -0.6596878170967102],\n",
       " [-2.13814377784729, 3.9663774967193604],\n",
       " [1.115867018699646, 4.0693817138671875],\n",
       " [-2.083986520767212, -0.2928007245063782],\n",
       " [5.368040561676025, 3.8830482959747314],\n",
       " [1.6739009618759155, 2.9997966289520264],\n",
       " [-0.14753134548664093, 4.873457908630371],\n",
       " [3.712737798690796, 1.0288572311401367],\n",
       " [-1.0827373266220093, 0.38879984617233276],\n",
       " [6.490537166595459, 1.7619479894638062],\n",
       " [0.42171984910964966, -0.19261151552200317],\n",
       " [-0.19369149208068848, 1.1140168905258179],\n",
       " [4.6828932762146, 1.564148187637329],\n",
       " [2.7776806354522705, 0.8541856408119202],\n",
       " [-1.1605101823806763, 3.611478805541992],\n",
       " [0.8050457239151001, 2.709183931350708],\n",
       " [1.5904417037963867, 0.19514644145965576],\n",
       " [0.4802152216434479, 1.3256502151489258],\n",
       " [0.6850935220718384, 6.5542311668396],\n",
       " [3.7044830322265625, 1.9130194187164307],\n",
       " [-0.3154295086860657, 0.34258583188056946],\n",
       " [-0.10589257627725601, 0.2920708954334259],\n",
       " [1.2491201162338257, 4.970030307769775],\n",
       " [-0.8528692722320557, 3.838409662246704],\n",
       " [3.107529401779175, 3.7070438861846924],\n",
       " [-1.0698405504226685, 6.873682022094727],\n",
       " [-2.5732316970825195, 7.211230754852295],\n",
       " [6.117489337921143, 3.611957311630249],\n",
       " [-0.5587927103042603, 2.4768223762512207],\n",
       " [3.7791049480438232, -1.2941298484802246],\n",
       " [4.761294841766357, 1.6016623973846436],\n",
       " [4.829259872436523, 2.2388837337493896],\n",
       " [5.381025791168213, 1.6255847215652466],\n",
       " [-6.887601852416992, 0.7820393443107605],\n",
       " [-1.3245596885681152, -0.33411386609077454],\n",
       " [-5.8118181228637695, -0.36832714080810547],\n",
       " [-7.4312872886657715, -0.7700251936912537],\n",
       " [-0.23575463891029358, -0.17939646542072296],\n",
       " [-0.8343037962913513, 0.033947885036468506],\n",
       " [-0.7332277894020081, -0.7786043882369995],\n",
       " [-3.2846643924713135, -3.8076093196868896],\n",
       " [-1.653892993927002, -1.5194923877716064],\n",
       " [-0.17668473720550537, -0.01513053011149168],\n",
       " [-5.463772296905518, -0.43904954195022583],\n",
       " [-1.8433502912521362, 0.0416000671684742],\n",
       " [-3.0144898891448975, -0.6380167603492737],\n",
       " [2.775397539138794, 0.9133082032203674],\n",
       " [-1.7374240159988403, 4.025478363037109],\n",
       " [0.7280998229980469, -0.6880217790603638],\n",
       " [0.1304493397474289, 4.634619235992432],\n",
       " [-5.406135082244873, -0.3996032476425171],\n",
       " [4.239551544189453, 1.720996618270874],\n",
       " [3.4909284114837646, 2.4117228984832764],\n",
       " [4.581038951873779, 7.303670406341553],\n",
       " [-0.03203809633851051, 1.388190507888794],\n",
       " [-0.9866392016410828, 4.7156147956848145],\n",
       " [1.686777949333191, 4.1838154792785645],\n",
       " [4.929628849029541, 5.222194671630859],\n",
       " [3.907585620880127, 2.947885513305664],\n",
       " [0.27249470353126526, 3.735837936401367],\n",
       " [-5.8512349128723145, 5.668209552764893],\n",
       " [-2.581961154937744, 2.012946844100952],\n",
       " [0.3848821818828583, 1.7525194883346558],\n",
       " [-0.15102869272232056, 3.806734323501587],\n",
       " [5.1823320388793945, 1.8152822256088257],\n",
       " [0.08118076622486115, 2.7323687076568604],\n",
       " [-6.279519081115723, -0.5126602649688721],\n",
       " [2.7639801502227783, -3.8054263591766357],\n",
       " [-3.2313010692596436, -0.37173992395401],\n",
       " [0.42862868309020996, 0.7179688811302185],\n",
       " [0.7121840119361877, 3.8876240253448486],\n",
       " [-2.3679001331329346, 4.95742654800415],\n",
       " [-0.06749606132507324, 4.837031364440918],\n",
       " [5.39146614074707, 4.002264022827148],\n",
       " [-1.6883212327957153, 2.1478214263916016],\n",
       " [6.483410358428955, 3.1364803314208984],\n",
       " [-1.3776975870132446, 0.31742462515830994],\n",
       " [1.9147579669952393, 2.429445505142212],\n",
       " [2.0777249336242676, -0.7590746283531189],\n",
       " [-6.497917652130127, 1.0112451314926147],\n",
       " [2.2956643104553223, 3.527500867843628],\n",
       " [4.590474605560303, 1.5736275911331177],\n",
       " [3.6767683029174805, 2.6301791667938232],\n",
       " [1.858974575996399, 3.8425660133361816],\n",
       " [0.4108581840991974, -0.8390253782272339],\n",
       " [2.313730239868164, 2.42322039604187],\n",
       " [-0.06860673427581787, 0.009290222078561783],\n",
       " [-0.10353684425354004, 0.04861179366707802],\n",
       " [-0.011427903547883034, 1.5548655986785889],\n",
       " [-0.07369522750377655, 0.23796886205673218],\n",
       " [6.299674987792969, 2.3992881774902344],\n",
       " [1.1048660278320312, 3.7121880054473877],\n",
       " [5.409234523773193, -0.762940526008606],\n",
       " [0.7270532846450806, 0.06079651042819023],\n",
       " [-5.925722122192383, -1.192306637763977],\n",
       " [-7.107599258422852, 0.7923385500907898],\n",
       " [-0.816272497177124, 1.437628984451294],\n",
       " [3.7671780586242676, -1.8273154497146606],\n",
       " [-1.0206267833709717, -1.8371094465255737],\n",
       " [1.6414803266525269, -2.334428548812866],\n",
       " [0.08567771315574646, 3.8738958835601807],\n",
       " [-5.429438591003418, -0.4434497654438019],\n",
       " [-3.6878397464752197, -0.442844033241272],\n",
       " [-0.6628339886665344, 3.7984299659729004],\n",
       " [3.103140354156494, -0.4879968464374542],\n",
       " [3.5370771884918213, 2.1582601070404053],\n",
       " [4.424212455749512, 3.644538402557373],\n",
       " [1.8882462978363037, 6.576506614685059],\n",
       " [4.578071594238281, 1.481674075126648],\n",
       " [1.642582654953003, 0.9014146327972412],\n",
       " [-3.900874614715576, -1.16189444065094],\n",
       " [0.08097326755523682, 1.616120457649231],\n",
       " [-0.01732277311384678, 0.14980608224868774],\n",
       " [2.1079020500183105, 5.252623558044434],\n",
       " [0.5803506970405579, 4.2723283767700195],\n",
       " [-0.14224772155284882, 0.09829995036125183],\n",
       " [1.0538138151168823, 2.6397335529327393],\n",
       " [2.9961931705474854, 1.1624375581741333],\n",
       " [1.2566430568695068, 7.689672470092773],\n",
       " [4.983658790588379, 4.966629505157471],\n",
       " [1.0073562860488892, 2.667181968688965],\n",
       " [3.7453293800354004, -0.6033066511154175],\n",
       " [1.2300692796707153, 0.19296158850193024],\n",
       " [0.7323184013366699, 5.039048194885254],\n",
       " [4.276248455047607, 3.4579455852508545],\n",
       " [0.9181538224220276, 4.328773021697998],\n",
       " [1.2922031879425049, -1.44438898563385],\n",
       " [1.0741711854934692, 4.16363000869751],\n",
       " [9.754709243774414, -1.1189301013946533],\n",
       " [5.628751277923584, 2.3962690830230713],\n",
       " [-0.4752868711948395, 5.218222618103027],\n",
       " [5.643582820892334, 3.3299951553344727],\n",
       " [1.5549824237823486, 3.603771209716797],\n",
       " [2.955036163330078, 4.336012840270996],\n",
       " [-2.5005428791046143, 1.2114408016204834],\n",
       " [2.004486322402954, 0.01872842386364937],\n",
       " [0.13216868042945862, 0.2527407109737396],\n",
       " [2.351806163787842, 3.604283571243286],\n",
       " [3.79746413230896, 2.2288625240325928],\n",
       " [4.115142822265625, 6.89213752746582],\n",
       " [3.8978984355926514, 4.107383728027344],\n",
       " [5.069828510284424, 2.7763285636901855],\n",
       " [2.8024961948394775, 5.733593940734863],\n",
       " [5.987561225891113, -1.1066049337387085],\n",
       " [1.6050493717193604, 5.6710333824157715],\n",
       " [6.020107269287109, -2.747772216796875],\n",
       " [0.8045988082885742, -0.8218960165977478],\n",
       " [1.6062220335006714, 1.3984109163284302],\n",
       " [8.304422378540039, 1.0988337993621826],\n",
       " [3.8651223182678223, -0.4949883222579956],\n",
       " [3.414458990097046, 3.945948362350464],\n",
       " [4.531709671020508, 2.7111165523529053],\n",
       " [2.7377140522003174, 1.2787885665893555],\n",
       " [-1.5824851989746094, 4.103115081787109],\n",
       " [2.1295247077941895, 0.029665719717741013],\n",
       " [-1.7450405359268188, -2.1454195976257324],\n",
       " [-0.15792332589626312, 0.8323736190795898],\n",
       " [0.022599179297685623, -0.1527462601661682],\n",
       " [3.9312856197357178, 4.975512504577637],\n",
       " [0.3844665288925171, 4.014939785003662],\n",
       " [4.2789459228515625, 1.1885089874267578],\n",
       " [6.988655090332031, 1.5430526733398438],\n",
       " [1.5559016466140747, 1.9810068607330322],\n",
       " [-2.0591812133789062, 2.613442897796631],\n",
       " [4.823966979980469, 3.665942907333374],\n",
       " [-1.280714750289917, 5.682744026184082],\n",
       " [3.699568748474121, 2.4298934936523438],\n",
       " [-2.977620840072632, 4.7490363121032715],\n",
       " [6.549551010131836, -1.1206704378128052],\n",
       " [2.2379744052886963, 0.10864538699388504],\n",
       " [5.65221643447876, 1.7518129348754883],\n",
       " [0.9428066611289978, 0.7114693522453308],\n",
       " [2.5269455909729004, 3.1218411922454834],\n",
       " [0.5871972441673279, 2.1164512634277344],\n",
       " [2.5096378326416016, 0.5320690274238586],\n",
       " [3.1278839111328125, 2.8863470554351807],\n",
       " [0.13556848466396332, -1.1187995672225952],\n",
       " [1.7879987955093384, -0.7024251222610474],\n",
       " [-3.4896507263183594, -3.349705219268799],\n",
       " [-0.5880753993988037, -0.047950536012649536],\n",
       " [0.6289134621620178, 0.9020761847496033],\n",
       " [0.12884896993637085, -0.43450525403022766],\n",
       " [3.047563076019287, 3.4830610752105713],\n",
       " [0.4285230040550232, 5.033650875091553],\n",
       " [1.7030316591262817, 6.269221305847168],\n",
       " [4.031827449798584, 3.6899912357330322],\n",
       " [2.89543080329895, 3.2532339096069336],\n",
       " [4.9701151847839355, 0.4688209891319275],\n",
       " [0.3258977234363556, 3.1834073066711426],\n",
       " [5.739180088043213, 1.248604416847229],\n",
       " [1.0746512413024902, 1.1694648265838623],\n",
       " [0.07535959780216217, 0.05706107243895531],\n",
       " [-0.4952176809310913, -0.3041790723800659],\n",
       " [3.741340160369873, 1.5456771850585938],\n",
       " [0.009588582441210747, 1.5984694957733154],\n",
       " [3.685060739517212, 1.9571144580841064],\n",
       " [0.16578111052513123, 3.713970184326172],\n",
       " [5.346273422241211, 0.37585416436195374],\n",
       " [-0.14175879955291748, 2.387258529663086],\n",
       " [1.6970757246017456, 2.7713420391082764],\n",
       " [-0.06105104461312294, 0.15884113311767578],\n",
       " [4.465137958526611, 2.9499073028564453],\n",
       " [2.0424981117248535, 1.9805787801742554],\n",
       " [5.281732559204102, 2.002168655395508],\n",
       " [-1.1126285791397095, 4.570235729217529],\n",
       " [4.8240065574646, 0.42938292026519775],\n",
       " [1.6405844688415527, -0.5129899978637695],\n",
       " [3.117020606994629, 1.942541480064392],\n",
       " [-0.007583983242511749, 0.1438935250043869],\n",
       " [0.27303609251976013, -0.20650112628936768],\n",
       " [3.1661417484283447, 2.690974235534668],\n",
       " [0.011971952393651009, 4.638395309448242],\n",
       " [2.405897855758667, 0.7606701254844666],\n",
       " [0.6236867308616638, 0.8077475428581238],\n",
       " [0.07349488884210587, 0.24890932440757751],\n",
       " [-1.1257944107055664, -0.44099801778793335],\n",
       " [3.8635475635528564, 4.462521076202393],\n",
       " [2.852330207824707, 1.233968734741211],\n",
       " [1.633117914199829, 3.147245407104492],\n",
       " [-0.39558303356170654, 0.10821131616830826],\n",
       " [0.7974074482917786, 0.6746785044670105],\n",
       " [-0.4322439134120941, -0.20572616159915924],\n",
       " [1.5624072551727295, 2.827475070953369],\n",
       " [-2.144826889038086, 3.8876731395721436],\n",
       " [-0.13196446001529694, 0.09015436470508575],\n",
       " [1.298548698425293, 3.836613416671753],\n",
       " [1.3070265054702759, 0.4428727626800537],\n",
       " [3.376225233078003, 2.786912441253662],\n",
       " [3.5545573234558105, 1.93883216381073],\n",
       " [-0.729732096195221, 2.1755566596984863],\n",
       " [-5.60458517074585, -0.3550666272640228],\n",
       " [-2.2554991245269775, 0.5303204655647278],\n",
       " [-1.9182369709014893, -0.3143334984779358],\n",
       " [-3.5652878284454346, -0.3483251929283142],\n",
       " [-2.5149075984954834, 1.0381706953048706],\n",
       " [-4.16967248916626, -0.5577391982078552],\n",
       " [-1.7567683458328247, 3.4471018314361572],\n",
       " [0.005311081185936928, 0.08544480055570602],\n",
       " [2.4030065536499023, -1.7611374855041504],\n",
       " [-3.752140998840332, 1.7439792156219482],\n",
       " [-7.223401069641113, -2.672513484954834],\n",
       " [-3.644721746444702, -0.6302478313446045],\n",
       " [0.9445106387138367, 2.44069242477417],\n",
       " [1.2074193954467773, 0.5864921808242798],\n",
       " [0.05958070978522301, 4.776188850402832],\n",
       " [3.767810821533203, 2.704761028289795],\n",
       " [-0.22018592059612274, 4.713405609130859],\n",
       " [-0.47476303577423096, 0.2565699815750122],\n",
       " [4.6544928550720215, 2.64693284034729],\n",
       " [5.828369617462158, 3.2881782054901123],\n",
       " [2.386894941329956, 8.606496810913086],\n",
       " [-0.1292317509651184, 3.172135591506958],\n",
       " [2.353564500808716, 5.308419704437256],\n",
       " [3.266638994216919, 3.231097459793091],\n",
       " [6.951694488525391, 4.224867343902588],\n",
       " [-0.4159202575683594, 1.3375645875930786],\n",
       " [0.09846650809049606, 0.8012452721595764],\n",
       " [3.1378748416900635, 6.630091190338135],\n",
       " [-1.4239695072174072, 2.4485487937927246],\n",
       " [-0.0724470466375351, 0.292888879776001],\n",
       " [1.5582101345062256, 2.1439156532287598],\n",
       " [-5.161016941070557, 0.26781731843948364],\n",
       " [1.0572247505187988, 3.9182310104370117],\n",
       " [-0.13225725293159485, 0.001496796845458448],\n",
       " [-0.5229142904281616, 1.2706928253173828],\n",
       " [-0.7687773704528809, 0.029965078458189964],\n",
       " [1.7306427955627441, 2.163996934890747],\n",
       " [-1.8939714431762695, 0.32995760440826416],\n",
       " [0.0017501666443422437, 0.19543087482452393],\n",
       " [0.32424184679985046, 0.6192536354064941],\n",
       " [0.9064956903457642, 7.549694538116455],\n",
       " [1.279387354850769, 1.723193883895874],\n",
       " [-0.5301931500434875, 3.885441780090332],\n",
       " [-3.141178846359253, 0.7460894584655762],\n",
       " [-4.379176616668701, 2.020644426345825],\n",
       " [-3.5721662044525146, 3.2085752487182617],\n",
       " [1.5929597616195679, 2.5815863609313965],\n",
       " [-2.1010000705718994, 5.298346996307373],\n",
       " [-4.446715831756592, -3.2304177284240723],\n",
       " [-2.072866916656494, -0.9114369750022888],\n",
       " [-3.156409502029419, -2.7253198623657227],\n",
       " [-5.106788635253906, 1.5227901935577393],\n",
       " [-4.28593111038208, 1.3693870306015015],\n",
       " [2.3729822635650635, 1.2840549945831299],\n",
       " [-0.9639981389045715, -0.3899567723274231],\n",
       " [-1.6123812198638916, 3.9480133056640625],\n",
       " [3.8082637786865234, 2.716301202774048],\n",
       " [1.015679955482483, 2.4283154010772705],\n",
       " [-0.18615998327732086, 1.2265433073043823],\n",
       " [7.002330780029297, -0.6027308702468872],\n",
       " [0.23001502454280853, 1.2877765893936157],\n",
       " [2.3629016876220703, 2.791947603225708],\n",
       " [7.117973327636719, 2.020117998123169],\n",
       " [6.273465633392334, 0.5799233913421631],\n",
       " [4.728315830230713, 0.941344141960144],\n",
       " [0.05674487352371216, 0.3221674859523773],\n",
       " [8.373042106628418, 1.9273654222488403],\n",
       " [5.214621067047119, 2.8412201404571533],\n",
       " [-5.268226146697998, -0.27835404872894287],\n",
       " [-3.534372091293335, -1.3309506177902222],\n",
       " [1.4466536045074463, 5.751502990722656],\n",
       " [2.311098337173462, 3.626462459564209],\n",
       " [6.945520401000977, -0.39902716875076294],\n",
       " [-1.5696958303451538, 3.0997912883758545],\n",
       " [0.8735705018043518, 3.7896547317504883],\n",
       " [1.3825715780258179, 3.0913448333740234],\n",
       " [6.6128387451171875, 1.9785386323928833],\n",
       " [2.259624481201172, -0.649219810962677],\n",
       " [2.940223217010498, 2.299574136734009],\n",
       " [3.1902096271514893, 1.2500710487365723],\n",
       " [3.048837900161743, 2.305302381515503],\n",
       " [-1.1793467998504639, 3.2693798542022705],\n",
       " [2.65470552444458, 1.2261937856674194],\n",
       " [0.30817899107933044, 0.7884824275970459],\n",
       " [-0.24520820379257202, 0.5697763562202454],\n",
       " [-0.7117590308189392, 0.23338468372821808],\n",
       " [-0.9389843344688416, 0.16706739366054535],\n",
       " [-6.3996381759643555, -2.7500598430633545],\n",
       " [-2.671182870864868, -1.4679808616638184],\n",
       " [-3.391975164413452, -1.4524850845336914],\n",
       " [-5.156065940856934, -0.5807121396064758],\n",
       " [0.16951681673526764, 2.600456476211548],\n",
       " [-3.1327590942382812, 1.6810927391052246],\n",
       " [-1.0589596033096313, 0.9795393347740173],\n",
       " [1.3079742193222046, 2.2902421951293945],\n",
       " [5.664343357086182, 1.1279702186584473],\n",
       " [-0.08996465057134628, 2.213932514190674],\n",
       " [0.14165610074996948, 1.2244930267333984],\n",
       " [-0.7295414209365845, 1.735196828842163],\n",
       " [-0.0674237385392189, 0.1970052719116211],\n",
       " [-0.9119683504104614, 3.0097336769104004],\n",
       " [1.761737585067749, 4.920562267303467],\n",
       " [-2.100379705429077, 4.879130840301514],\n",
       " [3.6071243286132812, -0.8393346667289734],\n",
       " [4.140270233154297, 2.6109819412231445],\n",
       " [1.1724649667739868, 1.4714964628219604],\n",
       " [-0.6788992881774902, -0.9543933868408203],\n",
       " [3.0120136737823486, 1.450972080230713],\n",
       " [-5.0575852394104, 0.5860915184020996],\n",
       " [-1.5112930536270142, 2.4166834354400635],\n",
       " [0.43173086643218994, 3.1440937519073486],\n",
       " [0.10107395797967911, 1.007270336151123],\n",
       " [-2.832667589187622, 5.960798740386963],\n",
       " [-0.8838585019111633, 0.7324715256690979],\n",
       " [-1.012555718421936, 9.053118705749512],\n",
       " [0.7800862193107605, 2.660515546798706],\n",
       " [-1.2176845073699951, 4.002881050109863],\n",
       " [-2.0447983741760254, 3.8880507946014404],\n",
       " [0.15359298884868622, 0.36350002884864807],\n",
       " [-2.7811100482940674, 2.303072452545166],\n",
       " [-2.073596239089966, 3.4856317043304443],\n",
       " [-5.0357818603515625, 2.597773790359497],\n",
       " [0.1481059044599533, -0.08284871280193329],\n",
       " [2.927177906036377, 1.4910037517547607],\n",
       " [-0.584311842918396, 5.5714111328125],\n",
       " [2.3184564113616943, 3.248028039932251],\n",
       " [-0.03686247766017914, 0.09558123350143433],\n",
       " [6.78995943069458, 0.4914606809616089],\n",
       " [2.622227668762207, 2.582329750061035],\n",
       " [4.170648097991943, 2.005866765975952],\n",
       " [1.4899643659591675, 0.014784493483603],\n",
       " [0.2782394587993622, 1.8635987043380737],\n",
       " [3.9328408241271973, 0.8337805867195129],\n",
       " [4.088330268859863, 2.768902540206909],\n",
       " [2.067072629928589, 0.20520839095115662],\n",
       " [0.744780957698822, 7.027687072753906],\n",
       " [1.9642122983932495, 4.890351295471191],\n",
       " [0.8840022087097168, 0.7559086680412292],\n",
       " [0.5186159610748291, 6.026078701019287],\n",
       " [0.08487488329410553, 1.3911479711532593],\n",
       " [2.7756335735321045, 1.8246243000030518],\n",
       " [5.951335906982422, 4.18062162399292],\n",
       " [1.6780887842178345, 0.6609396934509277],\n",
       " [1.6713594198226929, 0.30565232038497925],\n",
       " [7.526245594024658, 2.324921131134033],\n",
       " [-0.512381911277771, 4.601737022399902],\n",
       " [-0.5079838633537292, 7.294238090515137],\n",
       " [0.1437823623418808, 4.523682117462158],\n",
       " [-2.038843870162964, 8.941752433776855],\n",
       " [2.5381088256835938, 2.833254337310791],\n",
       " [1.3035471439361572, -0.013617416843771935],\n",
       " [-0.8265577554702759, 5.696403503417969],\n",
       " [-3.0681650638580322, 5.117819786071777],\n",
       " [-0.1469699889421463, 0.09339705109596252],\n",
       " [0.9911555051803589, 1.486716628074646],\n",
       " [2.068204402923584, 3.1150951385498047],\n",
       " [-1.870094656944275, 1.0835901498794556],\n",
       " [-1.2122348546981812, 7.222249507904053],\n",
       " [6.047599792480469, 1.1210672855377197],\n",
       " [0.1916649341583252, 1.8633921146392822],\n",
       " [2.2360153198242188, 2.159235954284668],\n",
       " [-0.35626518726348877, 1.6568586826324463],\n",
       " [-0.3748227655887604, 6.47815465927124],\n",
       " [0.7489891648292542, 5.148257255554199],\n",
       " [5.175109386444092, 1.5855656862258911],\n",
       " [2.1895928382873535, 4.5750732421875],\n",
       " [-2.8563764095306396, 2.2273354530334473],\n",
       " [-0.2465483397245407, 0.43259093165397644],\n",
       " [-6.782894134521484, -1.3724596500396729],\n",
       " [3.0136992931365967, 2.4280288219451904],\n",
       " [0.11545499414205551, 0.16458572447299957],\n",
       " [-2.6000640392303467, 2.0652055740356445],\n",
       " [1.9986190795898438, 1.5697963237762451],\n",
       " [2.8778374195098877, 2.6071360111236572],\n",
       " [0.29637154936790466, 0.6794060468673706],\n",
       " [-0.40587514638900757, 1.9261904954910278],\n",
       " [-1.100193977355957, 7.396090030670166],\n",
       " [5.2661895751953125, 2.113769054412842],\n",
       " [-0.9366161227226257, 6.368860244750977],\n",
       " [-0.6974171996116638, 0.5066214203834534],\n",
       " [0.34911787509918213, 0.20075508952140808],\n",
       " [4.4525957107543945, -0.8771200776100159],\n",
       " [7.096877574920654, 2.6288857460021973],\n",
       " [-5.413963794708252, -3.3620259761810303],\n",
       " [4.1312785148620605, 3.692959785461426],\n",
       " [3.1261892318725586, -0.21049945056438446],\n",
       " [0.26466938853263855, 1.4365038871765137],\n",
       " [1.58671236038208, 1.1432502269744873],\n",
       " [6.257776737213135, 2.089003801345825],\n",
       " [2.6593565940856934, 1.637913703918457],\n",
       " [4.17918062210083, 1.613710641860962],\n",
       " [4.83580207824707, 2.690349578857422],\n",
       " [-2.4678401947021484, 2.231564998626709],\n",
       " [1.5849552154541016, 2.6171860694885254],\n",
       " [-1.7279125452041626, -0.029100118204951286],\n",
       " [-6.543982028961182, -3.7120378017425537],\n",
       " [3.0614616870880127, 1.998308777809143],\n",
       " [3.8160319328308105, 2.6972389221191406],\n",
       " [-1.195576786994934, 0.5560542345046997],\n",
       " [0.17552927136421204, 0.6335416436195374],\n",
       " [-2.6463863849639893, 5.44031286239624],\n",
       " [1.194362759590149, -1.0254204273223877],\n",
       " [4.234737396240234, -0.7879593372344971],\n",
       " [1.2418748140335083, 0.7468187808990479],\n",
       " [0.7802924513816833, 4.131280422210693],\n",
       " [3.278702735900879, 1.3645375967025757],\n",
       " [3.2154650688171387, 1.0567899942398071],\n",
       " [-0.48257210850715637, -1.5398069620132446],\n",
       " [5.369227886199951, 0.8228435516357422],\n",
       " [3.7773759365081787, 1.5604588985443115],\n",
       " [0.6567301750183105, 2.6705322265625],\n",
       " [1.5846487283706665, -2.2670936584472656],\n",
       " [-3.503988027572632, -0.22155262529850006],\n",
       " [-2.813788414001465, -0.15728452801704407],\n",
       " [-5.245917320251465, 1.8593991994857788],\n",
       " [-0.7205479145050049, 0.1308656632900238],\n",
       " [0.8542836308479309, 3.5992941856384277],\n",
       " [-0.16494138538837433, 0.547073483467102],\n",
       " [4.309106826782227, -1.3563926219940186],\n",
       " [-1.1774983406066895, 2.953674077987671],\n",
       " [3.923936128616333, 2.225970506668091],\n",
       " [-3.842885732650757, -0.5818741321563721],\n",
       " [-0.2888973653316498, 0.07341717928647995],\n",
       " [-3.7232539653778076, 3.445230484008789],\n",
       " [-0.1814347356557846, 0.375447154045105],\n",
       " [-1.7104426622390747, 1.691174030303955],\n",
       " [-0.7006144523620605, 2.780761241912842],\n",
       " [-0.6776031255722046, 0.7090101838111877],\n",
       " [1.2031784057617188, 0.5946056842803955],\n",
       " [2.9460842609405518, 1.967697024345398],\n",
       " [1.210437536239624, 3.969693899154663],\n",
       " [0.03233407065272331, 3.7613484859466553],\n",
       " [5.288589000701904, 1.377858281135559],\n",
       " [3.9876105785369873, -1.0015220642089844],\n",
       " [-0.026499278843402863, 0.3230381906032562],\n",
       " [-2.9163331985473633, -0.9977010488510132],\n",
       " [0.3947400450706482, -0.5499963760375977],\n",
       " [0.004922947380691767, 3.2370924949645996],\n",
       " [0.04817766696214676, 0.6362232565879822],\n",
       " [-5.36857795715332, -1.608120322227478],\n",
       " [-0.7842947840690613, 1.139954686164856],\n",
       " [2.9580070972442627, 7.1147780418396],\n",
       " [-2.130974531173706, -0.3183993995189667],\n",
       " [3.935256242752075, 1.360312581062317],\n",
       " [3.8932292461395264, -0.48915499448776245],\n",
       " [0.7143068313598633, 0.11412284523248672],\n",
       " [1.706275224685669, 3.3862431049346924],\n",
       " [-1.5200788974761963, 2.692385196685791],\n",
       " [-0.3062051236629486, 1.1676799058914185],\n",
       " [-0.08261508494615555, 0.34629911184310913],\n",
       " [0.683020293712616, 4.4427666664123535],\n",
       " [-0.5604878067970276, 1.8503581285476685],\n",
       " [-1.6319130659103394, 1.3592668771743774],\n",
       " [0.6244441866874695, 4.662656784057617],\n",
       " [-1.1087440252304077, 0.8429083228111267],\n",
       " [0.09937617927789688, 1.5359842777252197],\n",
       " [2.651522636413574, 3.434426784515381],\n",
       " [4.385017395019531, 6.914979934692383],\n",
       " [2.511230707168579, 4.630043029785156],\n",
       " [-0.7686423063278198, 1.961929440498352],\n",
       " [5.234358787536621, 2.5588037967681885],\n",
       " [0.14273369312286377, -0.2891029715538025],\n",
       " [1.6636656522750854, 0.32097384333610535],\n",
       " [-2.0046396255493164, 2.304370164871216],\n",
       " [0.596958339214325, 0.43786564469337463],\n",
       " [0.6876976490020752, 0.17779938876628876],\n",
       " [5.612281322479248, 2.8314740657806396],\n",
       " [-1.0494242906570435, 1.7379118204116821],\n",
       " [0.5021439790725708, 4.405174732208252],\n",
       " [2.04329514503479, 5.854550838470459],\n",
       " [6.906697750091553, 2.201447010040283],\n",
       " [5.327323913574219, -1.5377697944641113],\n",
       " [2.4080915451049805, 1.4799532890319824],\n",
       " [6.647714138031006, -0.6728222966194153],\n",
       " [-0.44464415311813354, -1.2068676948547363],\n",
       " [-1.2018651962280273, 0.814976692199707],\n",
       " [-0.6741768717765808, -0.2695787250995636],\n",
       " [2.8262856006622314, 4.842514514923096],\n",
       " [0.7896692156791687, 3.310182571411133],\n",
       " [3.6683647632598877, -0.6470375061035156],\n",
       " [-0.30640190839767456, -0.0034286207519471645],\n",
       " [-0.35718971490859985, 0.048292286694049835],\n",
       " [7.762763500213623, 3.8604626655578613],\n",
       " [2.805665969848633, -0.06195385381579399],\n",
       " [2.971348285675049, 4.295261383056641],\n",
       " [3.20771861076355, -0.5885259509086609],\n",
       " [4.786978721618652, 1.3663195371627808],\n",
       " [-1.6291753053665161, 3.113967180252075],\n",
       " [-0.0814109593629837, 0.289188027381897],\n",
       " [1.3596457242965698, 1.5552442073822021],\n",
       " [-0.6382235884666443, 1.5101890563964844],\n",
       " [0.008248400874435902, 0.6384822130203247],\n",
       " [-3.6938586235046387, -0.6849898099899292],\n",
       " [-1.7494640350341797, 0.6105955243110657],\n",
       " [-0.34265604615211487, 0.8700240254402161],\n",
       " [2.635749578475952, 2.9996650218963623],\n",
       " [-1.847171425819397, 5.269556045532227],\n",
       " [-0.03461097180843353, -0.23751115798950195],\n",
       " [0.556174099445343, -0.5067895650863647],\n",
       " [-0.18489927053451538, 0.9252492189407349],\n",
       " [3.28977370262146, 4.361164569854736],\n",
       " [0.13081195950508118, -1.7212424278259277],\n",
       " [-0.11522343009710312, -0.8543217182159424],\n",
       " [0.0060723768547177315, 1.7483927011489868],\n",
       " [-0.10660949349403381, 2.6942477226257324],\n",
       " [4.634026050567627, 3.227931022644043],\n",
       " [3.6419105529785156, 1.078925371170044],\n",
       " [-0.18495726585388184, 0.7393622994422913],\n",
       " [1.3612691164016724, 4.2942094802856445],\n",
       " [-1.4446110725402832, 4.120248317718506],\n",
       " [-2.501579761505127, 1.2957123517990112],\n",
       " [3.708519220352173, 2.403848886489868],\n",
       " [0.04688467085361481, 3.5618600845336914],\n",
       " [2.7131433486938477, 1.6804213523864746],\n",
       " [1.4910914897918701, 1.3685336112976074],\n",
       " [3.361006498336792, 0.9403740167617798],\n",
       " [0.1044013723731041, 0.5593798160552979],\n",
       " [3.0864362716674805, 3.0055935382843018],\n",
       " [0.4233941435813904, 2.778177261352539],\n",
       " [-0.10643859952688217, 0.11566276103258133],\n",
       " [0.7414577007293701, 0.9154821038246155],\n",
       " [2.3486666679382324, 5.224487781524658],\n",
       " [-0.38520917296409607, -0.4095359146595001],\n",
       " [-0.8949019312858582, -0.7334966063499451],\n",
       " [0.7511951923370361, -2.7295424938201904],\n",
       " [-0.31153732538223267, -2.448216438293457],\n",
       " [-0.7320834994316101, -0.5736453533172607],\n",
       " [-5.700794219970703, -3.4634547233581543],\n",
       " [-0.09382858872413635, 0.15556426346302032],\n",
       " [-2.1211953163146973, 4.448040962219238],\n",
       " [-0.12272283434867859, 0.1491592675447464],\n",
       " [0.16300781071186066, 1.5931708812713623],\n",
       " [-1.62794828414917, 0.017682567238807678],\n",
       " [1.5928068161010742, 0.6610544919967651],\n",
       " [4.337451934814453, 2.6056413650512695],\n",
       " [2.0114638805389404, 5.243566989898682],\n",
       " [-0.21281316876411438, 0.5288732647895813],\n",
       " [1.3966002464294434, -1.1360174417495728],\n",
       " [4.68970251083374, 3.886414051055908],\n",
       " [0.36740151047706604, 2.6162374019622803],\n",
       " [-0.22200654447078705, 6.189637660980225],\n",
       " [-3.5853867530822754, 5.897552967071533],\n",
       " [0.6539473533630371, 0.5608530044555664],\n",
       " [2.0044119358062744, 3.2806079387664795],\n",
       " [-0.10527714341878891, 0.18001863360404968],\n",
       " [-6.442831516265869, 2.1072299480438232],\n",
       " [-0.4181618094444275, 1.2109347581863403],\n",
       " [0.059636928141117096, 0.5449029803276062],\n",
       " [0.7589172124862671, 6.605217456817627],\n",
       " [-0.8164529204368591, -0.13968078792095184],\n",
       " [0.2202107012271881, 0.7784128785133362],\n",
       " [0.14202500879764557, 5.857301712036133],\n",
       " [3.9342281818389893, 5.224104404449463],\n",
       " [1.8113486766815186, 2.8154659271240234],\n",
       " [0.4587714374065399, 2.5353195667266846],\n",
       " [5.71454381942749, -2.0105807781219482],\n",
       " [1.2899153232574463, 7.208656311035156],\n",
       " [0.16363833844661713, 0.24639743566513062],\n",
       " [-1.9861555099487305, -0.21329793334007263],\n",
       " [-0.17930762469768524, 0.9709697365760803],\n",
       " [-1.223359227180481, -1.4276920557022095],\n",
       " [-2.7091119289398193, -2.7973477840423584],\n",
       " [1.6093428134918213, -0.4895866811275482],\n",
       " [-1.0971944332122803, 5.382775783538818],\n",
       " [2.368316650390625, 7.063973903656006],\n",
       " [3.0708553791046143, 2.956892728805542],\n",
       " [-0.2312421202659607, 3.2674691677093506],\n",
       " [2.473947763442993, -0.5746670961380005],\n",
       " [1.8589578866958618, 6.509852409362793],\n",
       " [1.8465386629104614, 2.6479244232177734],\n",
       " [6.533283233642578, 1.1940306425094604],\n",
       " [1.1234527826309204, 5.461592197418213],\n",
       " [4.933174133300781, 2.885720729827881],\n",
       " [3.2876815795898438, 0.9385173916816711],\n",
       " [-0.04885763302445412, 5.818378925323486],\n",
       " [-0.009639882482588291, 0.8149357438087463],\n",
       " [0.9104116559028625, 2.0329251289367676],\n",
       " [-0.08411486446857452, 0.012058175168931484],\n",
       " [-1.5404454469680786, 0.021477986127138138],\n",
       " [-6.087116718292236, -3.549074649810791],\n",
       " [-0.18267229199409485, 0.036468978971242905],\n",
       " [-0.7731152176856995, 3.38875412940979],\n",
       " [-1.1327704191207886, 6.610332012176514],\n",
       " [2.792790651321411, 6.601070880889893],\n",
       " [1.9762684106826782, 2.9955220222473145],\n",
       " [-1.717965006828308, -1.3156194686889648],\n",
       " [1.4456164836883545, 3.3999972343444824],\n",
       " [1.9762945175170898, -2.5214290618896484],\n",
       " [-1.792857050895691, 0.4703103005886078],\n",
       " [-1.0919805765151978, -0.491128534078598],\n",
       " [-0.2854715585708618, -1.3104678392410278],\n",
       " [4.553940296173096, 0.7723972797393799],\n",
       " [0.6326073408126831, 3.1958911418914795],\n",
       " [-3.628298044204712, 1.3128608465194702],\n",
       " [-0.04434102401137352, 0.8803426623344421],\n",
       " [-0.4106774628162384, 1.9880026578903198],\n",
       " [1.6695765256881714, 0.5830843448638916],\n",
       " [-0.2985914349555969, 0.5821383595466614],\n",
       " [-3.321817636489868, 5.308498859405518],\n",
       " [-0.5013025403022766, -2.184619426727295],\n",
       " [-0.5944707989692688, 6.380171775817871],\n",
       " [-2.805213689804077, 2.8293874263763428],\n",
       " [-3.230379581451416, 1.4731117486953735],\n",
       " [-2.839691400527954, 3.2955081462860107],\n",
       " [-0.4244009852409363, 1.9677890539169312],\n",
       " [2.9012415409088135, 2.635786294937134],\n",
       " [1.4617425203323364, 0.923904538154602],\n",
       " [5.160575866699219, -0.6377744078636169],\n",
       " [1.4459643363952637, 1.6811362504959106],\n",
       " [-0.29939597845077515, 2.5864272117614746],\n",
       " [2.2239294052124023, 2.427640438079834],\n",
       " [1.0212678909301758, 5.508601665496826],\n",
       " [0.9896970391273499, 3.7630202770233154],\n",
       " [1.3053807020187378, 4.721373081207275],\n",
       " [1.2350690364837646, 8.097253799438477],\n",
       " [-0.2207190990447998, 2.3279671669006348],\n",
       " [-1.3842158317565918, 6.006447792053223],\n",
       " [0.6340395212173462, 0.5094066262245178],\n",
       " [-1.07868230342865, 5.350839614868164],\n",
       " [-1.023725986480713, 0.8969155550003052],\n",
       " [4.787961959838867, 1.7006229162216187],\n",
       " [-0.25975391268730164, 3.8188092708587646],\n",
       " [1.6124967336654663, 5.549055099487305],\n",
       " [2.792092800140381, 1.355597972869873],\n",
       " [3.218456745147705, 3.711174964904785],\n",
       " [1.069214940071106, 2.9250833988189697],\n",
       " [3.063944101333618, 3.4713387489318848],\n",
       " [-0.44068968296051025, 2.0730156898498535],\n",
       " [-4.036731719970703, -3.9431588649749756],\n",
       " [0.24287059903144836, 1.7092622518539429],\n",
       " [0.7835555672645569, 0.7065584063529968],\n",
       " [-0.019322117790579796, 1.2282716035842896],\n",
       " [-2.8448567390441895, 2.8457016944885254],\n",
       " [1.0647711753845215, -0.36887261271476746],\n",
       " [2.9044694900512695, 2.048593282699585],\n",
       " [4.28270959854126, 2.4651098251342773],\n",
       " [-1.8572602272033691, 0.08710898458957672],\n",
       " [-1.1835346221923828, 2.499101400375366],\n",
       " [-4.2360405921936035, 1.8761745691299438],\n",
       " [-4.444781303405762, 1.8914198875427246],\n",
       " [-0.046260882169008255, 1.5495326519012451],\n",
       " [1.0970613956451416, 2.1143746376037598],\n",
       " [-1.4862143993377686, 3.2694807052612305],\n",
       " [-3.5675530433654785, 5.712326526641846],\n",
       " [-0.49310755729675293, 2.7801339626312256],\n",
       " [-1.190622329711914, 2.254706859588623],\n",
       " [-0.17510578036308289, 2.1755125522613525],\n",
       " [0.2602117955684662, 2.071462392807007],\n",
       " [1.2714041471481323, 8.720105171203613],\n",
       " [-0.3700235188007355, 1.3473021984100342],\n",
       " [-0.1960398107767105, 0.23661315441131592],\n",
       " [1.3414479494094849, 3.3181018829345703],\n",
       " [-2.227234363555908, 5.634263038635254],\n",
       " [-2.6574113368988037, 2.838642120361328],\n",
       " [2.9648430347442627, 0.33552417159080505],\n",
       " [0.7403284311294556, -1.227993130683899],\n",
       " [-1.8800208568572998, 1.9667670726776123],\n",
       " [-3.2820076942443848, 2.787313938140869],\n",
       " [-0.06245453283190727, 2.094581365585327],\n",
       " [-0.9025300741195679, 1.9102307558059692],\n",
       " [-2.5626649856567383, 6.653595447540283],\n",
       " [-2.234372138977051, 4.469472408294678],\n",
       " [-0.6035265922546387, -0.13348990678787231],\n",
       " [-0.24719005823135376, 0.21008062362670898],\n",
       " [-2.6141726970672607, 5.112597465515137],\n",
       " [0.3389229476451874, 2.4569647312164307],\n",
       " [0.4219009280204773, 2.68723464012146],\n",
       " [5.1729888916015625, 4.984963417053223],\n",
       " [-0.060644522309303284, 0.35678136348724365],\n",
       " [3.6178407669067383, 3.2005279064178467],\n",
       " [3.6881895065307617, 8.952425956726074],\n",
       " [1.3303781747817993, 3.035956382751465],\n",
       " [-2.9396564960479736, 4.801076889038086],\n",
       " [-0.021689407527446747, -2.83040714263916],\n",
       " [1.3587459325790405, 3.774176597595215],\n",
       " [2.626108169555664, 2.129452705383301],\n",
       " [1.0980130434036255, 0.9616624712944031],\n",
       " [0.8581359386444092, 0.6401321291923523],\n",
       " [4.260976314544678, 4.152650356292725],\n",
       " [4.222506999969482, 3.834467649459839],\n",
       " [3.0962910652160645, 0.7699498534202576],\n",
       " [4.248971462249756, 4.254481792449951],\n",
       " [1.682477593421936, 2.560662031173706],\n",
       " [4.14900541305542, 1.9643559455871582],\n",
       " [-2.5592169761657715, 5.494577407836914],\n",
       " [4.479872226715088, 0.7911813855171204],\n",
       " [3.4948222637176514, 4.2019267082214355],\n",
       " [5.875534534454346, 0.862837016582489],\n",
       " [-0.05281895771622658, 1.3008098602294922],\n",
       " [-0.35188108682632446, 4.335022449493408],\n",
       " [2.0071635246276855, 3.646637201309204],\n",
       " [2.615061044692993, 0.7037702798843384],\n",
       " [3.321981430053711, 8.335223197937012],\n",
       " [-0.21076127886772156, 3.18095064163208],\n",
       " [2.245403289794922, 2.520063638687134],\n",
       " [-1.5141249895095825, 5.8787007331848145],\n",
       " [-1.2449101209640503, 3.4359512329101562],\n",
       " [0.24979066848754883, 0.07162212580442429],\n",
       " [4.666228294372559, 5.557189464569092],\n",
       " [2.1402177810668945, 3.703885316848755],\n",
       " [-5.367344856262207, 1.2963929176330566],\n",
       " [2.0162365436553955, 1.771405816078186],\n",
       " [-0.9786533117294312, 0.947295606136322],\n",
       " [0.4038722515106201, 2.9840126037597656],\n",
       " [5.903693675994873, 1.6664097309112549],\n",
       " [5.05067253112793, 1.8481987714767456],\n",
       " [5.739245414733887, 0.2266123741865158],\n",
       " [0.2538130581378937, 0.3297714591026306],\n",
       " [2.98258113861084, -0.6284179091453552],\n",
       " [0.10329567641019821, 0.9873887300491333],\n",
       " [3.602196455001831, 0.8181616067886353],\n",
       " [2.2175064086914062, 0.4900931119918823],\n",
       " [2.3102781772613525, 3.1335623264312744],\n",
       " [2.757397174835205, 6.677452564239502],\n",
       " [-0.007083638571202755, 0.9397110939025879],\n",
       " [-1.3803037405014038, 4.142921447753906],\n",
       " [-0.6482548713684082, 2.537987232208252],\n",
       " [0.46658775210380554, 5.131217002868652],\n",
       " [-0.8977645635604858, 1.1981573104858398],\n",
       " [1.361830234527588, 5.4301981925964355],\n",
       " [-0.44417116045951843, 0.9417670369148254],\n",
       " [-0.029543479904532433, 2.1372342109680176],\n",
       " [-0.31052032113075256, 4.8240556716918945],\n",
       " [-0.6748588681221008, 3.9382095336914062],\n",
       " [4.368797779083252, -0.5828778147697449],\n",
       " [0.8460254669189453, -0.5058016180992126],\n",
       " [3.2825446128845215, -2.646578311920166],\n",
       " [-0.4280063807964325, 0.9153752326965332],\n",
       " [2.347628593444824, -0.3078352212905884],\n",
       " [3.6383066177368164, -1.167472243309021],\n",
       " [1.0021991729736328, 0.8323654532432556],\n",
       " [1.7073266506195068, 3.757359266281128],\n",
       " [6.428864002227783, 3.460141181945801],\n",
       " [-0.033144377171993256, 4.0407514572143555],\n",
       " [7.351207256317139, 2.4889445304870605],\n",
       " [2.814338207244873, 0.8713591694831848],\n",
       " [0.9877197742462158, 0.5334200859069824],\n",
       " [0.49120742082595825, 0.9135138392448425],\n",
       " [-0.6731594204902649, 0.9530004858970642],\n",
       " [-1.0549291372299194, 6.137121200561523],\n",
       " [-0.31726303696632385, 6.432122230529785],\n",
       " [5.822056293487549, 0.6522380709648132],\n",
       " [-1.6709580421447754, 4.857921123504639],\n",
       " [1.4650799036026, 3.8142940998077393],\n",
       " [-2.2254226207733154, -1.3649765253067017],\n",
       " [-3.28131365776062, 5.428838729858398],\n",
       " [-5.2090349197387695, 0.6688627004623413],\n",
       " [1.80214524269104, 3.6988563537597656],\n",
       " [8.177793502807617, 0.8910385966300964],\n",
       " [3.2977914810180664, 0.5901446342468262],\n",
       " [2.906222343444824, 0.9984499216079712],\n",
       " [1.4819176197052002, 10.231345176696777],\n",
       " [4.305751323699951, -3.57114577293396],\n",
       " [0.06419626623392105, -0.1035744845867157],\n",
       " [2.3906171321868896, -0.7683768272399902],\n",
       " [0.2908787727355957, 0.740541934967041],\n",
       " [-0.11560630053281784, 0.2121594250202179],\n",
       " [4.922760009765625, 5.04533576965332],\n",
       " [5.533107757568359, 3.8383193016052246],\n",
       " [1.3477882146835327, 8.248756408691406],\n",
       " [1.914547085762024, 1.2872072458267212],\n",
       " [-0.8119072914123535, 1.9746676683425903],\n",
       " [2.2544140815734863, 3.774456024169922],\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:48.563907Z",
     "start_time": "2019-10-07T14:15:48.557294Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:15:56.480311Z",
     "start_time": "2019-10-07T14:15:56.459152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat',\n",
       " 'verona',\n",
       " 'orthodoxy',\n",
       " 'relaxes',\n",
       " 'exiguus',\n",
       " 'repel',\n",
       " 'colonization',\n",
       " 'morehouse',\n",
       " 'jardines',\n",
       " 'fitter',\n",
       " 'dweller',\n",
       " 'ct',\n",
       " 'zoroastrians',\n",
       " 'junctions',\n",
       " 'crossfire',\n",
       " 'hedge',\n",
       " 'genome',\n",
       " 'poignant',\n",
       " 'at',\n",
       " 'ackerman',\n",
       " 'bloemfontein',\n",
       " 'keefe',\n",
       " 'simplest',\n",
       " 'leftist',\n",
       " 'janine',\n",
       " 'dandelin',\n",
       " 'balto',\n",
       " 'customs',\n",
       " 'rita',\n",
       " 'annum',\n",
       " 'basins',\n",
       " 'antibiotics',\n",
       " 'repress',\n",
       " 'harpsichords',\n",
       " 'metropole',\n",
       " 'staffordshire',\n",
       " 'resp',\n",
       " 'seward',\n",
       " 'butcher',\n",
       " 'elia',\n",
       " 'bahamonde',\n",
       " 'mousepad',\n",
       " 'mcginty',\n",
       " 'dystrophy',\n",
       " 'fliers',\n",
       " 'maintain',\n",
       " 'trucker',\n",
       " 'tetryl',\n",
       " 'hallstatt',\n",
       " 'scotton',\n",
       " 'laye',\n",
       " 'lcp',\n",
       " 'goizueta',\n",
       " 'felton',\n",
       " 'shatters',\n",
       " 'bones',\n",
       " 'vehement',\n",
       " 'tennis',\n",
       " 'kryptonian',\n",
       " 'excreted',\n",
       " 'murinus',\n",
       " 'octavio',\n",
       " 'anecdotes',\n",
       " 'sephardic',\n",
       " 'mia',\n",
       " 'corollaries',\n",
       " 'debaters',\n",
       " 'esse',\n",
       " 'input',\n",
       " 'shigella',\n",
       " 'conventionally',\n",
       " 'katha',\n",
       " 'recently',\n",
       " 'satara',\n",
       " 'condense',\n",
       " 'fretless',\n",
       " 'virginals',\n",
       " 'jeong',\n",
       " 'khaldun',\n",
       " 'mutinies',\n",
       " 'polyanin',\n",
       " 'endomorphisms',\n",
       " 'dewar',\n",
       " 'lfo',\n",
       " 'knocks',\n",
       " 'soba',\n",
       " 'vonnegut',\n",
       " 'sax',\n",
       " 'pining',\n",
       " 'prove',\n",
       " 'ideology',\n",
       " 'shattering',\n",
       " 'warrens',\n",
       " 'mayne',\n",
       " 'accuracy',\n",
       " 'goff',\n",
       " 'kashi',\n",
       " 'fragrance',\n",
       " 'tunics',\n",
       " 'lkerwanderung']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = random.sample(range(0, len(X)), 100)\n",
    "result_random = result[ind]\n",
    "all_words = list(model.wv.vocab)\n",
    "words = [all_words[i] for i in ind]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:16:01.356507Z",
     "start_time": "2019-10-07T14:16:00.523853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(result_random[:, 0], result_random[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result_random[i, 0], result_random[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with vector size 50: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:17:08.463522Z",
     "start_time": "2019-10-07T14:16:05.218672Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = Word2Vec(sentences, size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:19:15.223273Z",
     "start_time": "2019-10-07T14:17:08.485627Z"
    }
   },
   "outputs": [],
   "source": [
    "model3 = Word2Vec(sentences, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:19:15.532138Z",
     "start_time": "2019-10-07T14:19:15.288592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model with vector default size \n",
      ":\n",
      "[('queen', 0.693665623664856), ('princess', 0.6304328441619873), ('prince', 0.6225016713142395), ('emperor', 0.6130492091178894), ('elizabeth', 0.5962637066841125), ('empress', 0.589701771736145), ('daughter', 0.5871102213859558), ('throne', 0.5866202116012573), ('isabella', 0.5824654698371887), ('sigismund', 0.5815116763114929)]\n",
      "\n",
      " Model with vector size 50 \n",
      "[('prince', 0.7527000308036804), ('queen', 0.7450971603393555), ('empress', 0.7407457232475281), ('son', 0.7010347843170166), ('isabella', 0.6900959014892578), ('emperor', 0.6885149478912354), ('throne', 0.6865389943122864), ('princess', 0.6837332248687744), ('regent', 0.6822634339332581), ('viii', 0.6733502149581909)]\n",
      "\n",
      " Model with vector size 300 \n",
      "[('queen', 0.6468744277954102), ('prince', 0.567291259765625), ('princess', 0.5601068735122681), ('isabella', 0.5475542545318604), ('elizabeth', 0.5470207929611206), ('empress', 0.5431647896766663), ('throne', 0.5399587154388428), ('daughter', 0.5315943956375122), ('emperor', 0.5204334259033203), ('son', 0.5081612467765808)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Model with vector default size \\n:\")\n",
    "print(model.wv.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "print(\"\\n Model with vector size 50 \")\n",
    "print(model2.wv.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "print(\"\\n Model with vector size 300 \")\n",
    "print(model3.wv.most_similar(positive=['woman', 'king'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:20:55.933641Z",
     "start_time": "2019-10-07T14:20:48.982706Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie reivews using word2vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:20:56.013296Z",
     "start_time": "2019-10-07T14:20:56.005533Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:25:19.543394Z",
     "start_time": "2019-10-07T14:21:00.292156Z"
    }
   },
   "outputs": [],
   "source": [
    "# skip gram model:\n",
    "model_sg = Word2Vec(sentences, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:29:37.876210Z",
     "start_time": "2019-10-07T14:28:45.258684Z"
    }
   },
   "outputs": [],
   "source": [
    "model_brown = Word2Vec(brown.sents(), sg=1)\n",
    "model_reviews = Word2Vec(movie_reviews.sents(), sg=1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:30:28.430097Z",
     "start_time": "2019-10-07T14:30:28.416866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('credit', 0.7630125284194946),\n",
       " ('dividends', 0.7604372501373291),\n",
       " ('specie', 0.7495940327644348),\n",
       " ('repay', 0.7461877465248108),\n",
       " ('repayment', 0.743943989276886)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:30:46.000620Z",
     "start_time": "2019-10-07T14:30:45.954967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('care', 0.8486089706420898),\n",
       " ('job', 0.8463981747627258),\n",
       " ('friendship', 0.8380179405212402),\n",
       " ('permission', 0.8346951007843018),\n",
       " ('chances', 0.8309653401374817)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_brown.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:31:08.061065Z",
     "start_time": "2019-10-07T14:31:08.046408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cash', 0.7365164160728455),\n",
       " ('bucks', 0.7025608420372009),\n",
       " ('ransom', 0.6767388582229614),\n",
       " ('risk', 0.6708565950393677),\n",
       " ('pact', 0.6623475551605225)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reviews.wv.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:31:37.507644Z",
     "start_time": "2019-10-07T14:31:37.491420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('newsreel', 0.7679038047790527),\n",
       " ('buccaneer', 0.7525641918182373),\n",
       " ('showgirl', 0.7456099390983582),\n",
       " ('petherbridge', 0.7437957525253296),\n",
       " ('kidd', 0.7401689887046814)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar('titanic', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:32:05.372221Z",
     "start_time": "2019-10-07T14:32:05.361446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('caligula', 0.7983949184417725),\n",
       " ('flubber', 0.7914865016937256),\n",
       " ('mummy', 0.7904785871505737),\n",
       " ('jackal', 0.7850232124328613),\n",
       " ('sphere', 0.7769988179206848)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reviews.wv.most_similar('titanic', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:44:40.081332Z",
     "start_time": "2019-10-07T14:44:40.073832Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:44:50.090450Z",
     "start_time": "2019-10-07T14:44:50.085107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function glove2word2vec in module gensim.scripts.glove2word2vec:\n",
      "\n",
      "glove2word2vec(glove_input_file, word2vec_output_file)\n",
      "    Convert `glove_input_file` in GloVe format to word2vec format and write it to `word2vec_output_file`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    glove_input_file : str\n",
      "        Path to file in GloVe format.\n",
      "    word2vec_output_file: str\n",
      "        Path to output file.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    (int, int)\n",
      "        Number of vectors (lines) of input file and its dimension.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(glove2word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:54:23.258721Z",
     "start_time": "2019-10-07T14:54:23.118419Z"
    }
   },
   "source": [
    "# Classification of news articles: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessery libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:19:27.938056Z",
     "start_time": "2019-10-07T15:19:27.933941Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:23:59.983712Z",
     "start_time": "2019-10-07T15:23:59.979777Z"
    }
   },
   "outputs": [],
   "source": [
    "train_url = 'https://cdn.upgrad.com/UpGrad/temp/cd04044e-8945-459e-b582-029665159a16/r8-train-all-terms.txt'\n",
    "test_url = 'https://cdn.upgrad.com/UpGrad/temp/fe81269b-6a02-474e-a88f-c15478e169f8/r8-test-all-terms.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:36:39.084965Z",
     "start_time": "2019-10-07T15:36:38.884097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of training examples: 5485\n"
     ]
    }
   ],
   "source": [
    "opener = urlopen(train_url)\n",
    "x, y = [], []\n",
    "for line in opener:\n",
    "    label, text = line.decode(\"utf-8\").split('\\t')\n",
    "    x.append(text)\n",
    "    y.append(label)\n",
    "\n",
    "x, y = np.array(x), np.array(y)\n",
    "print('No.of training examples:', len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:38:14.844346Z",
     "start_time": "2019-10-07T15:38:14.436616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.ofo test examples: 2189\n"
     ]
    }
   ],
   "source": [
    "opener = urlopen(test_url)\n",
    "x_test, y_test = [], []\n",
    "for line in opener:\n",
    "    label, text = line.decode('utf-8').split('\\t')\n",
    "    x_test.append(text)\n",
    "    y_test.append(label)\n",
    "\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "print('No.ofo test examples:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:39:11.458603Z",
     "start_time": "2019-10-07T15:39:11.443032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['acq', 'crude', 'earn', 'grain', 'interest', 'money-fx', 'ship',\n",
       "        'trade'], dtype='<U8'),\n",
       " array([ 696,  121, 1083,   10,   81,   87,   36,   75]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:46:37.505768Z",
     "start_time": "2019-10-07T15:46:37.332764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter \n",
      " \n",
      "\n",
      "asian exporters fear damage from u s japan rift mounting trade friction between the u s and japan has raised fears among many of asia s exporting nations that the row could inflict far reaching economic damage businessmen and officials said they told reuter correspondents in asian capitals a u s move against japan might boost protectionist sentiment in the u s and lead to curbs on american imports of their products but some exporters said that while the conflict would hurt them in the long run in the short term tokyo s loss might be their gain the u s has said it will impose mln dlrs of tariffs on imports of japanese electronics goods on april in retaliation for japan s alleged failure to stick to a pact not to sell semiconductors on world markets at below cost unofficial japanese estimates put the impact of the tariffs at billion dlrs and spokesmen for major electronics firms said they would virtually halt exports of products hit by the new taxes we wouldn t be able to do business said a spokesman for leading japanese electronics firm matsushita electric industrial co ltd mc t if the tariffs remain in place for any length of time beyond a few months it will mean the complete erosion of exports of goods subject to tariffs to the u s said tom murtha a stock analyst at the tokyo office of broker james capel and co in taiwan businessmen and officials are also worried we are aware of the seriousness of the u s threat against japan because it serves as a warning to us said a senior taiwanese trade official who asked not to be named taiwan had a trade trade surplus of billion dlrs last year pct of it with the u s the surplus helped swell taiwan s foreign exchange reserves to billion dlrs among the world s largest we must quickly open our markets remove trade barriers and cut import tariffs to allow imports of u s products if we want to defuse problems from possible u s retaliation said paul sheen chairman of textile exporters taiwan safe group a senior official of south korea s trade promotion association said the trade dispute between the u s and japan might also lead to pressure on south korea whose chief exports are similar to those of japan last year south korea had a trade surplus of billion dlrs with the u s up from billion dlrs in in malaysia trade officers and businessmen said tough curbs against japan might allow hard hit producers of semiconductors in third countries to expand their sales to the u s in hong kong where newspapers have alleged japan has been selling below cost semiconductors some electronics manufacturers share that view but other businessmen said such a short term commercial advantage would be outweighed by further u s pressure to block imports that is a very short term view said lawrence mills director general of the federation of hong kong industry if the whole purpose is to prevent imports one day it will be extended to other sources much more serious for hong kong is the disadvantage of action restraining trade he said the u s last year was hong kong s biggest export market accounting for over pct of domestically produced exports the australian government is awaiting the outcome of trade talks between the u s and japan with interest and concern industry minister john button said in canberra last friday this kind of deterioration in trade relations between two countries which are major trading partners of ours is a very serious matter button said he said australia s concerns centred on coal and beef australia s two largest exports to japan and also significant u s exports to that country meanwhile u s japanese diplomatic manoeuvres to solve the trade stand off continue japan s ruling liberal democratic party yesterday outlined a package of economic measures to boost the japanese economy the measures proposed include a large supplementary budget and record public works spending in the first half of the financial year they also call for stepped up spending as an emergency measure to stimulate the economy despite prime minister yasuhiro nakasone s avowed fiscal reform program deputy u s trade representative michael smith and makoto kuroda japan s deputy minister of international trade and industry miti are due to meet in washington this week in an effort to end the dispute reuter \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = [\"\".join(sent) for sent in x]\n",
    "print(x_train[0], '\\n')\n",
    "x_test_str = [\"\".join(sent) for sent in x_test]\n",
    "print(x_test_str[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:48:01.568137Z",
     "start_time": "2019-10-07T15:48:01.561156Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:48:48.611465Z",
     "start_time": "2019-10-07T15:48:48.545276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CountVectorizer in module sklearn.feature_extraction.text:\n",
      "\n",
      "class CountVectorizer(sklearn.base.BaseEstimator, VectorizerMixin)\n",
      " |  CountVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n",
      " |  \n",
      " |  Convert a collection of text documents to a matrix of token counts\n",
      " |  \n",
      " |  This implementation produces a sparse representation of the counts using\n",
      " |  scipy.sparse.csr_matrix.\n",
      " |  \n",
      " |  If you do not provide an a-priori dictionary and you do not use an analyzer\n",
      " |  that does some kind of feature selection then the number of features will\n",
      " |  be equal to the vocabulary size found by analyzing the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  input : string {'filename', 'file', 'content'}\n",
      " |      If 'filename', the sequence passed as an argument to fit is\n",
      " |      expected to be a list of filenames that need reading to fetch\n",
      " |      the raw content to analyze.\n",
      " |  \n",
      " |      If 'file', the sequence items must have a 'read' method (file-like\n",
      " |      object) that is called to fetch the bytes in memory.\n",
      " |  \n",
      " |      Otherwise the input is expected to be the sequence strings or\n",
      " |      bytes items are expected to be analyzed directly.\n",
      " |  \n",
      " |  encoding : string, 'utf-8' by default.\n",
      " |      If bytes or files are given to analyze, this encoding is used to\n",
      " |      decode.\n",
      " |  \n",
      " |  decode_error : {'strict', 'ignore', 'replace'}\n",
      " |      Instruction on what to do if a byte sequence is given to analyze that\n",
      " |      contains characters not of the given `encoding`. By default, it is\n",
      " |      'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      " |      values are 'ignore' and 'replace'.\n",
      " |  \n",
      " |  strip_accents : {'ascii', 'unicode', None}\n",
      " |      Remove accents and perform other character normalization\n",
      " |      during the preprocessing step.\n",
      " |      'ascii' is a fast method that only works on characters that have\n",
      " |      an direct ASCII mapping.\n",
      " |      'unicode' is a slightly slower method that works on any characters.\n",
      " |      None (default) does nothing.\n",
      " |  \n",
      " |      Both 'ascii' and 'unicode' use NFKD normalization from\n",
      " |      :func:`unicodedata.normalize`.\n",
      " |  \n",
      " |  lowercase : boolean, True by default\n",
      " |      Convert all characters to lowercase before tokenizing.\n",
      " |  \n",
      " |  preprocessor : callable or None (default)\n",
      " |      Override the preprocessing (string transformation) stage while\n",
      " |      preserving the tokenizing and n-grams generation steps.\n",
      " |  \n",
      " |  tokenizer : callable or None (default)\n",
      " |      Override the string tokenization step while preserving the\n",
      " |      preprocessing and n-grams generation steps.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |  stop_words : string {'english'}, list, or None (default)\n",
      " |      If 'english', a built-in stop word list for English is used.\n",
      " |      There are several known issues with 'english' and you should\n",
      " |      consider an alternative (see :ref:`stop_words`).\n",
      " |  \n",
      " |      If a list, that list is assumed to contain stop words, all of which\n",
      " |      will be removed from the resulting tokens.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |      If None, no stop words will be used. max_df can be set to a value\n",
      " |      in the range [0.7, 1.0) to automatically detect and filter stop\n",
      " |      words based on intra corpus document frequency of terms.\n",
      " |  \n",
      " |  token_pattern : string\n",
      " |      Regular expression denoting what constitutes a \"token\", only used\n",
      " |      if ``analyzer == 'word'``. The default regexp select tokens of 2\n",
      " |      or more alphanumeric characters (punctuation is completely ignored\n",
      " |      and always treated as a token separator).\n",
      " |  \n",
      " |  ngram_range : tuple (min_n, max_n)\n",
      " |      The lower and upper boundary of the range of n-values for different\n",
      " |      n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      " |      will be used.\n",
      " |  \n",
      " |  analyzer : string, {'word', 'char', 'char_wb'} or callable\n",
      " |      Whether the feature should be made of word or character n-grams.\n",
      " |      Option 'char_wb' creates character n-grams only from text inside\n",
      " |      word boundaries; n-grams at the edges of words are padded with space.\n",
      " |  \n",
      " |      If a callable is passed it is used to extract the sequence of features\n",
      " |      out of the raw, unprocessed input.\n",
      " |  \n",
      " |  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly higher than the given threshold (corpus-specific\n",
      " |      stop words).\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  min_df : float in range [0.0, 1.0] or int, default=1\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly lower than the given threshold. This value is also\n",
      " |      called cut-off in the literature.\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  max_features : int or None, default=None\n",
      " |      If not None, build a vocabulary that only consider the top\n",
      " |      max_features ordered by term frequency across the corpus.\n",
      " |  \n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  vocabulary : Mapping or iterable, optional\n",
      " |      Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      " |      indices in the feature matrix, or an iterable over terms. If not\n",
      " |      given, a vocabulary is determined from the input documents. Indices\n",
      " |      in the mapping should not be repeated and should not have any gap\n",
      " |      between 0 and the largest index.\n",
      " |  \n",
      " |  binary : boolean, default=False\n",
      " |      If True, all non zero counts are set to 1. This is useful for discrete\n",
      " |      probabilistic models that model binary events rather than integer\n",
      " |      counts.\n",
      " |  \n",
      " |  dtype : type, optional\n",
      " |      Type of the matrix returned by fit_transform() or transform().\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  vocabulary_ : dict\n",
      " |      A mapping of terms to feature indices.\n",
      " |  \n",
      " |  stop_words_ : set\n",
      " |      Terms that were ignored because they either:\n",
      " |  \n",
      " |        - occurred in too many documents (`max_df`)\n",
      " |        - occurred in too few documents (`min_df`)\n",
      " |        - were cut off by feature selection (`max_features`).\n",
      " |  \n",
      " |      This is only available if no vocabulary was given.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.feature_extraction.text import CountVectorizer\n",
      " |  >>> corpus = [\n",
      " |  ...     'This is the first document.',\n",
      " |  ...     'This document is the second document.',\n",
      " |  ...     'And this is the third one.',\n",
      " |  ...     'Is this the first document?',\n",
      " |  ... ]\n",
      " |  >>> vectorizer = CountVectorizer()\n",
      " |  >>> X = vectorizer.fit_transform(corpus)\n",
      " |  >>> print(vectorizer.get_feature_names())\n",
      " |  ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      " |  >>> print(X.toarray())  # doctest: +NORMALIZE_WHITESPACE\n",
      " |  [[0 1 1 1 0 0 1 0 1]\n",
      " |   [0 2 0 1 0 1 1 0 1]\n",
      " |   [1 0 0 1 1 0 1 1 1]\n",
      " |   [0 1 1 1 0 0 1 0 1]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  HashingVectorizer, TfidfVectorizer\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The ``stop_words_`` attribute can get large and increase the model size\n",
      " |  when pickling. This attribute is provided only for introspection and can\n",
      " |  be safely removed using delattr or set to None before pickling.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CountVectorizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      VectorizerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, raw_documents, y=None)\n",
      " |      Learn a vocabulary dictionary of all tokens in the raw documents.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, raw_documents, y=None)\n",
      " |      Learn the vocabulary dictionary and return term-document matrix.\n",
      " |      \n",
      " |      This is equivalent to fit followed by transform, but more efficiently\n",
      " |      implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  get_feature_names(self)\n",
      " |      Array mapping from feature integer indices to feature name\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Return terms per document with nonzero entries in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array, sparse matrix}, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_inv : list of arrays, len = n_samples\n",
      " |          List of arrays of terms.\n",
      " |  \n",
      " |  transform(self, raw_documents)\n",
      " |      Transform documents to document-term matrix.\n",
      " |      \n",
      " |      Extract token counts out of raw text documents using the vocabulary\n",
      " |      fitted with fit or the one provided to the constructor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from VectorizerMixin:\n",
      " |  \n",
      " |  build_analyzer(self)\n",
      " |      Return a callable that handles preprocessing and tokenization\n",
      " |  \n",
      " |  build_preprocessor(self)\n",
      " |      Return a function to preprocess the text before tokenization\n",
      " |  \n",
      " |  build_tokenizer(self)\n",
      " |      Return a function that splits a string into a sequence of tokens\n",
      " |  \n",
      " |  decode(self, doc)\n",
      " |      Decode the input into a string of unicode symbols\n",
      " |      \n",
      " |      The decoding strategy depends on the vectorizer parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      doc : string\n",
      " |          The string to decode\n",
      " |  \n",
      " |  get_stop_words(self)\n",
      " |      Build or fetch the effective stop words list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the test and training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:53:44.067857Z",
     "start_time": "2019-10-07T15:53:43.610295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:54:30.202093Z",
     "start_time": "2019-10-07T15:54:29.733235Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_str = vectorizer.transform(x_test_str)\n",
    "x_train = vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:56:23.315737Z",
     "start_time": "2019-10-07T15:56:23.306208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stock': 88,\n",
       " 'split': 84,\n",
       " 'said': 74,\n",
       " 'board': 12,\n",
       " 'common': 16,\n",
       " 'shares': 81,\n",
       " 'shareholders': 80,\n",
       " 'record': 70,\n",
       " 'april': 6,\n",
       " 'company': 18,\n",
       " 'meeting': 47,\n",
       " 'increase': 39,\n",
       " 'mln': 49,\n",
       " 'reuter': 72,\n",
       " 'sale': 75,\n",
       " 'dlrs': 25,\n",
       " 'price': 61,\n",
       " 'share': 79,\n",
       " 'buy': 14,\n",
       " 'total': 93,\n",
       " 'pct': 59,\n",
       " 'market': 46,\n",
       " 'pay': 58,\n",
       " 'current': 21,\n",
       " 'year': 99,\n",
       " 'net': 51,\n",
       " 'shr': 82,\n",
       " 'cts': 20,\n",
       " 'vs': 96,\n",
       " 'assets': 7,\n",
       " 'note': 53,\n",
       " 'th': 90,\n",
       " 'qtr': 66,\n",
       " 'includes': 38,\n",
       " 'gain': 34,\n",
       " 'tax': 89,\n",
       " 'international': 40,\n",
       " 'oper': 56,\n",
       " 'loss': 44,\n",
       " 'profit': 64,\n",
       " 'revs': 73,\n",
       " 'avg': 8,\n",
       " 'shrs': 83,\n",
       " 'results': 71,\n",
       " 'prior': 63,\n",
       " 'dlr': 24,\n",
       " 'billion': 11,\n",
       " 'earnings': 27,\n",
       " 'quarter': 67,\n",
       " 'told': 92,\n",
       " 'analysts': 5,\n",
       " 'sales': 76,\n",
       " 'earlier': 26,\n",
       " 'president': 60,\n",
       " 'acquisition': 0,\n",
       " 'japan': 42,\n",
       " 'corp': 19,\n",
       " 'cash': 15,\n",
       " 'dividend': 23,\n",
       " 'march': 45,\n",
       " 'new': 52,\n",
       " 'today': 91,\n",
       " 'operations': 57,\n",
       " 'rates': 69,\n",
       " 'expected': 30,\n",
       " 'div': 22,\n",
       " 'business': 13,\n",
       " 'qtly': 65,\n",
       " 'months': 50,\n",
       " 'offer': 54,\n",
       " 'companies': 17,\n",
       " 'rate': 68,\n",
       " 'prices': 62,\n",
       " 'foreign': 33,\n",
       " 'february': 31,\n",
       " 'bank': 9,\n",
       " 'trade': 94,\n",
       " 'government': 36,\n",
       " 'end': 28,\n",
       " 'unit': 95,\n",
       " 'exchange': 29,\n",
       " 'week': 97,\n",
       " 'added': 1,\n",
       " 'group': 37,\n",
       " 'oil': 55,\n",
       " 'financial': 32,\n",
       " 'banks': 10,\n",
       " 'merger': 48,\n",
       " 'investment': 41,\n",
       " 'stake': 86,\n",
       " 'securities': 77,\n",
       " 'american': 4,\n",
       " 'sell': 78,\n",
       " 'agreement': 3,\n",
       " 'world': 98,\n",
       " 'agreed': 2,\n",
       " 'general': 35,\n",
       " 'spokesman': 85,\n",
       " 'japanese': 43,\n",
       " 'stg': 87}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using naive bayes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:56:43.630733Z",
     "start_time": "2019-10-07T15:56:43.626328Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:57:06.817940Z",
     "start_time": "2019-10-07T15:57:06.804286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BernoulliNB in module sklearn.naive_bayes:\n",
      "\n",
      "class BernoulliNB(BaseDiscreteNB)\n",
      " |  BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)\n",
      " |  \n",
      " |  Naive Bayes classifier for multivariate Bernoulli models.\n",
      " |  \n",
      " |  Like MultinomialNB, this classifier is suitable for discrete data. The\n",
      " |  difference is that while MultinomialNB works with occurrence counts,\n",
      " |  BernoulliNB is designed for binary/boolean features.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <bernoulli_naive_bayes>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, optional (default=1.0)\n",
      " |      Additive (Laplace/Lidstone) smoothing parameter\n",
      " |      (0 for no smoothing).\n",
      " |  \n",
      " |  binarize : float or None, optional (default=0.0)\n",
      " |      Threshold for binarizing (mapping to booleans) of sample features.\n",
      " |      If None, input is presumed to already consist of binary vectors.\n",
      " |  \n",
      " |  fit_prior : boolean, optional (default=True)\n",
      " |      Whether to learn class prior probabilities or not.\n",
      " |      If false, a uniform prior will be used.\n",
      " |  \n",
      " |  class_prior : array-like, size=[n_classes,], optional (default=None)\n",
      " |      Prior probabilities of the classes. If specified the priors are not\n",
      " |      adjusted according to the data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_log_prior_ : array, shape = [n_classes]\n",
      " |      Log probability of each class (smoothed).\n",
      " |  \n",
      " |  feature_log_prob_ : array, shape = [n_classes, n_features]\n",
      " |      Empirical log probability of features given a class, P(x_i|y).\n",
      " |  \n",
      " |  class_count_ : array, shape = [n_classes]\n",
      " |      Number of samples encountered for each class during fitting. This\n",
      " |      value is weighted by the sample weight when provided.\n",
      " |  \n",
      " |  feature_count_ : array, shape = [n_classes, n_features]\n",
      " |      Number of samples encountered for each (class, feature)\n",
      " |      during fitting. This value is weighted by the sample weight when\n",
      " |      provided.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.random.randint(2, size=(6, 100))\n",
      " |  >>> Y = np.array([1, 2, 3, 4, 4, 5])\n",
      " |  >>> from sklearn.naive_bayes import BernoulliNB\n",
      " |  >>> clf = BernoulliNB()\n",
      " |  >>> clf.fit(X, Y)\n",
      " |  BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      " |  >>> print(clf.predict(X[2:3]))\n",
      " |  [3]\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n",
      " |  Information Retrieval. Cambridge University Press, pp. 234-265.\n",
      " |  http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html\n",
      " |  \n",
      " |  A. McCallum and K. Nigam (1998). A comparison of event models for naive\n",
      " |  Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for\n",
      " |  Text Categorization, pp. 41-48.\n",
      " |  \n",
      " |  V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with\n",
      " |  naive Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BernoulliNB\n",
      " |      BaseDiscreteNB\n",
      " |      BaseNB\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDiscreteNB:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Naive Bayes classifier according to X, y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Incremental fit on a batch of samples.\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different chunks of a dataset so as to implement out-of-core\n",
      " |      or online learning.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to fit in\n",
      " |      memory at once.\n",
      " |      \n",
      " |      This method has some performance overhead hence it is better to call\n",
      " |      partial_fit on chunks of data that are as large as possible\n",
      " |      (as long as fitting in the memory budget) to hide the overhead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      classes : array-like, shape = [n_classes] (default=None)\n",
      " |          List of all the classes that can possibly appear in the y vector.\n",
      " |      \n",
      " |          Must be provided at the first call to partial_fit, can be omitted\n",
      " |          in subsequent calls.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDiscreteNB:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  intercept_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseNB:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted target values for X\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return log-probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T15:57:43.937169Z",
     "start_time": "2019-10-07T15:57:43.931130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5485,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:14:38.224319Z",
     "start_time": "2019-10-07T16:14:38.213571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:14:38.674785Z",
     "start_time": "2019-10-07T16:14:38.666259Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test_str)\n",
    "y_train_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:14:39.085862Z",
     "start_time": "2019-10-07T16:14:39.074438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy with bernoulli naive bayes: 0.9026952946550937\n",
      "Training accuracy with bernoulli naive bayes: 0.8638103919781221\n"
     ]
    }
   ],
   "source": [
    "print(\"testing accuracy with bernoulli naive bayes:\", accuracy_score(y_test, y_test_pred)) \n",
    "print(\"Training accuracy with bernoulli naive bayes:\", accuracy_score(y, y_train_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial naive bayes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:06:11.611920Z",
     "start_time": "2019-10-07T16:06:11.604696Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:07:48.520980Z",
     "start_time": "2019-10-07T16:07:48.509819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_model =  MultinomialNB()\n",
    "multinomial_model.fit(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:12:47.307594Z",
     "start_time": "2019-10-07T16:12:47.299339Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = multinomial_model.predict(x_test_str)\n",
    "y_train_pred = multinomial_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T16:12:47.947801Z",
     "start_time": "2019-10-07T16:12:47.939798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy with bernoulli naive bayes: 0.9086340794883508\n",
      "Training accuracy with bernoulli naive bayes: 0.8842297174111212\n"
     ]
    }
   ],
   "source": [
    "print(\"testing accuracy with bernoulli naive bayes:\", accuracy_score(y_test, y_test_pred)) \n",
    "print(\"Training accuracy with bernoulli naive bayes:\", accuracy_score(y, y_train_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word embedding approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
