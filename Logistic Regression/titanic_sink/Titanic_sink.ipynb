{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description: \n",
    "\n",
    "    The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "    One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "    In this challenge, complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:14:51.045522Z",
     "start_time": "2019-09-02T12:14:51.030852Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:41.903534Z",
     "start_time": "2019-09-01T18:41:41.875329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv', engine='python', sep=\",\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:42.174177Z",
     "start_time": "2019-09-01T18:41:42.139988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv', engine='python', sep=\",\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:42.387878Z",
     "start_time": "2019-09-01T18:41:42.379744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:42.586409Z",
     "start_time": "2019-09-01T18:41:42.580661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:42.790929Z",
     "start_time": "2019-09-01T18:41:42.775271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:42.982210Z",
     "start_time": "2019-09-01T18:41:42.972613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===> unique values count:\n",
    "train_data.PassengerId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:43.209678Z",
     "start_time": "2019-09-01T18:41:43.202907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:43.429626Z",
     "start_time": "2019-09-01T18:41:43.424008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:43.647010Z",
     "start_time": "2019-09-01T18:41:43.633542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:43.901507Z",
     "start_time": "2019-09-01T18:41:43.888484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    176\n",
      "2     16\n",
      "3     12\n",
      "Name: Pclass, dtype: int64\n",
      "1    136\n",
      "0     68\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data.Cabin.value_counts().head(10)\n",
    "print(train_data[train_data.Cabin.isnull() == False]['Pclass'].value_counts())\n",
    "print(train_data[train_data.Cabin.isnull() == False]['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:44.106931Z",
     "start_time": "2019-09-01T18:41:44.099171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:44.332735Z",
     "start_time": "2019-09-01T18:41:44.322888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:44.560308Z",
     "start_time": "2019-09-01T18:41:44.551620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Ticket.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:44.799922Z",
     "start_time": "2019-09-01T18:41:44.773988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  TicketCoPassengers  \n",
       "0      0         A/5 21171   7.2500   NaN        S                   0  \n",
       "1      0          PC 17599  71.2833   C85        C                   0  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S                   0  \n",
       "3      0            113803  53.1000  C123        S                   1  \n",
       "4      0            373450   8.0500   NaN        S                   0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train_data.Ticket.value_counts()\n",
    "train_data['TicketCoPassengers'] = train_data.Ticket.apply(lambda x: t[x]-1) \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:45.024238Z",
     "start_time": "2019-09-01T18:41:45.011026Z"
    }
   },
   "outputs": [],
   "source": [
    "t = test_data.Ticket.value_counts()\n",
    "test_data['TicketCoPassengers'] = test_data.Ticket.apply(lambda x: t[x]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:45.256868Z",
     "start_time": "2019-09-01T18:41:45.243266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601            7\n",
       "347082          7\n",
       "CA. 2343        7\n",
       "347088          6\n",
       "3101295         6\n",
       "CA 2144         6\n",
       "S.O.C. 14879    5\n",
       "382652          5\n",
       "113781          4\n",
       "347077          4\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Ticket.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:45.506711Z",
     "start_time": "2019-09-01T18:41:45.493451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cherry, Miss. Gladys</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>86.5</td>\n",
       "      <td>B77</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Maioni, Miss. Roberta</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>86.5</td>\n",
       "      <td>B79</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rothes, the Countess. of (Lucy Noel Martha Dye...</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>86.5</td>\n",
       "      <td>B77</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "257          258         1       1   \n",
       "504          505         1       1   \n",
       "759          760         1       1   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "257                               Cherry, Miss. Gladys  female  30.0      0   \n",
       "504                              Maioni, Miss. Roberta  female  16.0      0   \n",
       "759  Rothes, the Countess. of (Lucy Noel Martha Dye...  female  33.0      0   \n",
       "\n",
       "     Parch  Ticket  Fare Cabin Embarked  TicketCoPassengers  \n",
       "257      0  110152  86.5   B77        S                   2  \n",
       "504      0  110152  86.5   B79        S                   2  \n",
       "759      0  110152  86.5   B77        S                   2  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.Ticket == '110152']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:45.691209Z",
     "start_time": "2019-09-01T18:41:45.680119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket\n",
       "110152    3\n",
       "110413    3\n",
       "110465    2\n",
       "110564    1\n",
       "110813    1\n",
       "Name: TicketCoPassengers, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Ticket').TicketCoPassengers.count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:45.862047Z",
     "start_time": "2019-09-01T18:41:45.851757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId           891 non-null int64\n",
      "Survived              891 non-null int64\n",
      "Pclass                891 non-null int64\n",
      "Name                  891 non-null object\n",
      "Sex                   891 non-null object\n",
      "Age                   714 non-null float64\n",
      "SibSp                 891 non-null int64\n",
      "Parch                 891 non-null int64\n",
      "Ticket                891 non-null object\n",
      "Fare                  891 non-null float64\n",
      "Cabin                 204 non-null object\n",
      "Embarked              889 non-null object\n",
      "TicketCoPassengers    891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:46.764388Z",
     "start_time": "2019-09-01T18:41:46.738070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  TicketCoPassengers  \n",
       "0      0         A/5 21171   7.2500   NaN        S                   0  \n",
       "1      0          PC 17599  71.2833   C85        C                   0  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S                   0  \n",
       "3      0            113803  53.1000  C123        S                   1  \n",
       "4      0            373450   8.0500   NaN        S                   0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:47.028867Z",
     "start_time": "2019-09-01T18:41:47.011075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId           0.000000\n",
       "Survived              0.000000\n",
       "Pclass                0.000000\n",
       "Name                  0.000000\n",
       "Sex                   0.000000\n",
       "Age                   0.198653\n",
       "SibSp                 0.000000\n",
       "Parch                 0.000000\n",
       "Ticket                0.000000\n",
       "Fare                  0.000000\n",
       "Cabin                 0.771044\n",
       "Embarked              0.002245\n",
       "TicketCoPassengers    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum(axis=0) / train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:47.287675Z",
     "start_time": "2019-09-01T18:41:47.243223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>male</td>\n",
       "      <td>1601</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name   Sex Ticket    Cabin  \\\n",
       "count                                            891   891    891      204   \n",
       "unique                                           891     2    681      147   \n",
       "top     Shelley, Mrs. William (Imanita Parrish Hall)  male   1601  B96 B98   \n",
       "freq                                               1   577      7        4   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:47.523984Z",
     "start_time": "2019-09-01T18:41:47.509952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0    30\n",
       "22.0    27\n",
       "18.0    26\n",
       "19.0    25\n",
       "30.0    25\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Age.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:49.845178Z",
     "start_time": "2019-09-01T18:41:49.607709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a245fda58>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_data.Fare.dropna(), kde=False, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No.of co-passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:50.512912Z",
     "start_time": "2019-09-01T18:41:50.037605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a247ded68>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_data.TicketCoPassengers.dropna(), kde=False, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:50.890738Z",
     "start_time": "2019-09-01T18:41:50.705749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2369d0b8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data.Embarked.fillna('NoClass'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:51.221940Z",
     "start_time": "2019-09-01T18:41:51.073495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2377b390>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family siblings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:51.645291Z",
     "start_time": "2019-09-01T18:41:51.446170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a245a3ba8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data.Parch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-variate analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:51.964931Z",
     "start_time": "2019-09-01T18:41:51.797068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a247f2cc0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(hue='Survived', x='Parch', orient='h', data=train_data, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:52.246627Z",
     "start_time": "2019-09-01T18:41:52.227972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId           891 non-null int64\n",
      "Survived              891 non-null int64\n",
      "Pclass                891 non-null int64\n",
      "Name                  891 non-null object\n",
      "Sex                   891 non-null object\n",
      "Age                   714 non-null float64\n",
      "SibSp                 891 non-null int64\n",
      "Parch                 891 non-null int64\n",
      "Ticket                891 non-null object\n",
      "Fare                  891 non-null float64\n",
      "Cabin                 204 non-null object\n",
      "Embarked              889 non-null object\n",
      "TicketCoPassengers    891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked survival rate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:53.320737Z",
     "start_time": "2019-09-01T18:41:53.128095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24814780>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGXdJREFUeJzt3X2UVfV97/H3R0CwQUVhVGTAIYq3QkCiA2qtKcFcH7gWTCpPq1WM5I6Nehdt0txqHhRt6bJpjNeotSGXBEwMD2oshGtsvRqS60PUGYMooAHFyAjVAQ0RLSr4vX+cPXgcfsycgdlzzjCf11pnnb1/5/fb+3s4Cz7sZ0UEZmZmLR1U7gLMzKwyOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJfUsdwH7Y8CAAVFTU1PuMszMupSGhoYtEVHVVr8uHRA1NTXU19eXuwwzsy5F0m9L6eddTGZmluSAMDOzJAeEmZkldeljEGZmHe3999+nsbGRHTt2lLuU/danTx+qq6vp1avXPo13QJiZFWlsbOTQQw+lpqYGSeUuZ59FBFu3bqWxsZGhQ4fu0zK8i8nMrMiOHTvo379/lw4HAEn0799/v7aEHBBmZi109XBotr/fwwFhZmZJDggzsxLMmTOHESNGMGrUKEaPHs0TTzyx38tctmwZN954YwdUB3379u2Q5RTrNgepT/3KneUuod0a/umScpdgZsDjjz/O8uXLefrpp+nduzdbtmzhvffeK2nszp076dkz/U/txIkTmThxYkeW2qG8BWFm1obNmzczYMAAevfuDcCAAQM49thjqampYcuWLQDU19czbtw4AGbPnk1dXR3nnHMOl1xyCaeddhqrV6/evbxx48bR0NDA/Pnzueqqq9i2bRs1NTV88MEHALzzzjsMHjyY999/nxdffJHzzjuPU089lbPOOovnn38egA0bNnDGGWcwZswYvvGNb+TyvR0QZmZtOOecc9i4cSMnnngiV1xxBb/4xS/aHNPQ0MDSpUv58Y9/zLRp01iyZAlQCJtNmzZx6qmn7u57+OGHc/LJJ+9e7k9/+lPOPfdcevXqRV1dHbfeeisNDQ1861vf4oorrgBg1qxZfPGLX+Spp57imGOOyeFbOyDMzNrUt29fGhoamDt3LlVVVUydOpX58+e3OmbixIkccsghAEyZMoW7774bgCVLljB58uQ9+k+dOpXFixcDsGjRIqZOncr27dt57LHHmDx5MqNHj+byyy9n8+bNADz66KNMnz4dgIsvvrijvupHdJtjEGZm+6NHjx6MGzeOcePGMXLkSBYsWEDPnj137xZqeb3Bxz72sd3TgwYNon///qxatYrFixfz3e9+d4/lT5w4kWuuuYY33niDhoYGxo8fz9tvv02/fv1YuXJlsqa8T8f1FoSZWRteeOEF1q1bt3t+5cqVHHfccdTU1NDQ0ADAvffe2+oypk2bxje/+U22bdvGyJEj9/i8b9++jB07llmzZnHBBRfQo0cPDjvsMIYOHbp76yMieOaZZwA488wzWbRoEQB33XVXh3zPlhwQZmZt2L59OzNmzGD48OGMGjWKNWvWMHv2bK677jpmzZrFWWedRY8ePVpdxkUXXcSiRYuYMmXKXvtMnTqVH/3oR0ydOnV321133cW8efM4+eSTGTFiBEuXLgXglltu4fbbb2fMmDFs27atY75oC4qIXBbcGWpra6PUBwb5NFczK8XatWs56aSTyl1Gh0l9H0kNEVHb1lhvQZiZWVLuASGph6RfS1qezQ+V9ISkdZIWSzo4a++dza/PPq/JuzYzM9u7ztiCmAWsLZr/R+DmiBgGvAnMzNpnAm9GxAnAzVk/MzMrk1wDQlI18N+A/53NCxgP3JN1WQBcmE1PyubJPj9bB8otFc3MuqC8tyD+F/A/gQ+y+f7A7yJiZzbfCAzKpgcBGwGyz7dl/c3MrAxyCwhJFwCvR0RDcXOia5TwWfFy6yTVS6pvamrqgErNzCwlzyupzwQmSpoA9AEOo7BF0U9Sz2wroRrYlPVvBAYDjZJ6AocDb7RcaETMBeZC4TTXHOs3M0vq6NPmSzml/YEHHmDWrFns2rWLL3zhC1x99dUdWkNKblsQEXFNRFRHRA0wDXg4Iv4c+DlwUdZtBrA0m16WzZN9/nB05Ys0zMw6yK5du7jyyiv52c9+xpo1a1i4cCFr1qzJfb3luA7ib4EvSVpP4RjDvKx9HtA/a/8SkH88mpl1AU8++SQnnHACH//4xzn44IOZNm3a7iuq89QpN+uLiBXAimz6JWBsos8OYM9bHJqZdXOvvvoqgwcP3j1fXV3dIU+0a4uvpDYzq3Cpve2dcRWAA8LMrMJVV1ezcePG3fONjY0ce+yxua/XAWFmVuHGjBnDunXr2LBhA++99x6LFi3qlGdZ+4FBZmbt1Nl3Wu7Zsye33XYb5557Lrt27eKyyy5jxIgR+a839zWYmdl+mzBhAhMmTOjUdXoXk5mZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszMknyaq5lZO71yw8gOXd6Qa59ts89ll13G8uXLOeqoo3juuec6dP174y0IM7Mu4NJLL+WBBx7o1HU6IMzMuoBPfepTHHnkkZ26TgeEmZkl5flM6j6SnpT0jKTVkq7P2udL2iBpZfYanbVL0nckrZe0StIpedVmZmZty/Mg9bvA+IjYLqkX8Iikn2WffSUi7mnR/3xgWPY6DbgjezczszLI85nUERHbs9le2au1Z0xPAu7Mxv0K6CdpYF71mZlZ63I9zVVSD6ABOAG4PSKekPRFYI6ka4GHgKsj4l1gELCxaHhj1rY5zxrNzNqrlNNSO9r06dNZsWIFW7Zsobq6muuvv56ZM2fmus5cAyIidgGjJfUD7pP0CeAa4D+Ag4G5wN8CNwCp5+ftscUhqQ6oAxgyZEhOlZuZVZaFCxd2+jo75SymiPgdsAI4LyI2Z7uR3gV+AIzNujUCg4uGVQObEsuaGxG1EVFbVVWVc+VmZt1XnmcxVWVbDkg6BPgM8HzzcQUVnrh9IdB8SeAy4JLsbKbTgW0R4d1LZmZlkucupoHAguw4xEHAkohYLulhSVUUdimtBP4y638/MAFYD7wDfD7H2szM9ioiKPwftmuLaO28oLblFhARsQr4ZKJ9/F76B3BlXvWYmZWiT58+bN26lf79+3fpkIgItm7dSp8+ffZ5Gb5Zn5lZkerqahobG2lqaip3KfutT58+VFdX7/N4B4SZWZFevXoxdOjQcpdREXwvJjMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSXl+cjRPpKelPSMpNWSrs/ah0p6QtI6SYslHZy1987m12ef1+RVm5mZtS3PLYh3gfERcTIwGjgve9b0PwI3R8Qw4E1gZtZ/JvBmRJwA3Jz1MzOzMsktIKJgezbbK3sFMB64J2tfAFyYTU/K5sk+P1td+Xl/ZmZdXK7HICT1kLQSeB14EHgR+F1E7My6NAKDsulBwEaA7PNtQP/EMusk1UuqPxAeCWhmVqlyDYiI2BURo4FqYCxwUqpb9p7aWog9GiLmRkRtRNRWVVV1XLFmZvYRnXIWU0T8DlgBnA70k9T8LOxqYFM23QgMBsg+Pxx4ozPqMzOzPeV5FlOVpH7Z9CHAZ4C1wM+Bi7JuM4Cl2fSybJ7s84cjYo8tCDMz6xw92+6yzwYCCyT1oBBESyJiuaQ1wCJJfw/8GpiX9Z8H/FDSegpbDtNyrM3MzNqQW0BExCrgk4n2lygcj2jZvgOYnFc9ZmbWPr6S2szMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkOCDMzS8rziXKDJf1c0lpJqyXNytpnS3pV0srsNaFozDWS1kt6QdK5edVmZmZty/OJcjuBL0fE05IOBRokPZh9dnNEfKu4s6ThFJ4iNwI4Fvi/kk6MiF051mhmZnuR2xZERGyOiKez6bcoPI96UCtDJgGLIuLdiNgArCfx5DkzM+scnXIMQlINhcePPpE1XSVplaTvSzoiaxsEbCwa1kjrgWJmZjkqKSAkPVRK217G9gXuBf4qIn4P3AEcD4wGNgM3NXdNDI/E8uok1Uuqb2pqKqUEMzPbB60GhKQ+ko4EBkg6QtKR2auGwnGCVknqRSEc7oqInwBExGsRsSsiPgC+x4e7kRqBwUXDq4FNLZcZEXMjojYiaquqqtr+hmZmtk/a2oK4HGgA/jB7b34tBW5vbaAkAfOAtRHx7aL2gUXdPgs8l00vA6ZJ6i1pKDAMeLL0r2JmZh2p1bOYIuIW4BZJ/yMibm3nss8ELgaelbQya/sqMF3SaAq7j16mEEJExGpJS4A1FM6AutJnMJmZlU9Jp7lGxK2S/gioKR4TEXe2MuYR0scV7m9lzBxgTik1mZlZvkoKCEk/pHBgeSXQ/L/6APYaEGZm1rWVeqFcLTA8IvY4q8jMzA5MpV4H8RxwTJ6FmJlZZSl1C2IAsEbSk8C7zY0RMTGXqszMrOxKDYjZeRZhZmaVp9SzmH6RdyFmZlZZSj2L6S0+vO3FwUAv4O2IOCyvwszMrLxK3YI4tHhe0oX4TqtmZge0fbqba0T8KzC+g2sxM7MKUuoups8VzR5E4boIXxNhZnYAK/Uspj8tmt5J4R5Kkzq8GjMzqxilHoP4fN6F2J5euWFkuUtotyHXPlvuEsysg5T6wKBqSfdJel3Sa5LulVSdd3FmZlY+pR6k/gGF5zUcS+ExoD/N2szM7ABVakBURcQPImJn9poP+HFuZmYHsFIDYoukv5DUI3v9BbC1tQGSBkv6uaS1klZLmpW1HynpQUnrsvcjsnZJ+o6k9ZJWSTpl/76amZntj1ID4jJgCvAfwGbgIqCtA9c7gS9HxEnA6cCVkoYDVwMPRcQw4KFsHuB8Co8ZHQbUAXe043uYmVkHKzUg/g6YERFVEXEUhcCY3dqAiNgcEU9n028Baykcv5gELMi6LQAuzKYnAXdGwa+Afi2eX21mZp2o1IAYFRFvNs9ExBvAJ0tdiaSarP8TwNERsTlbzmbgqKzbIGBj0bDGrM3MzMqg1IA4qPlYARSOI1D6Vdh9gXuBv4qI37fWNdG2x9Xakuok1Uuqb2pqKqUEMzPbB6VeSX0T8Jikeyj8oz0FmNPWIEm9KITDXRHxk6z5NUkDI2Jztgvp9ay9ERhcNLwa2NRymRExF5gLUFtb69t9mJnlpKQtiIi4E/gz4DWgCfhcRPywtTGSBMwD1kbEt4s+WgbMyKZnAEuL2i/JzmY6HdjWvCvKzMw6X6lbEETEGmBNO5Z9JnAx8KyklVnbV4EbgSWSZgKvAJOzz+4HJgDrgXdo+ywpMzPLUckB0V4R8Qjp4woAZyf6B3BlXvWYmVn77NPzIMzM7MDngDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVlSbgEh6fuSXpf0XFHbbEmvSlqZvSYUfXaNpPWSXpB0bl51mZlZafLcgpgPnJdovzkiRmev+wEkDQemASOyMf8sqUeOtZmZWRtyC4iI+CXwRondJwGLIuLdiNhA4bGjY/OqzczM2laOYxBXSVqV7YI6ImsbBGws6tOYtZmZWZl0dkDcARwPjAY2Azdl7alnV0dqAZLqJNVLqm9qasqnSjMz69yAiIjXImJXRHwAfI8PdyM1AoOLulYDm/ayjLkRURsRtVVVVfkWbGbWjXVqQEgaWDT7WaD5DKdlwDRJvSUNBYYBT3ZmbWZm9lE981qwpIXAOGCApEbgOmCcpNEUdh+9DFwOEBGrJS0B1gA7gSsjYldetZmZWdtyC4iImJ5ontdK/znAnLzqMTOz9vGV1GZmluSAMDOzJAeEmZklOSDMzCzJAWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsyQFhZmZJDggzM0tyQJiZWZIDwszMknILCEnfl/S6pOeK2o6U9KCkddn7EVm7JH1H0npJqySdklddZmZWmjy3IOYD57Vouxp4KCKGAQ9l8wDnU3gO9TCgDrgjx7rMzKwEuQVERPwSeKNF8yRgQTa9ALiwqP3OKPgV0E/SwLxqMzOztnX2MYijI2IzQPZ+VNY+CNhY1K8xa9uDpDpJ9ZLqm5qaci3WzKw7q5SD1Eq0RapjRMyNiNqIqK2qqsq5LDOz7quzA+K15l1H2fvrWXsjMLioXzWwqZNrMzOzIp0dEMuAGdn0DGBpUfsl2dlMpwPbmndFmZlZefTMa8GSFgLjgAGSGoHrgBuBJZJmAq8Ak7Pu9wMTgPXAO8Dn86rLrLO8csPIcpfQLkOufbbcJViFyS0gImL6Xj46O9E3gCvzqsXMzNqvUg5Sm5lZhXFAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJeV2mqtZRzr1K3eWu4R2u+/Qcldgtn+8BWFmZkkOCDMzS3JAmJlZkgPCzMySHBBmZpbkgDAzsyQHhJmZJTkgzMwsqSwXykl6GXgL2AXsjIhaSUcCi4Ea4GVgSkS8WY76zMysvFsQn46I0RFRm81fDTwUEcOAh7J5MzMrk0raxTQJWJBNLwAuLGMtZmbdXrkCIoB/l9QgqS5rOzoiNgNk70eVqTYzM6N8N+s7MyI2SToKeFDS86UOzAKlDmDIkCF51Wdm1u2VJSAiYlP2/rqk+4CxwGuSBkbEZkkDgdf3MnYuMBegtrY2OqtmM9t3Xe1uvA3/dEm5S6gInb6LSdLHJB3aPA2cAzwHLANmZN1mAEs7uzYzM/tQObYgjgbuk9S8/h9HxAOSngKWSJoJvAJMLkNtZmaW6fSAiIiXgJMT7VuBszu7HjMzS6uk01zNzKyCOCDMzCzJAWFmZkkOCDMzSyrXhXJmZhXrlRtGlruEdhty7bMdvkxvQZiZWZIDwszMkhwQZmaW5IAwM7MkB4SZmSU5IMzMLMkBYWZmSQ4IMzNLckCYmVmSA8LMzJIqLiAknSfpBUnrJV1d7nrMzLqrigoIST2A24HzgeHAdEnDy1uVmVn3VFEBAYwF1kfESxHxHrAImFTmmszMuqVKC4hBwMai+caszczMOlml3e5bibb4SAepDqjLZrdLeiH3qsrkOBgAbCl3He1yXeon7J663O/n3263LvfbQXt/v+NK6VRpAdEIDC6arwY2FXeIiLnA3M4sqlwk1UdEbbnrsH3j36/r8m9XUGm7mJ4ChkkaKulgYBqwrMw1mZl1SxW1BREROyVdBfwb0AP4fkSsLnNZZmbdUkUFBEBE3A/cX+46KkS32JV2APPv13X5twMUEW33MjOzbqfSjkGYmVmFcEBUIElfk7Ra0ipJKyWdVu6arHSSjpG0SNKLktZIul/SieWuy9omqVrSUknrJL0k6TZJvctdV7k4ICqMpDOAC4BTImIU8Bk+evGgVTBJAu4DVkTE8RExHPgqcHR5K7O2ZL/dT4B/jYhhwDDgEOCbZS2sjCruILUxENgSEe8CRETXuljHPg28HxH/0twQESvLWI+VbjywIyJ+ABARuyT9NfBbSV+LiO3lLa/zeQui8vw7MFjSbyT9s6Q/KXdB1i6fABrKXYTtkxG0+O0i4vfAy8AJ5Sio3BwQFSb7X8qpFG4n0gQslnRpWYsy6x5Ei1v7FLV3Sw6IChQRuyJiRURcB1wF/Fm5a7KSraYQ8Nb1rAY+cnsNSYdROH50wN7zrTUOiAoj6b9IGlbUNBr4bbnqsXZ7GOgt6b83N0ga412FXcJDwB9IugR2P5/mJuC2iPjPslZWJg6IytMXWJCdHrmKwoOTZpe3JCtVFK48/SzwX7PTXFdT+P02tTrQyq7ot7tI0jpgK/BBRMwpb2Xl4yupzcwSJP0RsBD4XER0yxMPHBBmZpbkXUxmZpbkgDAzsyQHhJmZJTkgzMwsyQFh3ZKkXdmdcptfV7dj7DhJy/dz/Ssk7dMzjzti/Wal8M36rLv6z4gYXY4VZxdgmVU8b0GYFZH0sqR/kPS4pHpJp0j6t+yit78s6nqYpPuyCxr/RdJB2fg7snGrJV3fYrnXSnoEmFzUfpCkBZL+Pps/J1v305LultQ3az9P0vPZ+M91yh+GdXsOCOuuDmmxi2lq0WcbI+IM4P8B84GLgNOBG4r6jAW+DIwEjufDf7S/FhG1wCjgTySNKhqzIyL+OCIWZfM9gbuA30TE1yUNAL4OfCYiTgHqgS9J6gN8D/hT4CzgmA76MzBrlXcxWXfV2i6mZdn7s0DfiHgLeEvSDkn9ss+ejIiXACQtBP4YuAeYIqmOwt+tgRRulbIqG7O4xXq+CywpupXD6Vn/RwvPruFg4HHgD4ENEbEuW9+PKNzt1yxXDgizPb2bvX9QNN083/x3puUtCELSUOBvgDER8aak+UCfoj5vtxjzGPBpSTdFxA4Kt5V+MCKmF3eSNDqxPrPceReT2b4ZK2loduxhKvAIcBiFENgm6Wjg/DaWMQ+4H7hbUk/gV8CZkk4AkPQH2bOsnweGSjo+Gzc9uTSzDuYtCOuuDpFU/CjQByKi5FNdKez6uZHCMYhfAvdFxAeSfk3huQIvAY+2tZCI+Lakw4EfAn8OXAoslNQ76/L1iPhNttvq/0jaQiGMPtGOWs32iW/WZ2ZmSd7FZGZmSQ4IMzNLckCYmVmSA8LMzJIcEGZmluSAMDOzJAeEmZklOSDMzCzp/wNBUwXY96B1egAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train_data.Embarked, hue=train_data.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival chances based on class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:53.765728Z",
     "start_time": "2019-09-01T18:41:53.538129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a236c3c88>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Pclass', hue='Survived', data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Can see that First Class passengers has more survival chances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Survival chances based on gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:56.228208Z",
     "start_time": "2019-09-01T18:41:56.060952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24ba0d30>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Sex', hue='Survived', data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Female has more survival chances than men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:57.643106Z",
     "start_time": "2019-09-01T18:41:57.411216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.distplot(train_data[train_data.Survived == 1].Age.dropna(), bins=30)\n",
    "sns.distplot(train_data[train_data.Survived == 0].Age.dropna(), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Survival rate of age below 20 is more compared to other age group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:41:59.177020Z",
     "start_time": "2019-09-01T18:41:58.831389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1a248ab5c0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(train_data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:06.212409Z",
     "start_time": "2019-09-01T18:42:06.195640Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Age = train_data.Age.fillna(train_data.Age.mean())\n",
    "test_data.Age = test_data.Age.fillna(test_data.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:09.289171Z",
     "start_time": "2019-09-01T18:42:09.275466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Age.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:26.536827Z",
     "start_time": "2019-09-01T18:42:26.516922Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = [0, 15, 40, 60, 120]\n",
    "labels = [1, 2, 3, 4]\n",
    "train_data['age_bin'] = pd.cut(train_data.Age, bins=bins, labels=labels)\n",
    "test_data['age_bin'] = pd.cut(test_data.Age, bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:28.445821Z",
     "start_time": "2019-09-01T18:42:28.426863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  TicketCoPassengers age_bin  \n",
       "0      0         A/5 21171   7.2500   NaN        S                   0       2  \n",
       "1      0          PC 17599  71.2833   C85        C                   0       2  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S                   0       2  \n",
       "3      0            113803  53.1000  C123        S                   1       2  \n",
       "4      0            373450   8.0500   NaN        S                   0       2  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:31.284736Z",
     "start_time": "2019-09-01T18:42:30.937119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "g = sns.FacetGrid(train_data, col='Survived')\n",
    "g.map(plt.hist, 'Fare', bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:42:46.081079Z",
     "start_time": "2019-09-01T18:42:46.065774Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Fare = train_data.Fare.fillna(train_data.Fare.mean())\n",
    "test_data.Fare = test_data.Fare.fillna(test_data.Fare.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:04.633092Z",
     "start_time": "2019-09-01T18:43:04.609490Z"
    }
   },
   "outputs": [],
   "source": [
    "bins = [-1, 50, 100, 200, 10000]\n",
    "labels = [1, 2, 3, 4]\n",
    "train_data['Fare_bins'] = pd.cut(train_data.Fare, bins=bins, labels=labels)\n",
    "test_data['Fare_bins'] = pd.cut(test_data.Fare, bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:06.930514Z",
     "start_time": "2019-09-01T18:43:06.923980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:09.471015Z",
     "start_time": "2019-09-01T18:43:09.454549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN   \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN   \n",
       "\n",
       "     TicketCoPassengers age_bin Fare_bins  \n",
       "61                    1       2         2  \n",
       "829                   1       4         2  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.Embarked.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:24.434470Z",
     "start_time": "2019-09-01T18:43:24.428720Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Embarked = train_data.Embarked.fillna('S')\n",
    "test_data.Embarked = test_data.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:25.865820Z",
     "start_time": "2019-09-01T18:43:25.847491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  TicketCoPassengers  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S                   0   \n",
       "1      0          PC 17599  71.2833   C85        C                   0   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S                   0   \n",
       "3      0            113803  53.1000  C123        S                   1   \n",
       "4      0            373450   8.0500   NaN        S                   0   \n",
       "\n",
       "  age_bin Fare_bins  \n",
       "0       2         1  \n",
       "1       2         2  \n",
       "2       2         1  \n",
       "3       2         2  \n",
       "4       2         1  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:38.083149Z",
     "start_time": "2019-09-01T18:43:38.072125Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.Sex = train_data.Sex.map({'male': 1, 'female': 0})\n",
    "test_data.Sex = test_data.Sex.map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:43:52.296971Z",
     "start_time": "2019-09-01T18:43:52.262414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "   Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "0    1  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "1    0  38.0      1      0          PC 17599  71.2833   C85   \n",
       "2    0  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "3    0  35.0      1      0            113803  53.1000  C123   \n",
       "4    1  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "   TicketCoPassengers age_bin Fare_bins  Pclass_2  Pclass_3  Embarked_Q  \\\n",
       "0                   0       2         1         0         1           0   \n",
       "1                   0       2         2         0         0           0   \n",
       "2                   0       2         1         0         1           0   \n",
       "3                   1       2         2         0         0           0   \n",
       "4                   0       2         1         0         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===> \n",
    "train_data = pd.get_dummies(train_data, columns=['Pclass', 'Embarked'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['Pclass', 'Embarked'], drop_first=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:44:00.564683Z",
     "start_time": "2019-09-01T18:44:00.553263Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(columns=['Age', 'Fare', 'Ticket'], inplace=True)\n",
    "test_data.drop(columns=['Age', 'Fare', 'Ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:44:14.571643Z",
     "start_time": "2019-09-01T18:44:14.560382Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.loc[:, 'Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "test_data.loc[:, 'Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:44:15.751434Z",
     "start_time": "2019-09-01T18:44:15.723602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>55</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "Capt        1    0\n",
       "Col         1    1\n",
       "Countess    0    1\n",
       "Don         1    0\n",
       "Dr          4    3\n",
       "Jonkheer    1    0\n",
       "Lady        0    1\n",
       "Major       1    1\n",
       "Master     17   23\n",
       "Miss       55  127\n",
       "Mlle        0    2\n",
       "Mme         0    1\n",
       "Mr        436   81\n",
       "Mrs        26   99\n",
       "Ms          0    1\n",
       "Rev         6    0\n",
       "Sir         0    1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_data.Title, train_data.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:45:49.248775Z",
     "start_time": "2019-09-01T18:45:49.229532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      185\n",
      "Mrs       126\n",
      "Master     40\n",
      "Rare       23\n",
      "Name: Title, dtype: int64\n",
      "Mr        240\n",
      "Miss       79\n",
      "Mrs        72\n",
      "Master     21\n",
      "Rare        6\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def replaceTitles(_data):\n",
    "    _data['Title'] = _data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    _data['Title'] = _data['Title'].replace('Mlle', 'Miss')\n",
    "    _data['Title'] = _data['Title'].replace('Ms', 'Miss')\n",
    "    _data['Title'] = _data['Title'].replace('Mme', 'Mrs')\n",
    "    return _data\n",
    "\n",
    "train_data = replaceTitles(train_data)\n",
    "test_data = replaceTitles(test_data)\n",
    "print(train_data['Title'].value_counts())\n",
    "print(test_data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:08.071787Z",
     "start_time": "2019-09-01T18:46:08.045794Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data, columns=['Title'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['Title'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:14.936704Z",
     "start_time": "2019-09-01T18:46:14.918826Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(columns=['Name'], inplace=True)\n",
    "test_data.drop(columns=['Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:16.103140Z",
     "start_time": "2019-09-01T18:46:16.087214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex  SibSp  Parch Cabin  TicketCoPassengers age_bin  \\\n",
       "0            1         0    1      1      0   NaN                   0       2   \n",
       "1            2         1    0      1      0   C85                   0       2   \n",
       "2            3         1    0      0      0   NaN                   0       2   \n",
       "3            4         1    0      1      0  C123                   1       2   \n",
       "4            5         0    1      0      0   NaN                   0       2   \n",
       "\n",
       "  Fare_bins  Pclass_2  Pclass_3  Embarked_Q  Embarked_S  Title_Miss  Title_Mr  \\\n",
       "0         1         0         1           0           1           0         1   \n",
       "1         2         0         0           0           0           0         0   \n",
       "2         1         0         1           0           1           1         0   \n",
       "3         2         0         0           0           1           0         0   \n",
       "4         1         0         1           0           1           0         1   \n",
       "\n",
       "   Title_Mrs  Title_Rare  \n",
       "0          0           0  \n",
       "1          1           0  \n",
       "2          0           0  \n",
       "3          1           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:24.859964Z",
     "start_time": "2019-09-01T18:46:24.851960Z"
    }
   },
   "outputs": [],
   "source": [
    "#====> Fill cabin NaN as not assigned\n",
    "train_data.drop(columns=['Cabin', 'PassengerId'], inplace=True)\n",
    "test_data.drop(columns=['Cabin', 'PassengerId'], inplace=True)\n",
    "# train_data.Cabin.fillna('NotAssigned').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:27.329072Z",
     "start_time": "2019-09-01T18:46:27.322437Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data = pd.get_dummies(train_data, columns=['Cabin'], drop_first=True)\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:27.742758Z",
     "start_time": "2019-09-01T18:46:27.728355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex  SibSp  Parch  TicketCoPassengers age_bin Fare_bins  \\\n",
       "0         0    1      1      0                   0       2         1   \n",
       "1         1    0      1      0                   0       2         2   \n",
       "2         1    0      0      0                   0       2         1   \n",
       "3         1    0      1      0                   1       2         2   \n",
       "4         0    1      0      0                   0       2         1   \n",
       "\n",
       "   Pclass_2  Pclass_3  Embarked_Q  Embarked_S  Title_Miss  Title_Mr  \\\n",
       "0         0         1           0           1           0         1   \n",
       "1         0         0           0           0           0         0   \n",
       "2         0         1           0           1           1         0   \n",
       "3         0         0           0           1           0         0   \n",
       "4         0         1           0           1           0         1   \n",
       "\n",
       "   Title_Mrs  Title_Rare  \n",
       "0          0           0  \n",
       "1          1           0  \n",
       "2          0           0  \n",
       "3          1           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:46:34.221580Z",
     "start_time": "2019-09-01T18:46:34.204598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>TicketCoPassengers</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>Fare_bins</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  SibSp  Parch  TicketCoPassengers age_bin Fare_bins  Pclass_2  \\\n",
       "0    1      0      0                   0       2         1         0   \n",
       "1    0      1      0                   0       3         1         0   \n",
       "2    1      0      0                   0       4         1         1   \n",
       "3    1      0      0                   0       2         1         0   \n",
       "4    0      1      1                   0       2         1         0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0         1           1           0           0         1          0   \n",
       "1         1           0           1           0         0          1   \n",
       "2         0           1           0           0         1          0   \n",
       "3         1           0           1           0         1          0   \n",
       "4         1           0           1           0         0          1   \n",
       "\n",
       "   Title_Rare  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:49:55.603968Z",
     "start_time": "2019-09-01T18:49:55.563253Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_data.drop(columns=['Survived'])\n",
    "y_train = train_data.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can try different categorical models and try to see for best fit of the model**\n",
    "\n",
    "* Logistic Regression\n",
    "* KNN or k-Nearest Neighbors\n",
    "* Support Vector Machines\n",
    "* Decision Tree\n",
    "* Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-01T18:50:57.235246Z",
     "start_time": "2019-09-01T18:50:57.063636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.819304152637486"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_pred = log_reg.predict(test_data)\n",
    "log_reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T09:17:11.175466Z",
     "start_time": "2019-09-02T09:17:11.160700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11225988, -0.41465965, -0.26051771, -0.01516854, -0.47424329,\n",
       "        0.52410937, -0.55986429, -1.52983649, -0.05069401, -0.3018723 ,\n",
       "        0.28068525, -2.3920887 ,  0.85178985, -1.58529216])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T09:18:57.163950Z",
     "start_time": "2019-09-02T09:18:57.142033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.851790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fare_bins</td>\n",
       "      <td>0.524109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.280685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TicketCoPassengers</td>\n",
       "      <td>-0.015169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>-0.050694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>-0.112260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parch</td>\n",
       "      <td>-0.260518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.301872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>-0.414660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_bin</td>\n",
       "      <td>-0.474243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>-0.559864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.529836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Title_Rare</td>\n",
       "      <td>-1.585292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>-2.392089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              features      coff\n",
       "12           Title_Mrs  0.851790\n",
       "5            Fare_bins  0.524109\n",
       "10          Title_Miss  0.280685\n",
       "3   TicketCoPassengers -0.015169\n",
       "8           Embarked_Q -0.050694\n",
       "0                  Sex -0.112260\n",
       "2                Parch -0.260518\n",
       "9           Embarked_S -0.301872\n",
       "1                SibSp -0.414660\n",
       "4              age_bin -0.474243\n",
       "6             Pclass_2 -0.559864\n",
       "7             Pclass_3 -1.529836\n",
       "13          Title_Rare -1.585292\n",
       "11            Title_Mr -2.392089"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = pd.DataFrame({'features': x_train.columns, 'coff': log_reg.coef_[0]}).sort_values(by='coff', ascending=False)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T09:34:31.045760Z",
     "start_time": "2019-09-02T09:34:30.985687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridsearchCV for parameter tuning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:27:55.490904Z",
     "start_time": "2019-09-02T10:27:52.361141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    3.0s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_logit = LogisticRegression()\n",
    "params = {\n",
    "    \"C\": np.logspace(-3, 3, 7),\n",
    "    \"penalty\": [\"l1\", \"l2\"]  # l1 lasso l2 ridge\n",
    "}\n",
    "kfold = KFold(n_splits=2, random_state=101, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(g_logit,\n",
    "                    param_grid=params,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=True,\n",
    "                    return_train_score=True,\n",
    "                    scoring='accuracy',\n",
    "                    cv=kfold)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:28:06.300397Z",
     "start_time": "2019-09-02T10:28:06.285071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237934904601572"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:30:26.186634Z",
     "start_time": "2019-09-02T10:30:26.151947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.006775</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.831652</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>2</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.003560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.813901</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.054968</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.813901</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1000.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.813901</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.006532</td>\n",
       "      <td>2</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>6</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.813901</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>6</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>0.002048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>8</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.823792</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>9</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.806948</td>\n",
       "      <td>0.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.784270</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>10</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.793485</td>\n",
       "      <td>0.004721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.777528</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059788</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>12</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.616161</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062728</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>12</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.616161</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>12</td>\n",
       "      <td>0.615730</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.616161</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "8        0.031024      0.006775         0.002449        0.000072      10   \n",
       "6        0.008549      0.000718         0.002396        0.000048       1   \n",
       "10       0.046588      0.000220         0.002274        0.000065     100   \n",
       "12       0.054968      0.003259         0.001513        0.000017    1000   \n",
       "13       0.006582      0.000091         0.002206        0.000007    1000   \n",
       "9        0.014063      0.001858         0.002818        0.000274      10   \n",
       "11       0.008307      0.001754         0.002262        0.000023     100   \n",
       "7        0.013901      0.007859         0.002312        0.000326       1   \n",
       "5        0.011067      0.004944         0.002442        0.000033     0.1   \n",
       "4        0.010546      0.003442         0.002880        0.000216     0.1   \n",
       "3        0.006999      0.000081         0.002623        0.000031    0.01   \n",
       "0        0.059788      0.000124         0.005577        0.000899   0.001   \n",
       "1        0.062728      0.000503         0.003209        0.000090   0.001   \n",
       "2        0.006559      0.000229         0.005220        0.000722    0.01   \n",
       "\n",
       "   param_penalty                          params  split0_test_score  \\\n",
       "8             l1    {'C': 10.0, 'penalty': 'l1'}           0.822870   \n",
       "6             l1     {'C': 1.0, 'penalty': 'l1'}           0.822870   \n",
       "10            l1   {'C': 100.0, 'penalty': 'l1'}           0.813901   \n",
       "12            l1  {'C': 1000.0, 'penalty': 'l1'}           0.813901   \n",
       "13            l2  {'C': 1000.0, 'penalty': 'l2'}           0.813901   \n",
       "9             l2    {'C': 10.0, 'penalty': 'l2'}           0.818386   \n",
       "11            l2   {'C': 100.0, 'penalty': 'l2'}           0.813901   \n",
       "7             l2     {'C': 1.0, 'penalty': 'l2'}           0.818386   \n",
       "5             l2     {'C': 0.1, 'penalty': 'l2'}           0.818386   \n",
       "4             l1     {'C': 0.1, 'penalty': 'l1'}           0.798206   \n",
       "3             l2    {'C': 0.01, 'penalty': 'l2'}           0.802691   \n",
       "0             l1   {'C': 0.001, 'penalty': 'l1'}           0.616592   \n",
       "1             l2   {'C': 0.001, 'penalty': 'l2'}           0.616592   \n",
       "2             l1    {'C': 0.01, 'penalty': 'l1'}           0.616592   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "8            0.824719         0.823793        0.000925                1   \n",
       "6            0.817978         0.820426        0.002446                2   \n",
       "10           0.826966         0.820426        0.006532                2   \n",
       "12           0.826966         0.820426        0.006532                2   \n",
       "13           0.826966         0.820426        0.006532                2   \n",
       "9            0.820225         0.819304        0.000920                6   \n",
       "11           0.824719         0.819304        0.005409                6   \n",
       "7            0.813483         0.815937        0.002451                8   \n",
       "5            0.797753         0.808081        0.010316                9   \n",
       "4            0.784270         0.791246        0.006968               10   \n",
       "3            0.777528         0.790123        0.012581               11   \n",
       "0            0.615730         0.616162        0.000431               12   \n",
       "1            0.615730         0.616162        0.000431               12   \n",
       "2            0.615730         0.616162        0.000431               12   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "8             0.833708            0.829596          0.831652         0.002056  \n",
       "6             0.824719            0.831839          0.828279         0.003560  \n",
       "10            0.826966            0.822870          0.824918         0.002048  \n",
       "12            0.826966            0.822870          0.824918         0.002048  \n",
       "13            0.826966            0.822870          0.824918         0.002048  \n",
       "9             0.831461            0.831839          0.831650         0.000189  \n",
       "11            0.826966            0.822870          0.824918         0.002048  \n",
       "7             0.822472            0.825112          0.823792         0.001320  \n",
       "5             0.797753            0.816143          0.806948         0.009195  \n",
       "4             0.788764            0.798206          0.793485         0.004721  \n",
       "3             0.800000            0.800448          0.800224         0.000224  \n",
       "0             0.615730            0.616592          0.616161         0.000431  \n",
       "1             0.615730            0.616592          0.616161         0.000431  \n",
       "2             0.615730            0.616592          0.616161         0.000431  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:25:42.125344Z",
     "start_time": "2019-09-02T11:25:42.034525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the logistic regression:: 83.05274971941638\n"
     ]
    }
   ],
   "source": [
    "logit_alog = grid.best_estimator_\n",
    "logit_alog.fit(x_train, y_train)\n",
    "logit_y_predict = logit_alog.predict(test_data)\n",
    "print(\"Accuracy score for the logistic regression::\", logit_alog.score(x_train, y_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T09:59:57.046502Z",
     "start_time": "2019-09-02T09:59:56.848806Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4, n_jobs=-1)\n",
    "knn.fit(x_train, y_train)\n",
    "knn_y_pred = knn.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:00:38.246739Z",
     "start_time": "2019-09-02T10:00:38.088399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8417508417508418"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:01:39.521486Z",
     "start_time": "2019-09-02T10:01:39.509078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "                     weights='uniform')>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridsearchCV for parameter tuning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:34:17.532788Z",
     "start_time": "2019-09-02T10:34:09.453508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 317 out of 324 | elapsed:    8.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'leaf_size': range(4, 40, 4),\n",
       "                         'n_neighbors': range(2, 20)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_knn = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors': range(2, 20),\n",
    "    'leaf_size': range(4, 40, 4)\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=101)\n",
    "\n",
    "grid = GridSearchCV(g_knn,\n",
    "                    param_grid=params,\n",
    "                    cv=kfold,\n",
    "                    n_jobs=-1,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=True,\n",
    "                    return_train_score=True)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:34:19.637869Z",
     "start_time": "2019-09-02T10:34:19.632097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=8, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=16, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:34:20.329036Z",
     "start_time": "2019-09-02T10:34:20.324404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226711560044894"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:34:20.743073Z",
     "start_time": "2019-09-02T10:34:20.730970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 8, 'n_neighbors': 16}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:34:22.206957Z",
     "start_time": "2019-09-02T10:34:22.132896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_leaf_size</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.034772</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 16}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.833889</td>\n",
       "      <td>0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 16}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.833889</td>\n",
       "      <td>0.004676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.006550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.006550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.006550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 16}</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.830529</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.084676</td>\n",
       "      <td>0.035354</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 15}</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>3</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.831647</td>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 8}</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.036813</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 15}</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>3</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.831647</td>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 16}</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.830529</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 16}</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.830529</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.032398</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 8}</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.028576</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 8}</td>\n",
       "      <td>0.827354</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>3</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.058857</td>\n",
       "      <td>0.015423</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>14</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.832771</td>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 8}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>14</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.840628</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 16}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>14</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.838391</td>\n",
       "      <td>0.006553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.036768</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 15}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>14</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.840628</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>14</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.835020</td>\n",
       "      <td>0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>14</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.832771</td>\n",
       "      <td>0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.031847</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 16}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>14</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.838391</td>\n",
       "      <td>0.006553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 36, 'n_neighbors': 16}</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>14</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.838391</td>\n",
       "      <td>0.006553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 8}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>14</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.840628</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.043131</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 16}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>14</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.831647</td>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>24</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.043089</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 12}</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>24</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.033014</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 15}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>24</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.833897</td>\n",
       "      <td>0.002058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>24</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.829596</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.027991</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>24</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>24</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.047903</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 12}</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>24</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 6}</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>133</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.839512</td>\n",
       "      <td>0.005432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 6}</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>134</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.036712</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 6}</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>134</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.841757</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.032360</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 3}</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>136</td>\n",
       "      <td>0.860674</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.859709</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.029874</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 3}</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>136</td>\n",
       "      <td>0.860674</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.859709</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 4}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>138</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 36, 'n_neighbors': 4}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>138</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 4}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>138</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 4}</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>141</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.840628</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 4}</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>142</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.839502</td>\n",
       "      <td>0.003547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 4}</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.013239</td>\n",
       "      <td>142</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.839502</td>\n",
       "      <td>0.003547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 3}</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.802247</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>144</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.856338</td>\n",
       "      <td>0.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.030369</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 4}</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>145</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 4}</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>145</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.027327</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 4}</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>145</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.025594</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 3}</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>148</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.014765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.027894</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 3}</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>148</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.014765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 3}</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>148</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.858744</td>\n",
       "      <td>0.843979</td>\n",
       "      <td>0.014765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 36, 'n_neighbors': 3}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>151</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>0.847342</td>\n",
       "      <td>0.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.024512</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 3}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>151</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>0.847342</td>\n",
       "      <td>0.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 3}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>151</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>0.847342</td>\n",
       "      <td>0.018129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.027971</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 4, 'n_neighbors': 2}</td>\n",
       "      <td>0.764574</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>154</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.850726</td>\n",
       "      <td>0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 12, 'n_neighbors': 2}</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>155</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 8, 'n_neighbors': 2}</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>155</td>\n",
       "      <td>0.847191</td>\n",
       "      <td>0.852018</td>\n",
       "      <td>0.849604</td>\n",
       "      <td>0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 16, 'n_neighbors': 2}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>157</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.849602</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.035541</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 20, 'n_neighbors': 2}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>157</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.849602</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.024419</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 24, 'n_neighbors': 2}</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>157</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.849602</td>\n",
       "      <td>0.004658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 28, 'n_neighbors': 2}</td>\n",
       "      <td>0.724215</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>160</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.834993</td>\n",
       "      <td>0.021510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 32, 'n_neighbors': 2}</td>\n",
       "      <td>0.724215</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>160</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.834993</td>\n",
       "      <td>0.021510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leaf_size': 36, 'n_neighbors': 2}</td>\n",
       "      <td>0.724215</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.036769</td>\n",
       "      <td>160</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.834993</td>\n",
       "      <td>0.021510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "50        0.006807      0.001254         0.034772        0.004698   \n",
       "32        0.008386      0.000690         0.054117        0.008910   \n",
       "64        0.005918      0.001328         0.030325        0.000090   \n",
       "82        0.005728      0.001090         0.026689        0.000077   \n",
       "100       0.006416      0.001078         0.026801        0.000567   \n",
       "68        0.005072      0.000211         0.027782        0.000906   \n",
       "31        0.009644      0.002088         0.084676        0.035354   \n",
       "96        0.004791      0.000026         0.029168        0.004470   \n",
       "49        0.006879      0.000300         0.036813        0.004794   \n",
       "86        0.005085      0.000435         0.026127        0.000066   \n",
       "104       0.005149      0.000446         0.032156        0.000193   \n",
       "60        0.007597      0.000109         0.032398        0.002342   \n",
       "78        0.005455      0.000578         0.028576        0.001680   \n",
       "30        0.017412      0.004379         0.058857        0.015423   \n",
       "24        0.005785      0.000931         0.034409        0.001181   \n",
       "140       0.009237      0.001149         0.039831        0.000216   \n",
       "13        0.006440      0.000436         0.036768        0.001308   \n",
       "12        0.005514      0.000468         0.038070        0.000834   \n",
       "48        0.006515      0.000678         0.037814        0.000824   \n",
       "122       0.006091      0.000842         0.031847        0.005278   \n",
       "158       0.005041      0.000636         0.028550        0.002865   \n",
       "42        0.006701      0.001201         0.029777        0.000539   \n",
       "14        0.005789      0.000236         0.043131        0.000952   \n",
       "120       0.004811      0.000903         0.027096        0.000403   \n",
       "28        0.008477      0.000265         0.043089        0.002867   \n",
       "139       0.005112      0.000160         0.033014        0.005949   \n",
       "138       0.004658      0.000274         0.028261        0.001126   \n",
       "118       0.008449      0.003236         0.027991        0.001187   \n",
       "136       0.005805      0.001015         0.026880        0.002488   \n",
       "46        0.012203      0.003376         0.047903        0.004700   \n",
       "..             ...           ...              ...             ...   \n",
       "4         0.006733      0.001076         0.031949        0.004148   \n",
       "40        0.005761      0.000645         0.037128        0.004341   \n",
       "22        0.005121      0.000064         0.036712        0.000591   \n",
       "37        0.006655      0.000648         0.032360        0.001235   \n",
       "19        0.005522      0.000552         0.029874        0.003694   \n",
       "128       0.004633      0.000209         0.024779        0.000409   \n",
       "146       0.004895      0.000407         0.025035        0.000874   \n",
       "110       0.004746      0.000298         0.027066        0.002691   \n",
       "2         0.005872      0.000162         0.031456        0.003695   \n",
       "38        0.005475      0.000304         0.031714        0.003958   \n",
       "20        0.005484      0.000219         0.024454        0.000805   \n",
       "1         0.006214      0.000023         0.029430        0.000653   \n",
       "56        0.004704      0.000283         0.030369        0.000283   \n",
       "74        0.006505      0.000633         0.025163        0.000890   \n",
       "92        0.004999      0.000132         0.027327        0.004963   \n",
       "55        0.005530      0.001397         0.025594        0.000211   \n",
       "73        0.008012      0.001905         0.027894        0.001076   \n",
       "91        0.005041      0.000275         0.022570        0.000318   \n",
       "145       0.007960      0.002885         0.023595        0.000143   \n",
       "109       0.005492      0.000960         0.024512        0.001117   \n",
       "127       0.005393      0.000736         0.025075        0.001898   \n",
       "0         0.006537      0.000577         0.027971        0.000230   \n",
       "36        0.005616      0.000356         0.026584        0.001608   \n",
       "18        0.005582      0.000309         0.027747        0.000766   \n",
       "54        0.004892      0.000624         0.026389        0.004039   \n",
       "72        0.006125      0.000530         0.035541        0.002058   \n",
       "90        0.005331      0.000304         0.024419        0.000416   \n",
       "108       0.004790      0.000466         0.028822        0.000150   \n",
       "126       0.004952      0.000059         0.022354        0.003995   \n",
       "144       0.004896      0.000071         0.026592        0.002980   \n",
       "\n",
       "    param_leaf_size param_n_neighbors                                params  \\\n",
       "50               12                16  {'leaf_size': 12, 'n_neighbors': 16}   \n",
       "32                8                16   {'leaf_size': 8, 'n_neighbors': 16}   \n",
       "64               16                12  {'leaf_size': 16, 'n_neighbors': 12}   \n",
       "82               20                12  {'leaf_size': 20, 'n_neighbors': 12}   \n",
       "100              24                12  {'leaf_size': 24, 'n_neighbors': 12}   \n",
       "68               16                16  {'leaf_size': 16, 'n_neighbors': 16}   \n",
       "31                8                15   {'leaf_size': 8, 'n_neighbors': 15}   \n",
       "96               24                 8   {'leaf_size': 24, 'n_neighbors': 8}   \n",
       "49               12                15  {'leaf_size': 12, 'n_neighbors': 15}   \n",
       "86               20                16  {'leaf_size': 20, 'n_neighbors': 16}   \n",
       "104              24                16  {'leaf_size': 24, 'n_neighbors': 16}   \n",
       "60               16                 8   {'leaf_size': 16, 'n_neighbors': 8}   \n",
       "78               20                 8   {'leaf_size': 20, 'n_neighbors': 8}   \n",
       "30                8                14   {'leaf_size': 8, 'n_neighbors': 14}   \n",
       "24                8                 8    {'leaf_size': 8, 'n_neighbors': 8}   \n",
       "140              32                16  {'leaf_size': 32, 'n_neighbors': 16}   \n",
       "13                4                15   {'leaf_size': 4, 'n_neighbors': 15}   \n",
       "12                4                14   {'leaf_size': 4, 'n_neighbors': 14}   \n",
       "48               12                14  {'leaf_size': 12, 'n_neighbors': 14}   \n",
       "122              28                16  {'leaf_size': 28, 'n_neighbors': 16}   \n",
       "158              36                16  {'leaf_size': 36, 'n_neighbors': 16}   \n",
       "42               12                 8   {'leaf_size': 12, 'n_neighbors': 8}   \n",
       "14                4                16   {'leaf_size': 4, 'n_neighbors': 16}   \n",
       "120              28                14  {'leaf_size': 28, 'n_neighbors': 14}   \n",
       "28                8                12   {'leaf_size': 8, 'n_neighbors': 12}   \n",
       "139              32                15  {'leaf_size': 32, 'n_neighbors': 15}   \n",
       "138              32                14  {'leaf_size': 32, 'n_neighbors': 14}   \n",
       "118              28                12  {'leaf_size': 28, 'n_neighbors': 12}   \n",
       "136              32                12  {'leaf_size': 32, 'n_neighbors': 12}   \n",
       "46               12                12  {'leaf_size': 12, 'n_neighbors': 12}   \n",
       "..              ...               ...                                   ...   \n",
       "4                 4                 6    {'leaf_size': 4, 'n_neighbors': 6}   \n",
       "40               12                 6   {'leaf_size': 12, 'n_neighbors': 6}   \n",
       "22                8                 6    {'leaf_size': 8, 'n_neighbors': 6}   \n",
       "37               12                 3   {'leaf_size': 12, 'n_neighbors': 3}   \n",
       "19                8                 3    {'leaf_size': 8, 'n_neighbors': 3}   \n",
       "128              32                 4   {'leaf_size': 32, 'n_neighbors': 4}   \n",
       "146              36                 4   {'leaf_size': 36, 'n_neighbors': 4}   \n",
       "110              28                 4   {'leaf_size': 28, 'n_neighbors': 4}   \n",
       "2                 4                 4    {'leaf_size': 4, 'n_neighbors': 4}   \n",
       "38               12                 4   {'leaf_size': 12, 'n_neighbors': 4}   \n",
       "20                8                 4    {'leaf_size': 8, 'n_neighbors': 4}   \n",
       "1                 4                 3    {'leaf_size': 4, 'n_neighbors': 3}   \n",
       "56               16                 4   {'leaf_size': 16, 'n_neighbors': 4}   \n",
       "74               20                 4   {'leaf_size': 20, 'n_neighbors': 4}   \n",
       "92               24                 4   {'leaf_size': 24, 'n_neighbors': 4}   \n",
       "55               16                 3   {'leaf_size': 16, 'n_neighbors': 3}   \n",
       "73               20                 3   {'leaf_size': 20, 'n_neighbors': 3}   \n",
       "91               24                 3   {'leaf_size': 24, 'n_neighbors': 3}   \n",
       "145              36                 3   {'leaf_size': 36, 'n_neighbors': 3}   \n",
       "109              28                 3   {'leaf_size': 28, 'n_neighbors': 3}   \n",
       "127              32                 3   {'leaf_size': 32, 'n_neighbors': 3}   \n",
       "0                 4                 2    {'leaf_size': 4, 'n_neighbors': 2}   \n",
       "36               12                 2   {'leaf_size': 12, 'n_neighbors': 2}   \n",
       "18                8                 2    {'leaf_size': 8, 'n_neighbors': 2}   \n",
       "54               16                 2   {'leaf_size': 16, 'n_neighbors': 2}   \n",
       "72               20                 2   {'leaf_size': 20, 'n_neighbors': 2}   \n",
       "90               24                 2   {'leaf_size': 24, 'n_neighbors': 2}   \n",
       "108              28                 2   {'leaf_size': 28, 'n_neighbors': 2}   \n",
       "126              32                 2   {'leaf_size': 32, 'n_neighbors': 2}   \n",
       "144              36                 2   {'leaf_size': 36, 'n_neighbors': 2}   \n",
       "\n",
       "     split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
       "50            0.825112           0.820225         0.822671        0.002444   \n",
       "32            0.825112           0.820225         0.822671        0.002444   \n",
       "64            0.820628           0.822472         0.821549        0.000922   \n",
       "82            0.820628           0.822472         0.821549        0.000922   \n",
       "100           0.820628           0.822472         0.821549        0.000922   \n",
       "68            0.829596           0.813483         0.821549        0.008057   \n",
       "31            0.827354           0.815730         0.821549        0.005812   \n",
       "96            0.827354           0.815730         0.821549        0.005812   \n",
       "49            0.827354           0.815730         0.821549        0.005812   \n",
       "86            0.829596           0.813483         0.821549        0.008057   \n",
       "104           0.829596           0.813483         0.821549        0.008057   \n",
       "60            0.827354           0.815730         0.821549        0.005812   \n",
       "78            0.827354           0.815730         0.821549        0.005812   \n",
       "30            0.822870           0.817978         0.820426        0.002446   \n",
       "24            0.818386           0.822472         0.820426        0.002043   \n",
       "140           0.825112           0.815730         0.820426        0.004691   \n",
       "13            0.825112           0.815730         0.820426        0.004691   \n",
       "12            0.822870           0.817978         0.820426        0.002446   \n",
       "48            0.822870           0.817978         0.820426        0.002446   \n",
       "122           0.825112           0.815730         0.820426        0.004691   \n",
       "158           0.825112           0.815730         0.820426        0.004691   \n",
       "42            0.818386           0.822472         0.820426        0.002043   \n",
       "14            0.820628           0.820225         0.820426        0.000202   \n",
       "120           0.822870           0.815730         0.819304        0.003570   \n",
       "28            0.816143           0.822472         0.819304        0.003164   \n",
       "139           0.818386           0.820225         0.819304        0.000920   \n",
       "138           0.822870           0.815730         0.819304        0.003570   \n",
       "118           0.820628           0.817978         0.819304        0.001325   \n",
       "136           0.820628           0.817978         0.819304        0.001325   \n",
       "46            0.816143           0.822472         0.819304        0.003164   \n",
       "..                 ...                ...              ...             ...   \n",
       "4             0.802691           0.813483         0.808081        0.005396   \n",
       "40            0.802691           0.808989         0.805836        0.003149   \n",
       "22            0.802691           0.808989         0.805836        0.003149   \n",
       "37            0.800448           0.800000         0.800224        0.000224   \n",
       "19            0.800448           0.800000         0.800224        0.000224   \n",
       "128           0.791480           0.804494         0.797980        0.006507   \n",
       "146           0.791480           0.804494         0.797980        0.006507   \n",
       "110           0.791480           0.804494         0.797980        0.006507   \n",
       "2             0.782511           0.811236         0.796857        0.014362   \n",
       "38            0.782511           0.808989         0.795735        0.013239   \n",
       "20            0.782511           0.808989         0.795735        0.013239   \n",
       "1             0.782511           0.802247         0.792368        0.009868   \n",
       "56            0.778027           0.804494         0.791246        0.013234   \n",
       "74            0.778027           0.804494         0.791246        0.013234   \n",
       "92            0.778027           0.804494         0.791246        0.013234   \n",
       "55            0.762332           0.800000         0.781145        0.018834   \n",
       "73            0.762332           0.800000         0.781145        0.018834   \n",
       "91            0.762332           0.800000         0.781145        0.018834   \n",
       "145           0.760090           0.800000         0.780022        0.019955   \n",
       "109           0.760090           0.800000         0.780022        0.019955   \n",
       "127           0.760090           0.800000         0.780022        0.019955   \n",
       "0             0.764574           0.793258         0.778900        0.014342   \n",
       "36            0.762332           0.793258         0.777778        0.015463   \n",
       "18            0.762332           0.793258         0.777778        0.015463   \n",
       "54            0.760090           0.788764         0.774411        0.014337   \n",
       "72            0.760090           0.788764         0.774411        0.014337   \n",
       "90            0.760090           0.788764         0.774411        0.014337   \n",
       "108           0.724215           0.797753         0.760943        0.036769   \n",
       "126           0.724215           0.797753         0.760943        0.036769   \n",
       "144           0.724215           0.797753         0.760943        0.036769   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "50                 1            0.829213            0.838565   \n",
       "32                 1            0.829213            0.838565   \n",
       "64                 3            0.842697            0.829596   \n",
       "82                 3            0.842697            0.829596   \n",
       "100                3            0.842697            0.829596   \n",
       "68                 3            0.831461            0.829596   \n",
       "31                 3            0.829213            0.834081   \n",
       "96                 3            0.847191            0.836323   \n",
       "49                 3            0.829213            0.834081   \n",
       "86                 3            0.831461            0.829596   \n",
       "104                3            0.831461            0.829596   \n",
       "60                 3            0.847191            0.836323   \n",
       "78                 3            0.847191            0.836323   \n",
       "30                14            0.831461            0.834081   \n",
       "24                14            0.840449            0.840807   \n",
       "140               14            0.844944            0.831839   \n",
       "13                14            0.840449            0.840807   \n",
       "12                14            0.838202            0.831839   \n",
       "48                14            0.831461            0.834081   \n",
       "122               14            0.844944            0.831839   \n",
       "158               14            0.844944            0.831839   \n",
       "42                14            0.840449            0.840807   \n",
       "14                14            0.829213            0.834081   \n",
       "120               24            0.835955            0.829596   \n",
       "28                24            0.833708            0.838565   \n",
       "139               24            0.835955            0.831839   \n",
       "138               24            0.835955            0.829596   \n",
       "118               24            0.835955            0.836323   \n",
       "136               24            0.835955            0.836323   \n",
       "46                24            0.833708            0.838565   \n",
       "..               ...                 ...                 ...   \n",
       "4                133            0.844944            0.834081   \n",
       "40               134            0.847191            0.836323   \n",
       "22               134            0.847191            0.836323   \n",
       "37               136            0.860674            0.858744   \n",
       "19               136            0.860674            0.858744   \n",
       "128              138            0.838202            0.845291   \n",
       "146              138            0.838202            0.845291   \n",
       "110              138            0.838202            0.845291   \n",
       "2                141            0.840449            0.840807   \n",
       "38               142            0.835955            0.843049   \n",
       "20               142            0.835955            0.843049   \n",
       "1                144            0.853933            0.858744   \n",
       "56               145            0.838202            0.845291   \n",
       "74               145            0.838202            0.845291   \n",
       "92               145            0.838202            0.845291   \n",
       "55               148            0.829213            0.858744   \n",
       "73               148            0.829213            0.858744   \n",
       "91               148            0.829213            0.858744   \n",
       "145              151            0.829213            0.865471   \n",
       "109              151            0.829213            0.865471   \n",
       "127              151            0.829213            0.865471   \n",
       "0                154            0.847191            0.854260   \n",
       "36               155            0.847191            0.852018   \n",
       "18               155            0.847191            0.852018   \n",
       "54               157            0.844944            0.854260   \n",
       "72               157            0.844944            0.854260   \n",
       "90               157            0.844944            0.854260   \n",
       "108              160            0.813483            0.856502   \n",
       "126              160            0.813483            0.856502   \n",
       "144              160            0.813483            0.856502   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "50           0.833889         0.004676  \n",
       "32           0.833889         0.004676  \n",
       "64           0.836147         0.006550  \n",
       "82           0.836147         0.006550  \n",
       "100          0.836147         0.006550  \n",
       "68           0.830529         0.000932  \n",
       "31           0.831647         0.002434  \n",
       "96           0.841757         0.005434  \n",
       "49           0.831647         0.002434  \n",
       "86           0.830529         0.000932  \n",
       "104          0.830529         0.000932  \n",
       "60           0.841757         0.005434  \n",
       "78           0.841757         0.005434  \n",
       "30           0.832771         0.001310  \n",
       "24           0.840628         0.000179  \n",
       "140          0.838391         0.006553  \n",
       "13           0.840628         0.000179  \n",
       "12           0.835020         0.003182  \n",
       "48           0.832771         0.001310  \n",
       "122          0.838391         0.006553  \n",
       "158          0.838391         0.006553  \n",
       "42           0.840628         0.000179  \n",
       "14           0.831647         0.002434  \n",
       "120          0.832776         0.003179  \n",
       "28           0.836136         0.002429  \n",
       "139          0.833897         0.002058  \n",
       "138          0.832776         0.003179  \n",
       "118          0.836139         0.000184  \n",
       "136          0.836139         0.000184  \n",
       "46           0.836136         0.002429  \n",
       "..                ...              ...  \n",
       "4            0.839512         0.005432  \n",
       "40           0.841757         0.005434  \n",
       "22           0.841757         0.005434  \n",
       "37           0.859709         0.000965  \n",
       "19           0.859709         0.000965  \n",
       "128          0.841747         0.003545  \n",
       "146          0.841747         0.003545  \n",
       "110          0.841747         0.003545  \n",
       "2            0.840628         0.000179  \n",
       "38           0.839502         0.003547  \n",
       "20           0.839502         0.003547  \n",
       "1            0.856338         0.002406  \n",
       "56           0.841747         0.003545  \n",
       "74           0.841747         0.003545  \n",
       "92           0.841747         0.003545  \n",
       "55           0.843979         0.014765  \n",
       "73           0.843979         0.014765  \n",
       "91           0.843979         0.014765  \n",
       "145          0.847342         0.018129  \n",
       "109          0.847342         0.018129  \n",
       "127          0.847342         0.018129  \n",
       "0            0.850726         0.003535  \n",
       "36           0.849604         0.002413  \n",
       "18           0.849604         0.002413  \n",
       "54           0.849602         0.004658  \n",
       "72           0.849602         0.004658  \n",
       "90           0.849602         0.004658  \n",
       "108          0.834993         0.021510  \n",
       "126          0.834993         0.021510  \n",
       "144          0.834993         0.021510  \n",
       "\n",
       "[162 rows x 16 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Choose the best model with the train and test accuary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:25:33.876874Z",
     "start_time": "2019-09-02T11:25:33.620467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the logistic regression:: 83.05274971941638\n"
     ]
    }
   ],
   "source": [
    "knn_algo = grid.best_estimator_\n",
    "knn_algo.fit(x_train, y_train)\n",
    "knn_y_pred = knn.predict(test_data)\n",
    "print(\"Accuracy score for the logistic regression::\", knn_algo.score(x_train, y_train)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:48:36.027189Z",
     "start_time": "2019-09-02T10:48:36.023131Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:52:28.094098Z",
     "start_time": "2019-09-02T10:52:27.811158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.3s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 20, 30, 40, 50, 100, 150],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_alog = SVC()\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 20, 30, 40, 50, 100, 150],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "svc_grid = GridSearchCV(svc_alog,\n",
    "                        param_grid=params,\n",
    "                        cv=kfold,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=True,\n",
    "                        return_train_score=True)\n",
    "svc_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:52:30.161472Z",
     "start_time": "2019-09-02T10:52:30.138723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.841747</td>\n",
       "      <td>0.003545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013943</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.826038</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>2</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.831839</td>\n",
       "      <td>0.828279</td>\n",
       "      <td>0.003560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025270</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.809417</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>3</td>\n",
       "      <td>0.860674</td>\n",
       "      <td>0.863229</td>\n",
       "      <td>0.861951</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.804933</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>4</td>\n",
       "      <td>0.878652</td>\n",
       "      <td>0.869955</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.004348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>30</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 30, 'kernel': 'rbf'}</td>\n",
       "      <td>0.802691</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880899</td>\n",
       "      <td>0.872197</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.004351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>40</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 40, 'kernel': 'rbf'}</td>\n",
       "      <td>0.804933</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880899</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.877669</td>\n",
       "      <td>0.003230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 50, 'kernel': 'rbf'}</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>7</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.876682</td>\n",
       "      <td>0.879914</td>\n",
       "      <td>0.003232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>8</td>\n",
       "      <td>0.892135</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.887771</td>\n",
       "      <td>0.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017572</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>150</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 150, 'kernel': 'rbf'}</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>9</td>\n",
       "      <td>0.896629</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "1       0.013947      0.000272         0.006226        0.000273       1   \n",
       "0       0.013943      0.004791         0.009646        0.001305     0.1   \n",
       "2       0.025270      0.009192         0.014436        0.008621      10   \n",
       "3       0.023435      0.001298         0.006748        0.000049      20   \n",
       "4       0.014024      0.004019         0.004387        0.001020      30   \n",
       "5       0.009150      0.000367         0.004143        0.000734      40   \n",
       "6       0.009110      0.000337         0.004923        0.000296      50   \n",
       "7       0.010063      0.001183         0.006741        0.000399     100   \n",
       "8       0.017572      0.002038         0.004018        0.000239     150   \n",
       "\n",
       "  param_kernel                       params  split0_test_score  \\\n",
       "1          rbf    {'C': 1, 'kernel': 'rbf'}           0.831839   \n",
       "0          rbf  {'C': 0.1, 'kernel': 'rbf'}           0.831839   \n",
       "2          rbf   {'C': 10, 'kernel': 'rbf'}           0.809417   \n",
       "3          rbf   {'C': 20, 'kernel': 'rbf'}           0.804933   \n",
       "4          rbf   {'C': 30, 'kernel': 'rbf'}           0.802691   \n",
       "5          rbf   {'C': 40, 'kernel': 'rbf'}           0.804933   \n",
       "6          rbf   {'C': 50, 'kernel': 'rbf'}           0.800448   \n",
       "7          rbf  {'C': 100, 'kernel': 'rbf'}           0.798206   \n",
       "8          rbf  {'C': 150, 'kernel': 'rbf'}           0.795964   \n",
       "\n",
       "   split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "1           0.831461         0.831650        0.000189                1   \n",
       "0           0.820225         0.826038        0.005807                2   \n",
       "2           0.824719         0.817059        0.007651                3   \n",
       "3           0.822472         0.813692        0.008770                4   \n",
       "4           0.824719         0.813692        0.011014                4   \n",
       "5           0.822472         0.813692        0.008770                4   \n",
       "6           0.824719         0.812570        0.012135                7   \n",
       "7           0.824719         0.811448        0.013256                8   \n",
       "8           0.822472         0.809203        0.013254                9   \n",
       "\n",
       "   split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "1            0.838202            0.845291          0.841747         0.003545  \n",
       "0            0.824719            0.831839          0.828279         0.003560  \n",
       "2            0.860674            0.863229          0.861951         0.001277  \n",
       "3            0.878652            0.869955          0.874303         0.004348  \n",
       "4            0.880899            0.872197          0.876548         0.004351  \n",
       "5            0.880899            0.874439          0.877669         0.003230  \n",
       "6            0.883146            0.876682          0.879914         0.003232  \n",
       "7            0.892135            0.883408          0.887771         0.004363  \n",
       "8            0.896629            0.890135          0.893382         0.003247  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(svc_grid.cv_results_)\n",
    "results.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:52:34.916394Z",
     "start_time": "2019-09-02T10:52:34.912087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316498316498316"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:25:22.693146Z",
     "start_time": "2019-09-02T11:25:22.617071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM algorithm accuracy score::  83.9506172839506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_alog = svc_grid.best_estimator_\n",
    "svc_alog.fit(x_train, y_train)\n",
    "svc_y_pred = svc_alog.predict(test_data)\n",
    "print(\"Linear SVM algorithm accuracy score:: \", svc_alog.score(x_train, y_train)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:05:56.559438Z",
     "start_time": "2019-09-02T11:05:56.555980Z"
    }
   },
   "outputs": [],
   "source": [
    "decision_alog = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:10:07.307802Z",
     "start_time": "2019-09-02T11:10:07.233784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877665544332211"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_alog.fit(x_train, y_train)\n",
    "decision_alog.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridsearchCV for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:12:48.429711Z",
     "start_time": "2019-09-02T11:12:48.419141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_alog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:12:05.425442Z",
     "start_time": "2019-09-02T11:12:05.412102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DecisionTreeClassifier in module sklearn.tree.tree:\n",
      "\n",
      "class DecisionTreeClassifier(BaseDecisionTree, sklearn.base.ClassifierMixin)\n",
      " |  DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |  \n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a fraction and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\" or None, default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool\n",
      " |          Run check_array on X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Returns the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Returns the number of leaves of the decision tree.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:21:23.692751Z",
     "start_time": "2019-09-02T11:21:23.358818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_leaf_nodes': range(2, 10, 2),\n",
       "                         'min_samples_split': range(2, 20, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_decision_alog = DecisionTreeClassifier()\n",
    "params = {\n",
    "    'min_samples_split': range(2, 20, 2),\n",
    "    'max_leaf_nodes': range(2, 10, 2)\n",
    "}\n",
    "decision_tree_grid = GridSearchCV(g_decision_alog,\n",
    "                                  param_grid=params,\n",
    "                                  verbose=True,\n",
    "                                  scoring='accuracy',\n",
    "                                  return_train_score=True,\n",
    "                                  cv=kfold,\n",
    "                                  n_jobs=-1)\n",
    "decision_tree_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:21:25.929776Z",
     "start_time": "2019-09-02T11:21:25.925271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8204264870931538"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:21:30.953634Z",
     "start_time": "2019-09-02T11:21:30.948127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=8,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:21:33.278210Z",
     "start_time": "2019-09-02T11:21:33.235911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_leaf_nodes</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>5.428791e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 18}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.833892</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>2.272129e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 10}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>2.313852e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 2}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>3.793240e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 6}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>3.328323e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 8}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>1.496434e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 4}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.002429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>5.960464e-07</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 14}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.833892</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>1.252890e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 16}</td>\n",
       "      <td>0.822870</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.833892</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>2.778769e-04</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_leaf_nodes': 8, 'min_samples_split': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.835015</td>\n",
       "      <td>0.001308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>2.580881e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 4}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>4.223585e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 18}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>6.091595e-05</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 16}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>2.994537e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 14}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>3.833771e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 12}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>1.549721e-05</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 10}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>7.302284e-03</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 8}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>2.373457e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 6}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>6.974936e-04</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_leaf_nodes': 6, 'min_samples_split': 2}</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>9</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.836323</td>\n",
       "      <td>0.830521</td>\n",
       "      <td>0.005802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>5.294085e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 2}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>8.826256e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 16}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004845</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>3.921986e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 14}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>1.190901e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 12}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>2.970695e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 10}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>4.256964e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 8}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>9.284019e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 6}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012062</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>3.743172e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 4}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>2.664804e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_leaf_nodes': 4, 'min_samples_split': 18}</td>\n",
       "      <td>0.818386</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>19</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>3.043413e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 12}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>1.205444e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 6}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>1.808405e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 8}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>5.996227e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 10}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>4.278421e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 4}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>2.179146e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 14}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>1.185060e-03</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 16}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>8.337498e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 18}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>1.778603e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_leaf_nodes': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>28</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "35       0.004463      0.000228         0.001976    5.428791e-04   \n",
       "31       0.004980      0.000197         0.004846    2.272129e-03   \n",
       "27       0.005078      0.000013         0.002659    2.313852e-04   \n",
       "29       0.007330      0.002570         0.001945    3.793240e-04   \n",
       "30       0.005624      0.001883         0.002049    3.328323e-04   \n",
       "28       0.005841      0.000302         0.004078    1.496434e-03   \n",
       "33       0.002891      0.000044         0.001395    5.960464e-07   \n",
       "34       0.004227      0.000463         0.001585    1.252890e-04   \n",
       "32       0.008123      0.000135         0.002604    2.778769e-04   \n",
       "19       0.007791      0.000338         0.002207    2.580881e-04   \n",
       "26       0.005166      0.000278         0.003069    4.223585e-04   \n",
       "25       0.003662      0.000357         0.001413    6.091595e-05   \n",
       "24       0.004750      0.000100         0.001961    2.994537e-04   \n",
       "23       0.003900      0.000526         0.001826    3.833771e-04   \n",
       "22       0.003473      0.000026         0.002367    1.549721e-05   \n",
       "21       0.007097      0.001800         0.010412    7.302284e-03   \n",
       "20       0.004994      0.000790         0.002406    2.373457e-04   \n",
       "18       0.007241      0.002035         0.002156    6.974936e-04   \n",
       "9        0.003689      0.000912         0.002766    5.294085e-04   \n",
       "16       0.004923      0.000725         0.003432    8.826256e-04   \n",
       "15       0.004845      0.000349         0.002510    3.921986e-05   \n",
       "14       0.003618      0.000921         0.001736    1.190901e-04   \n",
       "13       0.003392      0.000381         0.001978    2.970695e-04   \n",
       "12       0.004732      0.000022         0.002756    4.256964e-04   \n",
       "11       0.005456      0.000398         0.002974    9.284019e-04   \n",
       "10       0.012062      0.007059         0.002331    3.743172e-05   \n",
       "17       0.005346      0.000138         0.005086    2.664804e-03   \n",
       "5        0.005659      0.000576         0.002511    3.043413e-04   \n",
       "2        0.005588      0.000412         0.004015    1.205444e-03   \n",
       "3        0.005880      0.000153         0.002393    1.808405e-04   \n",
       "4        0.004498      0.000089         0.002635    5.996227e-05   \n",
       "1        0.005211      0.000280         0.002818    4.278421e-04   \n",
       "6        0.008379      0.003991         0.002478    2.179146e-04   \n",
       "7        0.004610      0.000267         0.003621    1.185060e-03   \n",
       "8        0.005344      0.002582         0.002946    8.337498e-04   \n",
       "0        0.004988      0.000043         0.002071    1.778603e-04   \n",
       "\n",
       "   param_max_leaf_nodes param_min_samples_split  \\\n",
       "35                    8                      18   \n",
       "31                    8                      10   \n",
       "27                    8                       2   \n",
       "29                    8                       6   \n",
       "30                    8                       8   \n",
       "28                    8                       4   \n",
       "33                    8                      14   \n",
       "34                    8                      16   \n",
       "32                    8                      12   \n",
       "19                    6                       4   \n",
       "26                    6                      18   \n",
       "25                    6                      16   \n",
       "24                    6                      14   \n",
       "23                    6                      12   \n",
       "22                    6                      10   \n",
       "21                    6                       8   \n",
       "20                    6                       6   \n",
       "18                    6                       2   \n",
       "9                     4                       2   \n",
       "16                    4                      16   \n",
       "15                    4                      14   \n",
       "14                    4                      12   \n",
       "13                    4                      10   \n",
       "12                    4                       8   \n",
       "11                    4                       6   \n",
       "10                    4                       4   \n",
       "17                    4                      18   \n",
       "5                     2                      12   \n",
       "2                     2                       6   \n",
       "3                     2                       8   \n",
       "4                     2                      10   \n",
       "1                     2                       4   \n",
       "6                     2                      14   \n",
       "7                     2                      16   \n",
       "8                     2                      18   \n",
       "0                     2                       2   \n",
       "\n",
       "                                            params  split0_test_score  \\\n",
       "35  {'max_leaf_nodes': 8, 'min_samples_split': 18}           0.822870   \n",
       "31  {'max_leaf_nodes': 8, 'min_samples_split': 10}           0.820628   \n",
       "27   {'max_leaf_nodes': 8, 'min_samples_split': 2}           0.820628   \n",
       "29   {'max_leaf_nodes': 8, 'min_samples_split': 6}           0.820628   \n",
       "30   {'max_leaf_nodes': 8, 'min_samples_split': 8}           0.820628   \n",
       "28   {'max_leaf_nodes': 8, 'min_samples_split': 4}           0.820628   \n",
       "33  {'max_leaf_nodes': 8, 'min_samples_split': 14}           0.822870   \n",
       "34  {'max_leaf_nodes': 8, 'min_samples_split': 16}           0.822870   \n",
       "32  {'max_leaf_nodes': 8, 'min_samples_split': 12}           0.820628   \n",
       "19   {'max_leaf_nodes': 6, 'min_samples_split': 4}           0.820628   \n",
       "26  {'max_leaf_nodes': 6, 'min_samples_split': 18}           0.820628   \n",
       "25  {'max_leaf_nodes': 6, 'min_samples_split': 16}           0.820628   \n",
       "24  {'max_leaf_nodes': 6, 'min_samples_split': 14}           0.820628   \n",
       "23  {'max_leaf_nodes': 6, 'min_samples_split': 12}           0.820628   \n",
       "22  {'max_leaf_nodes': 6, 'min_samples_split': 10}           0.820628   \n",
       "21   {'max_leaf_nodes': 6, 'min_samples_split': 8}           0.820628   \n",
       "20   {'max_leaf_nodes': 6, 'min_samples_split': 6}           0.820628   \n",
       "18   {'max_leaf_nodes': 6, 'min_samples_split': 2}           0.820628   \n",
       "9    {'max_leaf_nodes': 4, 'min_samples_split': 2}           0.818386   \n",
       "16  {'max_leaf_nodes': 4, 'min_samples_split': 16}           0.818386   \n",
       "15  {'max_leaf_nodes': 4, 'min_samples_split': 14}           0.818386   \n",
       "14  {'max_leaf_nodes': 4, 'min_samples_split': 12}           0.818386   \n",
       "13  {'max_leaf_nodes': 4, 'min_samples_split': 10}           0.818386   \n",
       "12   {'max_leaf_nodes': 4, 'min_samples_split': 8}           0.818386   \n",
       "11   {'max_leaf_nodes': 4, 'min_samples_split': 6}           0.818386   \n",
       "10   {'max_leaf_nodes': 4, 'min_samples_split': 4}           0.818386   \n",
       "17  {'max_leaf_nodes': 4, 'min_samples_split': 18}           0.818386   \n",
       "5   {'max_leaf_nodes': 2, 'min_samples_split': 12}           0.791480   \n",
       "2    {'max_leaf_nodes': 2, 'min_samples_split': 6}           0.791480   \n",
       "3    {'max_leaf_nodes': 2, 'min_samples_split': 8}           0.791480   \n",
       "4   {'max_leaf_nodes': 2, 'min_samples_split': 10}           0.791480   \n",
       "1    {'max_leaf_nodes': 2, 'min_samples_split': 4}           0.791480   \n",
       "6   {'max_leaf_nodes': 2, 'min_samples_split': 14}           0.791480   \n",
       "7   {'max_leaf_nodes': 2, 'min_samples_split': 16}           0.791480   \n",
       "8   {'max_leaf_nodes': 2, 'min_samples_split': 18}           0.791480   \n",
       "0    {'max_leaf_nodes': 2, 'min_samples_split': 2}           0.791480   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "35           0.817978         0.820426        0.002446                1   \n",
       "31           0.820225         0.820426        0.000202                1   \n",
       "27           0.820225         0.820426        0.000202                1   \n",
       "29           0.820225         0.820426        0.000202                1   \n",
       "30           0.820225         0.820426        0.000202                1   \n",
       "28           0.820225         0.820426        0.000202                1   \n",
       "33           0.817978         0.820426        0.002446                1   \n",
       "34           0.817978         0.820426        0.002446                1   \n",
       "32           0.817978         0.819304        0.001325                9   \n",
       "19           0.817978         0.819304        0.001325                9   \n",
       "26           0.817978         0.819304        0.001325                9   \n",
       "25           0.817978         0.819304        0.001325                9   \n",
       "24           0.817978         0.819304        0.001325                9   \n",
       "23           0.817978         0.819304        0.001325                9   \n",
       "22           0.817978         0.819304        0.001325                9   \n",
       "21           0.817978         0.819304        0.001325                9   \n",
       "20           0.817978         0.819304        0.001325                9   \n",
       "18           0.817978         0.819304        0.001325                9   \n",
       "9            0.773034         0.795735        0.022676               19   \n",
       "16           0.773034         0.795735        0.022676               19   \n",
       "15           0.773034         0.795735        0.022676               19   \n",
       "14           0.773034         0.795735        0.022676               19   \n",
       "13           0.773034         0.795735        0.022676               19   \n",
       "12           0.773034         0.795735        0.022676               19   \n",
       "11           0.773034         0.795735        0.022676               19   \n",
       "10           0.773034         0.795735        0.022676               19   \n",
       "17           0.773034         0.795735        0.022676               19   \n",
       "5            0.773034         0.782267        0.009223               28   \n",
       "2            0.773034         0.782267        0.009223               28   \n",
       "3            0.773034         0.782267        0.009223               28   \n",
       "4            0.773034         0.782267        0.009223               28   \n",
       "1            0.773034         0.782267        0.009223               28   \n",
       "6            0.773034         0.782267        0.009223               28   \n",
       "7            0.773034         0.782267        0.009223               28   \n",
       "8            0.773034         0.782267        0.009223               28   \n",
       "0            0.773034         0.782267        0.009223               28   \n",
       "\n",
       "    split0_train_score  split1_train_score  mean_train_score  std_train_score  \n",
       "35            0.831461            0.836323          0.833892         0.002431  \n",
       "31            0.833708            0.838565          0.836136         0.002429  \n",
       "27            0.833708            0.838565          0.836136         0.002429  \n",
       "29            0.833708            0.838565          0.836136         0.002429  \n",
       "30            0.833708            0.838565          0.836136         0.002429  \n",
       "28            0.833708            0.838565          0.836136         0.002429  \n",
       "33            0.831461            0.836323          0.833892         0.002431  \n",
       "34            0.831461            0.836323          0.833892         0.002431  \n",
       "32            0.833708            0.836323          0.835015         0.001308  \n",
       "19            0.824719            0.836323          0.830521         0.005802  \n",
       "26            0.824719            0.836323          0.830521         0.005802  \n",
       "25            0.824719            0.836323          0.830521         0.005802  \n",
       "24            0.824719            0.836323          0.830521         0.005802  \n",
       "23            0.824719            0.836323          0.830521         0.005802  \n",
       "22            0.824719            0.836323          0.830521         0.005802  \n",
       "21            0.824719            0.836323          0.830521         0.005802  \n",
       "20            0.824719            0.836323          0.830521         0.005802  \n",
       "18            0.824719            0.836323          0.830521         0.005802  \n",
       "9             0.811236            0.800448          0.805842         0.005394  \n",
       "16            0.811236            0.800448          0.805842         0.005394  \n",
       "15            0.811236            0.800448          0.805842         0.005394  \n",
       "14            0.811236            0.800448          0.805842         0.005394  \n",
       "13            0.811236            0.800448          0.805842         0.005394  \n",
       "12            0.811236            0.800448          0.805842         0.005394  \n",
       "11            0.811236            0.800448          0.805842         0.005394  \n",
       "10            0.811236            0.800448          0.805842         0.005394  \n",
       "17            0.811236            0.800448          0.805842         0.005394  \n",
       "5             0.773034            0.800448          0.786741         0.013707  \n",
       "2             0.773034            0.800448          0.786741         0.013707  \n",
       "3             0.773034            0.800448          0.786741         0.013707  \n",
       "4             0.773034            0.800448          0.786741         0.013707  \n",
       "1             0.773034            0.800448          0.786741         0.013707  \n",
       "6             0.773034            0.800448          0.786741         0.013707  \n",
       "7             0.773034            0.800448          0.786741         0.013707  \n",
       "8             0.773034            0.800448          0.786741         0.013707  \n",
       "0             0.773034            0.800448          0.786741         0.013707  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(decision_tree_grid.cv_results_)\n",
    "result.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:24:46.907099Z",
     "start_time": "2019-09-02T11:24:46.888423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree alogirthm score::  82.82828282828282\n"
     ]
    }
   ],
   "source": [
    "decision_tree_algo = decision_tree_grid.best_estimator_\n",
    "decision_tree_algo.fit(x_train, y_train)\n",
    "dec_tree_y_pred = decision_tree_algo.predict(test_data)\n",
    "print(\"Decision Tree alogirthm score:: \", decision_tree_algo.score(x_train, y_train) * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:46:17.362041Z",
     "start_time": "2019-09-02T11:46:16.300760Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T11:59:30.773517Z",
     "start_time": "2019-09-02T11:59:30.685888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=8,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:01:08.639426Z",
     "start_time": "2019-09-02T12:01:08.232473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=8,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_alog = DecisionTreeClassifier(max_leaf_nodes=8, min_samples_split=2)\n",
    "adaboost = AdaBoostClassifier(d_alog, n_estimators=200)\n",
    "# adaboost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:01:27.281886Z",
     "start_time": "2019-09-02T12:01:27.220686Z"
    }
   },
   "outputs": [],
   "source": [
    "# ada_y_predict = adaboost.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:01:45.180029Z",
     "start_time": "2019-09-02T12:01:45.071343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877665544332211"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaboost.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:10:11.775134Z",
     "start_time": "2019-09-02T12:09:05.930924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 396 candidates, totalling 792 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 out of 792 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=8,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_s...\n",
       "                                                                                presort=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=1.0, n_estimators=200,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'base_estimator__criterion': ['gini', 'entropy'],\n",
       "                         'base_estimator__splitter': ['best', 'random'],\n",
       "                         'n_estimators': range(2, 200, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=2, random_state=101, shuffle=True)\n",
    "algo = DecisionTreeClassifier(max_leaf_nodes=8, min_samples_split=2)\n",
    "adaboost = AdaBoostClassifier(base_estimator=algo, n_estimators=200)\n",
    "params = {\n",
    "    \"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"base_estimator__splitter\": [\"best\", \"random\"],\n",
    "    \"n_estimators\": range(2, 200, 2)\n",
    "}\n",
    "adaboost_grid = GridSearchCV(adaboost,\n",
    "                             param_grid=params,\n",
    "                             verbose=True,\n",
    "                             scoring='accuracy',\n",
    "                             return_train_score=True,\n",
    "                             cv=kfold,\n",
    "                             n_jobs=-1)\n",
    "adaboost_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:10:12.309843Z",
     "start_time": "2019-09-02T12:10:12.304376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819304152637486"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:12:25.418122Z",
     "start_time": "2019-09-02T12:12:25.362515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_estimator__criterion</th>\n",
       "      <th>param_base_estimator__splitter</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856180</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038106</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>2</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.838565</td>\n",
       "      <td>0.846249</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>3</td>\n",
       "      <td>0.835955</td>\n",
       "      <td>0.840807</td>\n",
       "      <td>0.838381</td>\n",
       "      <td>0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.437269</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.110199</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>198</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>4</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.833708</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>5</td>\n",
       "      <td>0.856180</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.855220</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.062343</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>130</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>6</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.328706</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.081966</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>160</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>7</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>7</td>\n",
       "      <td>0.867416</td>\n",
       "      <td>0.863229</td>\n",
       "      <td>0.865322</td>\n",
       "      <td>0.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.370625</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.093186</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>186</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>9</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.395303</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.106074</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>196</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>9</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.258435</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.063551</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>126</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.815730</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>9</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.345703</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.084934</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>166</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>9</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.349428</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.083642</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>178</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>13</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.416005</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.102356</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>194</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.824719</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>13</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.260575</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>124</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>13</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.153829</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.035890</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>74</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>13</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.389534</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.104013</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>184</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.428293</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.081817</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>164</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.410662</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.098050</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>196</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.317744</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>158</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.381736</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.091037</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>184</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.313553</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.072321</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>154</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.019978</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.226065</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>76</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.786996</td>\n",
       "      <td>0.813483</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032319</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>6</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.822472</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>22</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.872197</td>\n",
       "      <td>0.874301</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.387568</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.101964</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>194</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.177512</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.044428</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>86</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.243125</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.060128</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>126</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.104216</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.782511</td>\n",
       "      <td>0.817978</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.017733</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.228504</td>\n",
       "      <td>0.017609</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>104</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.428589</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.097995</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>192</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>22</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>0.028290</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>54</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.082261</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>38</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.751121</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.145082</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>68</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.802247</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.024442</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.136899</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>66</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.766816</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.100514</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>42</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.766816</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.122819</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.029420</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>58</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.795506</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.113706</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.027477</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>54</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.744395</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.033421</td>\n",
       "      <td>367</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.126656</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.031978</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>60</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.795506</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.018829</td>\n",
       "      <td>374</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.283783</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>126</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>374</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.058569</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.015611</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>26</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.769058</td>\n",
       "      <td>0.784270</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>374</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.026825</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>8</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.782022</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>374</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.881040</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.182526</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.045214</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>84</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.766816</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>374</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>18</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>379</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.065589</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.017545</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>30</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>379</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>22</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>379</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.113201</td>\n",
       "      <td>0.011585</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>48</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.755605</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.097799</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>46</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.091352</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>40</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.050103</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>20</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.762332</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.207875</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.050807</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>96</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.162772</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>entropy</td>\n",
       "      <td>random</td>\n",
       "      <td>78</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.755605</td>\n",
       "      <td>0.793258</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.062259</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>24</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.760090</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.136475</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>52</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.755605</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>389</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.140036</td>\n",
       "      <td>0.026315</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>gini</td>\n",
       "      <td>best</td>\n",
       "      <td>50</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.788764</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>389</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.157936</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>76</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.742152</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>0.028924</td>\n",
       "      <td>391</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.085380</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>40</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.735426</td>\n",
       "      <td>0.804494</td>\n",
       "      <td>0.769921</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>392</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.067247</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>gini</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>{'base_estimator__criterion': 'gini', 'base_es...</td>\n",
       "      <td>0.746637</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.768799</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>393</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.896861</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.018266</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>6</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.784270</td>\n",
       "      <td>0.768799</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>393</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.872197</td>\n",
       "      <td>0.877672</td>\n",
       "      <td>0.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.037849</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>14</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.757848</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.766554</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>395</td>\n",
       "      <td>0.896629</td>\n",
       "      <td>0.892377</td>\n",
       "      <td>0.894503</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>entropy</td>\n",
       "      <td>best</td>\n",
       "      <td>16</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "      <td>0.748879</td>\n",
       "      <td>0.779775</td>\n",
       "      <td>0.764310</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>396</td>\n",
       "      <td>0.901124</td>\n",
       "      <td>0.894619</td>\n",
       "      <td>0.897871</td>\n",
       "      <td>0.003252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "298       0.014150      0.001295         0.004479        0.000018   \n",
       "0         0.038106      0.005182         0.011673        0.000759   \n",
       "297       0.008623      0.000032         0.002881        0.000512   \n",
       "197       0.437269      0.001098         0.110199        0.004017   \n",
       "100       0.016111      0.003621         0.005277        0.000053   \n",
       "64        0.281400      0.002425         0.062343        0.002670   \n",
       "178       0.328706      0.000947         0.081966        0.000024   \n",
       "1         0.069759      0.004714         0.005936        0.000238   \n",
       "191       0.370625      0.011738         0.093186        0.001735   \n",
       "196       0.395303      0.009795         0.106074        0.002242   \n",
       "161       0.258435      0.000129         0.063551        0.003345   \n",
       "379       0.345703      0.001788         0.084934        0.003814   \n",
       "187       0.349428      0.012555         0.083642        0.001680   \n",
       "96        0.416005      0.002167         0.102356        0.004012   \n",
       "61        0.260575      0.002790         0.061074        0.001936   \n",
       "333       0.153829      0.004696         0.035890        0.001684   \n",
       "91        0.389534      0.001682         0.104013        0.000602   \n",
       "81        0.428293      0.016556         0.081817        0.002384   \n",
       "394       0.410662      0.006593         0.098050        0.002604   \n",
       "78        0.317744      0.000371         0.080780        0.002157   \n",
       "388       0.381736      0.003623         0.091037        0.001832   \n",
       "76        0.313553      0.013713         0.072321        0.000289   \n",
       "37        0.226065      0.011957         0.046176        0.007133   \n",
       "2         0.032319      0.002022         0.016093        0.002890   \n",
       "393       0.387568      0.001539         0.101964        0.003052   \n",
       "141       0.177512      0.002820         0.044428        0.001112   \n",
       "62        0.243125      0.007051         0.060128        0.005389   \n",
       "123       0.104216      0.002464         0.027802        0.001848   \n",
       "51        0.228504      0.017609         0.047388        0.000783   \n",
       "194       0.428589      0.005344         0.097995        0.002762   \n",
       "..             ...           ...              ...             ...   \n",
       "224       0.127233      0.015541         0.028290        0.000468   \n",
       "117       0.082261      0.001426         0.022412        0.002696   \n",
       "330       0.145082      0.004157         0.036599        0.000874   \n",
       "131       0.136899      0.008689         0.033565        0.000530   \n",
       "218       0.100514      0.001215         0.021318        0.001591   \n",
       "226       0.122819      0.002387         0.029420        0.000535   \n",
       "125       0.113706      0.006739         0.027477        0.000127   \n",
       "227       0.126656      0.000403         0.031978        0.002191   \n",
       "260       0.283783      0.001144         0.064193        0.000813   \n",
       "210       0.058569      0.003267         0.015611        0.000013   \n",
       "201       0.026825      0.001042         0.009069        0.000223   \n",
       "140       0.182526      0.002169         0.045214        0.002205   \n",
       "206       0.044006      0.002202         0.011826        0.000791   \n",
       "311       0.065589      0.001945         0.017545        0.001148   \n",
       "208       0.055176      0.003891         0.014652        0.001586   \n",
       "23        0.113201      0.011585         0.027423        0.003272   \n",
       "121       0.097799      0.005185         0.023975        0.000247   \n",
       "316       0.091352      0.000839         0.020493        0.001261   \n",
       "207       0.050103      0.001578         0.014972        0.002555   \n",
       "245       0.207875      0.001139         0.050807        0.003107   \n",
       "335       0.162772      0.002660         0.038702        0.000370   \n",
       "209       0.062259      0.000897         0.013762        0.000216   \n",
       "25        0.136475      0.026460         0.038332        0.013059   \n",
       "24        0.140036      0.026315         0.028027        0.002368   \n",
       "136       0.157936      0.005919         0.038690        0.000096   \n",
       "118       0.085380      0.002172         0.021301        0.000659   \n",
       "114       0.067247      0.002222         0.018866        0.000046   \n",
       "200       0.018266      0.000458         0.005687        0.000201   \n",
       "204       0.037849      0.001105         0.009345        0.000048   \n",
       "205       0.040009      0.000941         0.011551        0.001235   \n",
       "\n",
       "    param_base_estimator__criterion param_base_estimator__splitter  \\\n",
       "298                         entropy                         random   \n",
       "0                              gini                           best   \n",
       "297                         entropy                         random   \n",
       "197                            gini                         random   \n",
       "100                            gini                         random   \n",
       "64                             gini                           best   \n",
       "178                            gini                         random   \n",
       "1                              gini                           best   \n",
       "191                            gini                         random   \n",
       "196                            gini                         random   \n",
       "161                            gini                         random   \n",
       "379                         entropy                         random   \n",
       "187                            gini                         random   \n",
       "96                             gini                           best   \n",
       "61                             gini                           best   \n",
       "333                         entropy                         random   \n",
       "91                             gini                           best   \n",
       "81                             gini                           best   \n",
       "394                         entropy                         random   \n",
       "78                             gini                           best   \n",
       "388                         entropy                         random   \n",
       "76                             gini                           best   \n",
       "37                             gini                           best   \n",
       "2                              gini                           best   \n",
       "393                         entropy                         random   \n",
       "141                            gini                         random   \n",
       "62                             gini                           best   \n",
       "123                            gini                         random   \n",
       "51                             gini                           best   \n",
       "194                            gini                         random   \n",
       "..                              ...                            ...   \n",
       "224                         entropy                           best   \n",
       "117                            gini                         random   \n",
       "330                         entropy                         random   \n",
       "131                            gini                         random   \n",
       "218                         entropy                           best   \n",
       "226                         entropy                           best   \n",
       "125                            gini                         random   \n",
       "227                         entropy                           best   \n",
       "260                         entropy                           best   \n",
       "210                         entropy                           best   \n",
       "201                         entropy                           best   \n",
       "140                            gini                         random   \n",
       "206                         entropy                           best   \n",
       "311                         entropy                         random   \n",
       "208                         entropy                           best   \n",
       "23                             gini                           best   \n",
       "121                            gini                         random   \n",
       "316                         entropy                         random   \n",
       "207                         entropy                           best   \n",
       "245                         entropy                           best   \n",
       "335                         entropy                         random   \n",
       "209                         entropy                           best   \n",
       "25                             gini                           best   \n",
       "24                             gini                           best   \n",
       "136                            gini                         random   \n",
       "118                            gini                         random   \n",
       "114                            gini                         random   \n",
       "200                         entropy                           best   \n",
       "204                         entropy                           best   \n",
       "205                         entropy                           best   \n",
       "\n",
       "    param_n_estimators                                             params  \\\n",
       "298                  4  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "0                    2  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "297                  2  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "197                198  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "100                  4  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "64                 130  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "178                160  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "1                    4  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "191                186  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "196                196  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "161                126  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "379                166  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "187                178  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "96                 194  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "61                 124  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "333                 74  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "91                 184  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "81                 164  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "394                196  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "78                 158  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "388                184  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "76                 154  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "37                  76  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "2                    6  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "393                194  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "141                 86  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "62                 126  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "123                 50  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "51                 104  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "194                192  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "..                 ...                                                ...   \n",
       "224                 54  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "117                 38  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "330                 68  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "131                 66  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "218                 42  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "226                 58  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "125                 54  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "227                 60  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "260                126  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "210                 26  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "201                  8  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "140                 84  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "206                 18  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "311                 30  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "208                 22  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "23                  48  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "121                 46  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "316                 40  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "207                 20  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "245                 96  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "335                 78  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "209                 24  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "25                  52  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "24                  50  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "136                 76  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "118                 40  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "114                 32  {'base_estimator__criterion': 'gini', 'base_es...   \n",
       "200                  6  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "204                 14  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "205                 16  {'base_estimator__criterion': 'entropy', 'base...   \n",
       "\n",
       "     split0_test_score  split1_test_score  mean_test_score  std_test_score  \\\n",
       "298           0.816143           0.822472         0.819304        0.003164   \n",
       "0             0.807175           0.820225         0.813692        0.006525   \n",
       "297           0.793722           0.829213         0.811448        0.017746   \n",
       "197           0.798206           0.820225         0.809203        0.011009   \n",
       "100           0.782511           0.833708         0.808081        0.025598   \n",
       "64            0.800448           0.811236         0.805836        0.005394   \n",
       "178           0.793722           0.815730         0.804714        0.011004   \n",
       "1             0.789238           0.820225         0.804714        0.015494   \n",
       "191           0.793722           0.813483         0.803591        0.009881   \n",
       "196           0.789238           0.817978         0.803591        0.014370   \n",
       "161           0.791480           0.815730         0.803591        0.012125   \n",
       "379           0.795964           0.811236         0.803591        0.007636   \n",
       "187           0.780269           0.824719         0.802469        0.022225   \n",
       "96            0.780269           0.824719         0.802469        0.022225   \n",
       "61            0.784753           0.820225         0.802469        0.017736   \n",
       "333           0.784753           0.820225         0.802469        0.017736   \n",
       "91            0.782511           0.820225         0.801347        0.018857   \n",
       "81            0.784753           0.817978         0.801347        0.016612   \n",
       "394           0.793722           0.808989         0.801347        0.007633   \n",
       "78            0.782511           0.820225         0.801347        0.018857   \n",
       "388           0.791480           0.811236         0.801347        0.009878   \n",
       "76            0.780269           0.820225         0.800224        0.019978   \n",
       "37            0.786996           0.813483         0.800224        0.013244   \n",
       "2             0.778027           0.822472         0.800224        0.022222   \n",
       "393           0.782511           0.817978         0.800224        0.017733   \n",
       "141           0.789238           0.811236         0.800224        0.010999   \n",
       "62            0.782511           0.817978         0.800224        0.017733   \n",
       "123           0.782511           0.817978         0.800224        0.017733   \n",
       "51            0.789238           0.811236         0.800224        0.010999   \n",
       "194           0.791480           0.808989         0.800224        0.008754   \n",
       "..                 ...                ...              ...             ...   \n",
       "224           0.762332           0.793258         0.777778        0.015463   \n",
       "117           0.751121           0.804494         0.777778        0.026687   \n",
       "330           0.753363           0.802247         0.777778        0.024442   \n",
       "131           0.766816           0.788764         0.777778        0.010974   \n",
       "218           0.766816           0.788764         0.777778        0.010974   \n",
       "226           0.760090           0.795506         0.777778        0.017708   \n",
       "125           0.744395           0.811236         0.777778        0.033421   \n",
       "227           0.757848           0.795506         0.776655        0.018829   \n",
       "260           0.760090           0.793258         0.776655        0.016584   \n",
       "210           0.769058           0.784270         0.776655        0.007606   \n",
       "201           0.771300           0.782022         0.776655        0.005361   \n",
       "140           0.766816           0.786517         0.776655        0.009850   \n",
       "206           0.762332           0.788764         0.775533        0.013216   \n",
       "311           0.757848           0.793258         0.775533        0.017705   \n",
       "208           0.762332           0.788764         0.775533        0.013216   \n",
       "23            0.755605           0.793258         0.774411        0.018827   \n",
       "121           0.757848           0.791011         0.774411        0.016582   \n",
       "316           0.757848           0.791011         0.774411        0.016582   \n",
       "207           0.762332           0.786517         0.774411        0.012093   \n",
       "245           0.760090           0.788764         0.774411        0.014337   \n",
       "335           0.755605           0.793258         0.774411        0.018827   \n",
       "209           0.760090           0.788764         0.774411        0.014337   \n",
       "25            0.755605           0.791011         0.773288        0.017703   \n",
       "24            0.757848           0.788764         0.773288        0.015458   \n",
       "136           0.742152           0.800000         0.771044        0.028924   \n",
       "118           0.735426           0.804494         0.769921        0.034534   \n",
       "114           0.746637           0.791011         0.768799        0.022187   \n",
       "200           0.753363           0.784270         0.768799        0.015453   \n",
       "204           0.757848           0.775281         0.766554        0.008717   \n",
       "205           0.748879           0.779775         0.764310        0.015448   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "298                1            0.856180            0.865471   \n",
       "0                  2            0.853933            0.838565   \n",
       "297                3            0.835955            0.840807   \n",
       "197                4            0.901124            0.896861   \n",
       "100                5            0.856180            0.854260   \n",
       "64                 6            0.901124            0.896861   \n",
       "178                7            0.901124            0.896861   \n",
       "1                  7            0.867416            0.863229   \n",
       "191                9            0.901124            0.896861   \n",
       "196                9            0.901124            0.896861   \n",
       "161                9            0.901124            0.896861   \n",
       "379                9            0.901124            0.896861   \n",
       "187               13            0.901124            0.896861   \n",
       "96                13            0.901124            0.896861   \n",
       "61                13            0.901124            0.896861   \n",
       "333               13            0.901124            0.896861   \n",
       "91                17            0.901124            0.896861   \n",
       "81                17            0.901124            0.896861   \n",
       "394               17            0.901124            0.896861   \n",
       "78                17            0.901124            0.896861   \n",
       "388               17            0.901124            0.896861   \n",
       "76                22            0.901124            0.896861   \n",
       "37                22            0.901124            0.896861   \n",
       "2                 22            0.876404            0.872197   \n",
       "393               22            0.901124            0.896861   \n",
       "141               22            0.901124            0.896861   \n",
       "62                22            0.901124            0.896861   \n",
       "123               22            0.901124            0.896861   \n",
       "51                22            0.901124            0.896861   \n",
       "194               22            0.901124            0.896861   \n",
       "..               ...                 ...                 ...   \n",
       "224              367            0.901124            0.896861   \n",
       "117              367            0.901124            0.896861   \n",
       "330              367            0.901124            0.896861   \n",
       "131              367            0.901124            0.896861   \n",
       "218              367            0.901124            0.896861   \n",
       "226              367            0.901124            0.896861   \n",
       "125              367            0.901124            0.896861   \n",
       "227              374            0.901124            0.896861   \n",
       "260              374            0.901124            0.896861   \n",
       "210              374            0.901124            0.896861   \n",
       "201              374            0.887640            0.874439   \n",
       "140              374            0.901124            0.896861   \n",
       "206              379            0.901124            0.896861   \n",
       "311              379            0.901124            0.896861   \n",
       "208              379            0.901124            0.896861   \n",
       "23               382            0.901124            0.896861   \n",
       "121              382            0.901124            0.896861   \n",
       "316              382            0.901124            0.896861   \n",
       "207              382            0.901124            0.896861   \n",
       "245              382            0.901124            0.896861   \n",
       "335              382            0.901124            0.896861   \n",
       "209              382            0.901124            0.896861   \n",
       "25               389            0.901124            0.896861   \n",
       "24               389            0.901124            0.896861   \n",
       "136              391            0.901124            0.896861   \n",
       "118              392            0.901124            0.896861   \n",
       "114              393            0.901124            0.896861   \n",
       "200              393            0.883146            0.872197   \n",
       "204              395            0.896629            0.892377   \n",
       "205              396            0.901124            0.894619   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "298          0.860825         0.004646  \n",
       "0            0.846249         0.007684  \n",
       "297          0.838381         0.002426  \n",
       "197          0.898992         0.002131  \n",
       "100          0.855220         0.000960  \n",
       "64           0.898992         0.002131  \n",
       "178          0.898992         0.002131  \n",
       "1            0.865322         0.002094  \n",
       "191          0.898992         0.002131  \n",
       "196          0.898992         0.002131  \n",
       "161          0.898992         0.002131  \n",
       "379          0.898992         0.002131  \n",
       "187          0.898992         0.002131  \n",
       "96           0.898992         0.002131  \n",
       "61           0.898992         0.002131  \n",
       "333          0.898992         0.002131  \n",
       "91           0.898992         0.002131  \n",
       "81           0.898992         0.002131  \n",
       "394          0.898992         0.002131  \n",
       "78           0.898992         0.002131  \n",
       "388          0.898992         0.002131  \n",
       "76           0.898992         0.002131  \n",
       "37           0.898992         0.002131  \n",
       "2            0.874301         0.002104  \n",
       "393          0.898992         0.002131  \n",
       "141          0.898992         0.002131  \n",
       "62           0.898992         0.002131  \n",
       "123          0.898992         0.002131  \n",
       "51           0.898992         0.002131  \n",
       "194          0.898992         0.002131  \n",
       "..                ...              ...  \n",
       "224          0.898992         0.002131  \n",
       "117          0.898992         0.002131  \n",
       "330          0.898992         0.002131  \n",
       "131          0.898992         0.002131  \n",
       "218          0.898992         0.002131  \n",
       "226          0.898992         0.002131  \n",
       "125          0.898992         0.002131  \n",
       "227          0.898992         0.002131  \n",
       "260          0.898992         0.002131  \n",
       "210          0.898992         0.002131  \n",
       "201          0.881040         0.006600  \n",
       "140          0.898992         0.002131  \n",
       "206          0.898992         0.002131  \n",
       "311          0.898992         0.002131  \n",
       "208          0.898992         0.002131  \n",
       "23           0.898992         0.002131  \n",
       "121          0.898992         0.002131  \n",
       "316          0.898992         0.002131  \n",
       "207          0.898992         0.002131  \n",
       "245          0.898992         0.002131  \n",
       "335          0.898992         0.002131  \n",
       "209          0.898992         0.002131  \n",
       "25           0.898992         0.002131  \n",
       "24           0.898992         0.002131  \n",
       "136          0.898992         0.002131  \n",
       "118          0.898992         0.002131  \n",
       "114          0.898992         0.002131  \n",
       "200          0.877672         0.005474  \n",
       "204          0.894503         0.002126  \n",
       "205          0.897871         0.003252  \n",
       "\n",
       "[396 rows x 17 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(adaboost_grid.cv_results_)\n",
    "result.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:13:25.909803Z",
     "start_time": "2019-09-02T12:13:25.900039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__criterion': 'entropy',\n",
       " 'base_estimator__splitter': 'random',\n",
       " 'n_estimators': 4}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:15:57.052260Z",
     "start_time": "2019-09-02T12:15:53.652395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    3.4s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=101, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_leaf_nodes': range(2, 10, 2),\n",
       "                         'min_samples_split': range(2, 20, 2)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "params = {\n",
    "    'min_samples_split': range(2, 20, 2),\n",
    "    'max_leaf_nodes': range(2, 10, 2)\n",
    "}\n",
    "rfc_grid = GridSearchCV(rfc,\n",
    "                        param_grid=params,\n",
    "                        verbose=True,\n",
    "                        scoring='accuracy',\n",
    "                        return_train_score=True,\n",
    "                        cv=kfold,\n",
    "                        n_jobs=-1)\n",
    "rfc_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:16:04.834509Z",
     "start_time": "2019-09-02T12:16:04.828406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294051627384961"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T12:16:16.482069Z",
     "start_time": "2019-09-02T12:16:16.472882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 6, 'min_samples_split': 18}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
